---
title: "Sensitivity Analysis"
author: \href{mailto:leavitt@hcp.med.harvard.edu}{Thomas Leavitt}
date: "August 10, 2022"
output: 
  pdf_document:
    citation_package: natbib
    fig_caption: yes
    fig_height: 5
    fig_width: 7
    highlight: tango
    keep_tex: true
    latex_engine: xelatex
    toc: no
    toc_depth: 1
    includes:
      in_header: mystyle.sty
fontsize: 12pt
classoption: leqno
geometry: margin = 1.5cm
bibliography: sensitivity.bib ## cannot have underscore in .bib file name
biblio-style: apsr
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
#install.packages("knitr")

#install.packages("rmdformats")
library(knitr)
library(rmdformats)
library(tidyverse)
library(magrittr)
library(optmatch)

## Global options
options(max.print = "75")
opts_chunk$set(echo = TRUE,
	             cache = TRUE,
               prompt = FALSE,
               tidy = TRUE,
               comment = NA,
               message = FALSE,
               warning = FALSE)
opts_knit$set(width = 75)

```

# Matched design

Imagine that we had this matched design from the @cerdaetal2012 study:

\scriptsize
```{r}

load(url("http://jakebowers.org/Data/meddat.rda"))
meddat <- mutate(meddat,
  HomRate03 = (HomCount2003 / Pop2003) * 1000,
  HomRate08 = (HomCount2008 / Pop2008) * 1000
)
row.names(meddat) <- meddat$nh

## Make one of the covariates have missing data to
## demonstrate how to match on it

covs <- c("nhPopD", "nhAboveHS","HomRate03")
balfmla <- reformulate(termlabels = covs,
                       response = "nhTrt")

mhdist <- match_on(x = balfmla,
                   data = meddat,
                   method = "rank_mahalanobis")

psmod <- arm::bayesglm(formula = balfmla,
                       data = meddat,
                       family = binomial(link = "logit"))
stopifnot(any(abs(coef(psmod)) < 10))
psdist <- match_on(x = psmod,
                   data = meddat)
## Make a scalar distance
tmp <- meddat$HomRate03
names(tmp) <- rownames(meddat)
absdist <- match_on(x = tmp,
                    z = meddat$nhTrt,
                    data = meddat)

## Inspect the distance matrices to choose calipers if desired
quantile(x = as.vector(x = psdist),
         probs = seq(from = 0,
                     to = 1,
                     by = 0.1))

quantile(x = as.vector(x = mhdist),
         probs = seq(from = 0,
                     to = 1,
                     by = 0.1))
quantile(x = as.vector(x = absdist),
         probs = seq(from = 0,
                     to = 1,
                     by = 0.1))
## Match and require no more than 3 treated per control, and no more than 5 control per treated
fmMh <- fullmatch(x = psdist + caliper(x = psdist,
                                       width = 5) + caliper(x = absdist,
                                                            width = 2) + caliper(x = mhdist,
                                                                                 width = 52),
                  min.controls = 0, ## 1/3
                  max.controls = Inf,
                  data = meddat,
                  tol = .00001)
summary(object = fmMh,
        min.controls = 0,
        max.controls = Inf,
        propensity.model = psmod)
meddat$fmMh <- factor(x = fmMh)
meddat$nhTrtF <- factor(x = meddat$nhTrt)

```
\normalsize

# How do I assess the sensitivity of my inferences to hidden bias?

In our case, with $n = 43$ total matched units and, based on the number of blocks and number of units within each block, the number of candidate vectors is:

\scriptsize
```{r}

meddat <- filter(.data = meddat,
                 !is.na(fmMh))

n_ubs <- table( meddat$fmMh ) - 1
prod( n_ubs ) 

```
\normalsize

When combined with the set of all possible treatment assignments, $\Omega$ and the many possible values of $\gamma$, it is computationally burdensome to enumerate this many candidate vectors, and this is only a small dataset.

To conduct our sensitivity analysis, we will use the \texttt{senstrat} package, which is the companion \texttt{R} package to @rosenbaum2018. The \texttt{senstrat} package uses the test statistic, $\mathbf{Z}^{\top}\mathbf{y}$, under the sharp null of no effect. Most test statistics of interest have an equivalent representation as a sum statistic via scale and shift factors of $\mathbf{y}$ that do not depend on the treatment variable.

For example, we can rescale our outcome variable such that the sum statistic in the \texttt{senstrat} package is equivalent to the Difference-in-Means test-statistic in which each set-specific test-statistic is weighted by the proportion of units in that set.

\scriptsize
```{r, tidy = FALSE}

meddat <- meddat %>% 
  group_by(fmMh) %>% 
  mutate(fm_n = n(),
         fm_n_0 = sum(1 - nhTrt),
         fm_n_1 = sum(nhTrt),
         fm_sum_y = sum(HomRate08),
         fm_h = (1/fm_n_0 + 1/fm_n_1)^{-1})

meddat <- mutate(.data = meddat,
                 HomRate08_resc = (HomRate08/fm_h - fm_sum_y/(fm_n_0 * fm_n_1)) * (fm_n/nrow(meddat)))

```
\normalsize

Now let's calculate the test-statistic on the rescaled outcomes. Notice that with our rescaled outcome, our observed test statistic, is reproduced by the sum statistic used in the \texttt{senstrat} package. 

\scriptsize
```{r, tidy = FALSE}

# install.packages("blkvar")
library(blkvar)
obs_diff_means <- block_estimator(Yobs = HomRate08,
                                  Z = nhTrt,
                                  B = fmMh,
                                  data = meddat,
                                  method = "hybrid_p" )$ATE_hat

# install.packages("senstrat")
library(senstrat)

cbind(senstrat(sc = meddat$HomRate08_resc,
               z = meddat$nhTrt,
               st = meddat$fmMh,
               gamma = 1)$Result["Statistic"],
      obs_diff_means)

```
\normalsize

Having rescaled the outcome of interest to recover our difference-in-means test statistic, we can now implement the sensitivity analysis. Since we are interested in the sharp null hypothesis relative to the alternative of larger effect, we assess how our upper $p$-values change for different values of $\Gamma$.

\scriptsize
```{r, tidy = FALSE, fig.width = 5, fig.height = 3}

senstrat_p_values <- sapply(X = seq(from = 1, to = 2.5, by = 0.001),
                            FUN = function(x) { 
                              senstrat(sc = meddat$HomRate08_resc,
                                       z = meddat$nhTrt,
                                       st = meddat$fmMh,
                                       gamma = x,
                                       alternative = "less")$Result[1] })

senstrat_plot_data <- data.frame(Gamma = seq(from = 1,
                                             to = 2.5,
                                             by = 0.001),
                                 p_value = senstrat_p_values)

min(senstrat_plot_data$Gamma[which(senstrat_plot_data$p_value >= 0.05)])
min(senstrat_plot_data$Gamma[which(senstrat_plot_data$p_value >= 0.1)])

alpha <- 0.05

ggplot(data = senstrat_plot_data,
       mapping = aes(x = Gamma,
                     y = p_value)) +
  geom_line() +
  geom_hline(yintercept = alpha) +
  theme_bw() +
  scale_x_continuous(breaks = seq(from = 1, to = 10, by = 1)) +
  scale_y_continuous(breaks = c(0, 0.05, 0.1)) +
  xlab(label = expression(Gamma)) +
  ylab(label = "Upper bound of p-value")

```
\normalsize

We are able to reject the sharp null of no effects under the assumption of uniform assignment probabilities within blocks (i.e., $\Gamma = 1$). However, this qualitative conclusion is fairly sensitive to deviations from this assumption. At a $\Gamma$ of roughly $1.404$, we are no longer able to reject the sharp null of no effect at an $\alpha$-level of $0.05$. In general, the worst-case $p$-value of a test of the sharp null of no effect is increasing in $\Gamma$ and in principle we could assess sensitivity for any $\alpha$-level, not only the conventional level of $\alpha = 0.05$.
E.g., for $\alpha = 0.10$ our sensitivity goes to around 2.289.

\newpage
# References
