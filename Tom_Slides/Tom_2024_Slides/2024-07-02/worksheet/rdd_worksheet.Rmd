---
title: "Regression Discontinuity Design"
author: \href{mailto:thomas.leavitt@baruch.cuny.edu}{Thomas Leavitt}
date: "July 2, 2024"
output: 
  pdf_document:
    citation_package: natbib
    fig_caption: yes
    fig_height: 5
    fig_width: 7
    highlight: tango
    keep_tex: true
    toc: no
    toc_depth: 1
    includes:
      in_header: mystyle.sty
fontsize: 12pt
classoption: leqno
geometry: margin = 1.5cm
bibliography: rddbibliography.bib
biblio-style: apsr
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
#install.packages("knitr")

#install.packages("rmdformats")
library(knitr)
library(rmdformats)
library(tidyverse)
library(magrittr)
library(haven)
library(RItools)
library(parallel)
library(MASS)
library(estimatr)
library(rdd)
library(rdrobust)

## Global options
options(max.print = "75")
opts_chunk$set(echo = TRUE,
	             cache = TRUE,
               prompt = FALSE,
               tidy = TRUE,
               comment = NA,
               message = FALSE,
               warning = FALSE)
opts_knit$set(width = 75)

```

\section{Application to close elections}

Today we are going to use the data on close US House of Representatives races
1942--2008 used in @caugheysekhon2011.^[The full replication data is
available for download \href{http://sekhon.berkeley.edu/rep/RDReplication.zip}{here}. But we read it directly below.] @caugheysekhon2011 engage in a debate whose
participants seek to identify the causal effect of the so-called "incumbency
advantage." That is, what effect does a candidate's status as an incumbent
have on whether or not that candidate wins an election? Obviously, whether or
not a candidate is an incumbent is *not* randomly assigned.

Let's first load the data:
\scriptsize
```{r, results = "hide", message = FALSE}

rdd_data <- read_dta("http://jakebowers.org/Matching/RDReplication.dta") %>%
  filter(Use == 1) ## Use is indicator for whether unit is included in RD incumbency advantage sample

```
\normalsize

The "running variable" is called `DifDPct`, which is defined as the Democratic margin of victory or defeat in the election; in other words, DifDPct is the difference between the percentage of all votes that were cast for the leading Democrat in the race and the percentage cast for the leading non-Democrat. Races in which no Democrat ran or in which the top two vote-getters were both Democrats are coded as missing.

\scriptsize
```{r, message = FALSE}

running_var <- matrix(c("DifDPct", "Democrat Margin of Victory"),
  ncol = 2,
  byrow = TRUE
)

dimnames(running_var) <- list(1, c("Running Variable", "Description"))

kable(running_var)

```
\normalsize

The treatment variable is whether or not the Democratic candidate wins the election or not. If the candidate wins the election, then that candidate is assigned to "treatment." If the candidate loses the election, then he or she is assigned to "control.''

\scriptsize
```{r, message = FALSE}

treatment <- matrix(c("DemWin", "Democrat Wins Election"),
  ncol = 2,
  byrow = TRUE
)
dimnames(treatment) <- list(1, c("Treatment", "Description"))
kable(treatment)

```
\normalsize

Now let's quickly look at the empirical distribution of the treatment variable:

\scriptsize
```{r, message = FALSE}

table(rdd_data$DemWin)

```
\normalsize

In @caugheysekhon2011, the primary outcome variables of interest are as
follows: whether a democrat wins the next election, the proportion voting for
a democrat in the next election, and the democratic vote margin in the next
election.

\scriptsize
```{r, message = FALSE}

dvs <- matrix(c("DWinNxt", "Dem Win t + 1",
                "DPctNxt", "Dem t + 1",
                "DifDPNxt", "Dem Margin t + 1"),
              ncol = 2,
              byrow = TRUE)

dimnames(dvs) <- list(seq(from = 1,
                          to = 3,
                          by = 1),
                      c("Outcome", "Description"))

kable(dvs)

```
\normalsize

The relevant baseline covariates (all measured prior to the realization of the running variable) are:

\scriptsize
```{r, message = FALSE}

covs <- matrix(c("DWinPrv", "Dem Win t - 1",
                 "DPctPrv", "Dem % t - 1",
                 "DifDPPrv", "Dem % Margin t - 1",
                 "IncDWNOM1", "Inc's D1 NOMINATE",
                 "DemInc", "Dem Inc in Race",
                 "NonDInc", "Rep Inc in Race",
                 "PrvTrmsD", "Dem's # Prev Terms",
                 "PrvTrmsO", "Rep's # Prev Terms",
                 "RExpAdv", "Rep Experience Adv",
                 "DExpAdv", "Dem Experience Adv",
                 "ElcSwing", "Partisan Swing",
                 "CQRating3", "CQ Rating {-1, 0, 1}",
                 "DSpndPct", "Dem Spending %",
                 "DDonaPct", "Dem Donation %",
                 "SoSDem", "Dem Sec of State",
                 "GovDem", "Dem Governor",
                 "DifPVDec", "Dem Pres % Margin", ## average over decade
                 "DemOpen", "Dem-held Open Seat",
                 "NonDOpen", "Rep-held Open Seat",
                 "OpenSeat", "Open Seat",
                 "VtTotPct", "Voter Turnout %",
                 "GovWkPct", "Pct Gov't Worker",
                 "UrbanPct", "Pct Urban",
                 "BlackPct", "Pct Black",
                 "ForgnPct", "Pct Foreign Born"),
               ncol = 2,
               byrow = TRUE)

dimnames(covs) <- list(seq(from = 1,
                           to = 25,
                           by = 1),
                       c("Covariate", "Description"))

kable(covs)

```
\normalsize

\section{Local as-if randomization framework}

\subsection{Optimal bandwidth selection}

Let's specify a set of candidate bandwidths and then sequentially test covariate balance. Before actually testing, though, we want to specify a balance criterion and then maximize effective sample size subject to that criterion.

\scriptsize
```{r, results = "hide", message = FALSE}

bal_fmla <- reformulate(termlabels = covs[1:25],
                        response = "DemWin")

candidate_bands <- seq(from = -5,
                       to = 5,
                       by = .1)

```
\normalsize

Now let's first filter our dataset and check for balance in the largest candidate bandwidth spanning from $-5$ to $5$.

\scriptsize
```{r, results = "hide", message = FALSE}

lower_bound <- seq(from = -5, to = -0.1, by = 0.1)

upper_bound <- seq(from = 0.1, to = 5, by = 0.1) %>%
  sort(decreasing = TRUE)

rdd_dataA <- rdd_data
rdd_dataA <- dplyr::filter(.data = rdd_dataA,
                           DifDPct > lower_bound[1] & DifDPct < upper_bound[1])

rdd_dataA %$% summary(DifDPct)

xBalance(fmla = bal_fmla,
         data = rdd_dataA,
         report = "chisquare.test")

xb1 <- xBalance(fmla = bal_fmla,
                data = rdd_dataA,
                report = "all")
xb1$results

```
\normalsize

Now let's write a function to perform this same procedure over all candidate
bandwidth sizes beginning with the largest candidate bandwidth and
subsequently testing smaller and smaller bandwidths in order.

\scriptsize
```{r, results = "hide", message = FALSE}

chi_squared_balance <- function(lb,
                                ub,
                                running_var,
                                bal_fmla,
                                data) {

  data <- dplyr::filter(.data = data,
                        running_var > lb & running_var < ub)


  ess <- nrow(data)

  p_value <- xBalance(fmla = bal_fmla,
                      data = data,
                      report = "chisquare.test")$overall[[3]]
  
  bands <- cbind(ess, p_value, lb, ub)

  return(bands)
}


```
\normalsize

Now use the function:

\scriptsize
```{r, message = FALSE}

lbs <- seq(from = -0.5, to = -0.1, by = 0.1)
ubs <- seq(from = 0.5, to = 0.1, by = -0.01)

band_df <- data.frame(t(sapply(X = 1:length(lbs),
                               FUN = function(x) { chi_squared_balance(lb = lbs[x],
                                                                       ub = ubs[x],
                                                                       running_var = rdd_data$DifDPct,
                                                                       bal_fmla = bal_fmla,
                                                                       data = rdd_data) }))) %>%
  rename(ess = X1,
         p_value = X2)

kable(band_df)

```
\normalsize


\scriptsize
```{r, message = FALSE, fig.width=5, fig.height=3}
g <- ggplot(data = rdd_data,
            mapping = aes(x = DifDPct,
                          y = DPctNxt,
                          color = DemWin)) +
  geom_point()
g + xlim(c(-.4,.4))

```
\normalsize

\subsection{Outcome analysis}

We could also perform permutation inference within the window around the cutpoint under the assumption that local randomization holds (useful especially if the window contains relatively few observations, skewed outcomes, etc..):

\scriptsize
```{r}

rdd_data47 <-  rdd_data %>%
  filter(DifDPct > lower_bound[47] & DifDPct < upper_bound[47])

rdd_data47 %>% nrow()

set.seed(1:5)
sharp_null_dist <- replicate(n = 10^3,
                             expr = coef(lm(formula = DPctNxt ~ sample(DemWin), data = rdd_data47))[[2]])

obsstat <- coef(lm(formula = DPctNxt ~ DemWin,
                   data = rdd_data47))[["DemWin"]]

upper_p_val <- mean(sharp_null_dist >= obsstat)
lower_p_val <- mean(sharp_null_dist <= obsstat)
two_sided_p_val <- min(1, 2 * min(upper_p_val, lower_p_val))

two_sided_p_val

rdd_data47$DemWinF <- factor(rdd_data47$DemWin)

```
\normalsize

We can now perform outcome analysis on the detrended outcome variable:

\scriptsize
```{r}

tmp_lm <- lm(DPctNxt ~ DifDPct, data = rdd_data47)

rdd_data47 %<>% mutate(resid_DPctNxt = resid(tmp_lm))

lm_robust(formula = resid_DPctNxt ~ DemWin,
          data = rdd_data47)

```
\normalsize


@saleshansen2020, however, propose robust regression, which is less sensitive to violations of the regression model's assumptions --- still removing linear trend here.

\scriptsize
```{r}

tmp_rlm <- rlm(DPctNxt ~ DifDPct, data = rdd_data47)
rdd_data47 %<>% mutate(rlm_resid_DPctNxt = resid(tmp_rlm))
lm_robust(formula = rlm_resid_DPctNxt ~ DemWin,
          data = rdd_data47)

```
\normalsize

We don't actually need to know the true form of $\E[\left[Y | R =r\right]$. Instead, we can use methods, such as local regression, to
approximate the function of $\E[\left[Y | R = r\right]$ at values of $R$
below and above the cutpoint.

\scriptsize
```{r}
rdd_data %<>% arrange(DifDPct)

rdd_data_cp <- dplyr::select(.data = rdd_data, DifDPct, DPctNxt, DemWin) %>%
  mutate(cp = ifelse(test = DifDPct < 0, yes = "Below Cutpoint",
    no = "Above Cutpoint"))
```
\normalsize

\scriptsize
```{r echo=FALSE}
ggplot(data = rdd_data_cp,
       mapping = aes(
         x = DifDPct,
         y = DPctNxt)) +
  geom_point() +
  geom_smooth(method = lm,
              se = FALSE) +
  geom_smooth(method = rlm,
              se = FALSE,
              colour = "black") +
  geom_smooth(method = loess,
              se = FALSE,
              colour = "red",
              method.args = list(deg = 1,
                                 span = 1 / 2,
                                 family = "symmetric")) +
  theme(plot.title = element_text(hjust = 0.5),
        axis.text.x = element_text(size = 4)) +
  xlab("Democratic Margin of Victory (Running Variable)") +
  ylab("Democratic Vote Percentage in Next Election (Outcome Variable)") +
  ggtitle("Relationship between Running Variable and Outcome") +
  facet_wrap(facets = . ~ cp,
             nrow = 1,
             ncol = 2)
```
\normalsize

\section{Continuity in Potential Outcomes}

Let's first use a simple linear model to estimate the relationship on both sides of the cutpoint. Here we are not using a window.

\scriptsize
```{r}

lm_predict_below <- predict(object = lm(formula = DPctNxt ~ DifDPct,
                                        data = rdd_data, subset = DifDPct < 0),
                            newdata = data.frame(DifDPct = 0))

lm_predict_above <- predict(object = lm(formula = DPctNxt ~ DifDPct,
                                        data = rdd_data, subset = DifDPct > 0),
                            newdata = data.frame(DifDPct = 0))

lm_predict_above - lm_predict_below
```
\normalsize

We could also do the same thing with LOESS regression:

\scriptsize
```{r}

loess_predict_below <- predict(object = loess(
  formula = DPctNxt ~ DifDPct,
  data = rdd_data,
  subset = DifDPct < 0,
  surface = "direct"),
  newdata = data.frame(DifDPct = 0))

loess_predict_above <- predict(object = loess(
  formula = DPctNxt ~ DifDPct,
  data = rdd_data,
  subset = DifDPct > 0,
  surface = "direct"),
  newdata = data.frame(DifDPct = 0))

loess_predict_above - loess_predict_below
```
\normalsize

We could also use a $p$th order polynomial. For example:

\scriptsize
```{r}

lm_poly_predict_below <- predict(object = lm(
  formula = DPctNxt ~ I(DifDPct^3) + I(DifDPct^2) + DifDPct,
  data = rdd_data, subset = DifDPct < 0),
  newdata = data.frame(DifDPct = 0))

lm_poly_predict_above <- predict(object = lm(
  formula = DPctNxt ~ I(DifDPct^3) + I(DifDPct^2) + DifDPct,
  data = rdd_data, subset = DifDPct > 0),
  newdata = data.frame(DifDPct = 0))

lm_poly_predict_above - lm_poly_predict_below
```
\normalsize

This next calculates a bandwidth and then does what we just did above (all in one step):

\scriptsize
```{r}

rdest1 <- RDestimate(formula = DPctNxt~DifDPct,
                     data = rdd_data,
                     se.type = "HC3")
summary(rdest1)

plot(rdest1)

```
\normalsize

\scriptsize
```{r}

rdrest1 <- rdrobust(y = rdd_data$DPctNxt,
                    x = rdd_data$DifDPct)
summary(rdrest1)


rdplot(y = rdd_data$DPctNxt,
       x = rdd_data$DifDPct)

```
\normalsize

\newpage
# References




