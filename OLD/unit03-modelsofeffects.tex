%  For slides only
\input{slidesonly}

% % For handout
%\input{handout}

%For handout + mynotes
%\input{handout+mynotes}

\input{beamer-preamble-bbh-all}
\input{defs-all}
\input{courseedition}

\title[Fisherian inference]{Unit 3: Fisherian randomization inference and models of effects}
% \author, date moved to beamer-preamble-*-all.tex

\begin{document}


% putting `\begin{frame}`/ `\end{frame}` in announcement-of-the-day.tex lets us 
% put frame notes into that file
% announcement-of-the-day.tex not part of repo
% \InputIfFileExists{announcement-of-the-day.tex}{% from https://tex.stackexchange.com/questions/100663/if-the-remote-file-exists-then-include-it-else-include-the-local-one
%   % File personal/bar.tex exists and is read
  \input{announcement-of-the-day}
% }{%
%   % File personal/bar.tex is not found, try bar.tex
% }


\begin{frame}[<+->]{Background: permutation tests vs parametric tests}

To compare 2 (or more) groups, one chooses between
permutation and parametric tests. E.g., Fisher vs. $\chi^{2}$ tests.
\begin{itemize}
\item both begin by computing a test statistic
\item they differ in terms of what they compare the statistic to in order to get a p-value
\item parametric tests posit a model for $Y| \mathrm{group}$
\item W/ random assignment, permutation tests don't have to
  assume any model for $Y| \mathrm{group}$.
\item (However, hunches about $Y| \mathrm{group}$ are sometimes used
  to select the test
  statistic.)
\item likewise, the permutational approach circumvents sample-size requirements for p-values' validity.
\end{itemize}

Software notes:
\begin{itemize}
\item In unit 2, $z$'s were permuted using \texttt{sample(z)}.
\item \texttt{sample()} is part of base R.  the ``permute'' library's
  ``\textrm{shuffle}''  is more evocative.
\end{itemize}

\end{frame}

\itnote{
\item   Example for test statistic point: $Y| G=g \sim \mathcal{N}(\mu_{g}, \sigma^{2})
  \Rightarrow $ $t(\mathbf{z}, \mathbf{y}) =$ difference of means statistic; $Y| G=g \sim \mathrm{Logistic}(\mu_{g}, s)
  \Rightarrow $ $t(\mathbf{z}, \mathbf{y}) =$  rank sum statistic.
}

\begin{frame}<1-4\mynoteonly>[label=testStats4MeanComparison1Fr]{Background:
    non-Normality robustness; choice of $t(\mathbf{z}, \mathbf{y})$}

Stepping back momentarily from issues specific to causal inference, consider the one-way model
$$
Y = \mu + Z\tau + \epsilon,\, \mathbf{E}(\epsilon) = 0.
$$

Suppose the goal is to test the hypothesis that $\tau = 0$.
  
\begin{itemize}[<+->]
\item If $\epsilon \sim \mathcal{N}(0, \sigma^{2})$, some $\sigma >0$, regardless of whether $Z=1$ or 0, the difference of means is optimal, in various senses, as an estimator of $\tau$. By extension, using it as a test statistic gives favorable power.
\item True both for parametric tests (t-test) and permutation tests.
\item If $\epsilon$ follows some other distribution, parametric
  $t$-test's $\alpha$ level is only approximate.  (To
  fix, use permutation $t$-test.)
\item For \textit{both} versions, {power} suffers. ($\bar{Y}$ reacts so
  strongly to outliers unrelated to treatment that  $\mu$ becomes
  hard to see.)
\item To fix, select a test statistic with built-in outlier
  protection.
\end{itemize}
\end{frame}

\itnote{
\item This time, first 4 bullets only.
}

\section{Models of effects}
\begin{frame}{A simple model of effects for the Acorn GOTV experiment}
  
One simple model is that the GOTV campaign increases voter turnout by $p$ percentage points per precinct.

\begin{center}
  \begin{tabular}{r|rr|rr}
  \hline
 & GOTV? & vote03(\%)& $y_c$ & $y_t$ \\
  \hline
1 & 0 & 38 & 38 & $38+p$\\
$\vdots$& & & & \\
13 & 0 & 19 & 19& $19+p$\\
14 & 0 & 34 & 34& $34+p$\\
15 & 1 & 49 & $49-p$& 49\\
16 & 1 & 38 & $38-p$& 38\\
$\vdots$& & & & \\
28 & 1 & 29 & $29-p$& 29\\
   \hline
\end{tabular}

\end{center}

This family of hypotheses, as $p$ varies between $-100$ and $100$, can be called a \textit{model of effects}.
\end{frame}

\begin{frame}{Testing simple models other than the no-effect model}

\begin{columns}
\column{.4\linewidth}

\begin{itemize}
\item At right: 3 models/hypotheses
\item You can decide how to test:
  \begin{itemize}
  \item $t$
  \item one-sided or 2? 
  \item \ldots
  \end{itemize}
\item Relative to the model that assignment to GOTV increases turnout by
  $p$, and to designated tests (each $p$) ---  
\end{itemize}
\column{.6\linewidth}    
{\small
\addtolength{\tabcolsep}{-\tabcolsepadj} 
  \begin{tabular}{r|rr|rr|rrr}
  \hline
  &       &                           &           &         &
                                                              \multicolumn{3}{c}{$y_{C
                                                              | p=
                                                              \underline{\hspace{1em}}}$} \\
 & $z$ & $y_{\mathrm{obs}}$ & $y_C$ & $y_T$ & $-10$\% & 0\% & 10\% \\
  \hline
1 & 0 & 38 & 38 & $38+p$ & 38 & 38 & 38\\
$\vdots$& & & & & &  &\\
13 & 0 & 19 & 19& $19+p$ & 19 & 19 & 19\\
14 & 0 & 34 & 34& $34+p$& 34 & 34 & 34 \\
15 & 1 & 49 & $49-p$& 49 & 59 & 49 & 39 \\
16 & 1 & 38 & $38-p$& 38 & 48 & 38 & 28 \\
$\vdots$& & & & & & &\\
28 & 1 & 29 & $29-p$& 29 & 39 & 29 & 19 \\
   \hline
\end{tabular}
 \addtolength{\tabcolsep}{\tabcolsepadj}
}

\end{columns}
  \vfill 
\begin{quote}
$1-\alpha$ confidence set for $p$ $\equiv $ \{$p$: $H_{p}$ not rejected at
  level $\alpha$\} .  
\end{quote}

\vfill
\end{frame}

\begin{frame}{A more nuanced model for the Acorn GOTV experiment} % if
                                % "more nuanced" changes, drop from
                                % next slide too

Recall that a \textit{response schedule} is a complete specification of unit-level responses to the experiment under every possible random assigment.

It's often more natural to hypothesize only about how treated units would have responded to control, not also how controls would have responded to treatment. For example, here are 3 competing models of the effects of the Acorn GOTV campaign:
\begin{itemize}
\item[No effect] says there was no effect (\texttt{RS0})
\item[one per 10] says the GOTV campaign generated 1 vote for every 10 contacts (\texttt{RS1})
\item[one per 5]says the GOTV campaign generated 1 vote for every 5 contacts (\texttt{RS2})
\end{itemize}

\pause
Note that these models don't specify $y_{t}$ for precincts we only got to observe under control, $z=0$ --- they leave ``blanks'' in the potential schedule.  That's OK.

\end{frame}

\begin{frame}<\nottheirhandout>{You can test a hypothesis specifying
    all of $\mathbf{y}_{c}$} \framesubtitle{even if it leaves blanks
    in $\mathbf{y}_{t}$}

   \textit{Uniformity trial}:  Measure covariates, ``assign'' treatments $\mathbf{Z}$; but then don't administer any ($\mathbf{d}\equiv 0$).    But measure outcomes anyway.  (Nowadays, a concept rather than a practice.)

 
   An incomplete response schedule can still give us enough to do
   statistical testing. For example, if  \{hypothesis,
   $\mathbf{y}_{\mathrm{obs}}$\} together determine $\mathbf{y}_{U}$,
   the vector of responses that would have been obtained in the
   \textit{uniformity trial}   then for any test statistic $t $ we can
   test by comparing $t(\mathbf{z}, \mathbf{y}_{U})$ to the permutation distribution of $t(\mathbf{Z}, \mathbf{y}_{U}) $ .

Using $t(\mathbf{z}, \mathbf{y}_{U}) = \bar{y}_{U1} - \bar{y}_{U0} $,

\begin{center}
\begin{tabular}{l|rrr} \hline
& \multicolumn{3}{c}{votes/ 10 contacts}\\
  Hypothesis & 0 & 1 & 2 \\ \hline
$p$ (2-sided) & \visible<2->{.15} & \visible<2->{.38} & \visible<2->{.003} \\ \hline
\end{tabular}
\end{center}

(see \texttt{unit03-Rex.pdf}).
\end{frame}

\note{
Now start \texttt{unit03-Rex}
}



\section{Inference w/ general models of effects}

\subsection{Confidence intervals by inversion of tests}
\begin{frame}{Confidence intervals and models of effects}

  \begin{itemize}[<+->]
  \item The 3 models just considered fall under the broader model that the GOTV
generated $v$ votes per contact, some $v \in [-1, 1]$.
\item Assuming that model, the 95\% CI for $v$ is the collection of $v$s corresponding to incomplete response schedules that would not be rejected at level .05 - a confidence interval by inversion of a family of hypothesis tests.
\item This enables us to back out a confidence interval for the
  ``Complier average treatment effect,'' w/o violating the
  intention-to-treat principle! (Rosenbaum, 1997).
\item In addition, this method of confidence interval construction is
  immune to the problem of weak instruments (cf. \textit{DOS} \S~5.3 \&
  contained references).
  \end{itemize}


\end{frame}

\begin{frame}{Estimates and models of effects}
  
  \begin{itemize}
\item If you want an estimate to go with such a confidence interval,
  the convention is to report a \textit{Hodges-Lehmann} estimate ---
  the limit of 100*$(1-\alpha)$\% CIs, as $\alpha \uparrow
  1$\footnote{Assuming the limit exists and contains a single
    point. If you want to compute (rather than interpret) an HL
    estimate, get the precise definition, as e.g. in \textit{DOS} \S~2.4.3. }. 
\item There's no precise analogue of the ``standard error''\ldots
\item So you can't use $\hat{\theta} \pm z_{*}\mathrm{s.e.}(\hat
  \theta)$ as a CI. 
\item However, for the spirit of a ``standard error'', some report a 2/3 CI alongside a 95\% CI  (Mosteller \& Tukey, 1977, \textit{Data analysis and regression}).
  \end{itemize}
\end{frame}
\subsection{Example: Violence in Medell{\'i}n} 
\begin{frame}
\frametitle{Example: Violence and public infrastructure in Medell{\'i}n, Colombia}
\begin{columns}
  \begin{column}{.5\linewidth}
    \begin{itemize}
    \item 2 million residents; 16 districts
    \item Pre-intervention: 60\% poverty rate, 20\% unemployment, homicide 185 p
er 100K
    \item High residential segregation
    \item<2-> 2004-2006: infrastructure intervention for certain poor neighborho
ods.
    \end{itemize}
  \end{column}
  \begin{column}{.5\linewidth}
    \only<1>{\igrphx{medellin-conc-pov}}
\only<2-\mynoteonly>{\igrphx{medellin-gondola}}
  \end{column}
\end{columns}

\end{frame}
\itnote{
\item 2017+: Cycled back to this later in course, not during unit 3.
  Ordinarily it's too much at first pass.
\item (strata will enter the story because the end analysis involved
  matching)
}



\begin{frame}[fragile]{A model of effects for homicide rates in Medellin}

Each Medellin neighborhood provides several years of non-independent
data.  If we're willing to model Metrocable as a natural experiment,
we can borrow longitudinal data methods, without having to adopt their
dependence assumptions.   For instance, using random
 effects: 

 \begin{enumerate}[<+->]
 \item Let
   $y(T)=$ neighborhood homicide rate in year $T=2002, \ldots, 2008$.  We'll test models of
   effects of form, for rates $r \leq 0$:
$$H_{0}: y_{t}(T) = \left\{ \begin{array}{lr}\exp((T-2004) r/4)
                              y_{c}(T),& T> 2004; \\
y_{c}(T),& T\leq 2004.\end{array} \right.$$ 
 \item Given $H_{0}$, fit a random effects model of this form:
\begin{semiverbatim}
 lmer(Count \textasciitilde\  year + (year+1|nh) +\ \pause
            \alert<@+| handout:0>{offset}( nhTrt*(yr>2004)*(r/4)*(yr-2004) ),
          family=poisson, data=homd)
\end{semiverbatim}
\item Fitted params include  ``fixed'' intercept and slope,
  $\hat{\beta}_{0(r)}$ and $ \hat{\beta}_{1(r)}$,\pause  plus a
  ``random'' slope and intercept (also specific to $r$) for
  each n-hood.  
\item To test $H_{0}$, I used a test statistic comparing $t$ vs $c$
  n-hoods' fitted intercepts. For reference distribution, 
  intercepts shuffled within matched sets.
 \end{enumerate}

  
\end{frame}

\begin{frame}<\nottheirhandout>{Outcome analysis for the Medellin study}
\framesubtitle{Official statistics on n-hood violence}
  
  \begin{center}
    \igrphx[width=\linewidth]{medellin-TEs-homicide}
  \end{center}

\end{frame}



\begin{frame}<\nottheirhandout>{Outcome analysis for the Medellin
    study}
\framesubtitle{Outcomes constructed from survey responses}

\begin{center}
      \igrphx[width=\linewidth]{medellin-TEs-amenities}
\end{center}
\end{frame}
\section{Tests for normal, not Normal, data distributions}


\subsection{Unstratified case}
\againframe{testStats4MeanComparison1Fr}

\begin{frame}{M-estimation using Huber's loss/psi function} \framesubtitle{as a remedy for the difference in means' hypersensitivity}
  \begin{columns}
    \begin{Column}
          \begin{center}
         {\usebeamercolor[fg]{titlelike} Huber vs squared-error loss}
    \end{center}
      \igrphx{huber-loss-fct}
    \end{Column}
    \begin{Column}
          \begin{center}a
         {\usebeamercolor[fg]{titlelike} Huber's psi function}
    \end{center}

\igrphx{Hubers-Psi-Graph}
    \end{Column}
  \end{columns}
\pause
In practice, Huber's M-estimation solves a regression problem in which
the residuals have been top- and bottom-coded, $e \mapsto \max(-t,
\min(t,e))$ at a data-dependent threshold $t>0$.
\end{frame}
\Note{

Tech note: specificially, just as OLS produces residuals that sum to 0
and are uncorrelated with each column of $\mathbf{x}$, the Huber
M-estimate gives residuals which sum to 0 and are uncorrelated with
the xes, \textit{after} the top and bottom coding.
}
\begin{frame}{Rank-based tests } \framesubtitle{as a remedy for the difference in means' hypersensitivity}
  
\end{frame}

\begin{frame}{Workflow for analyzing experiments/obs studies}
  \framesubtitle{To summarize from earlier units:}

  \begin{columns}
    \begin{column}{.25\linewidth}
      
    \end{column}
    \begin{column}{.75\linewidth}
        \begin{itemize}
  \item[Comparison Design] Specify clustering, pairing or blocking
  \item[Estimation] Optionally, compute unbiased estimate of ATE
  \item[MOEs] Specify models of effect; separately for each, figure $\mathbf{y}_{\mathbf{z}\equiv 0} $ or a summary of it.
  \item[Tests \& CIs] Select test statistic, perform h-tests (separately for each MOE). Summarize the results with a 95\% CI, maybe also 2/3 CI. 
  \item[HL estimates] Optionally, Hodges-Lehmann estimate
  \end{itemize}

    \end{column}
  \end{columns}
\end{frame}
\note{Update me.  Should covariance adjustment go in at first pass?}
\section{Covariance adjustment}
\begin{frame}<\nottheirhandout>{What's missing from this picture?}


  \begin{columns}
    \begin{column}{.25\linewidth}
      
    \end{column}
    \begin{column}{.75\linewidth}
        \begin{itemize}
  \item[Comparison Design] 
  \item[Estimation] 
  \item[MOEs] 
  \item[Tests \& CIs] 
  \item[HL estimates] 
  \end{itemize}

    \end{column}
  \end{columns}
\pause

\vfill
Covariance adjustments to enhance precision, of course.
  
\end{frame}

\begin{frame}{Basic varieties of covariance adjustment}
  
  \begin{itemize}
   \item{} {Differences-in-differences}
  
\item {} {Model-assisted covariance adjustment}

  \end{itemize}

\end{frame}

\begin{frame}{Workflow for analyzing experiments/obs studies}
  \framesubtitle{To summarize from earlier units:}

  \begin{columns}
    \begin{column}{.25\linewidth}
      
    \end{column}
    \begin{column}{.75\linewidth}
        \begin{itemize}
  \item[Comparison Design] Specify clustering, pairing or blocking
  \item[Gain scores] Optionally, adjust for lagged measure of the outcome by subtracting it off from the actual outcome.
  \item[Estimation] Optionally, compute unbiased estimate of ATE
  \item[MOEs] Specify models of effect; separately for each, figure $\mathbf{y}_{\mathbf{z}\equiv 0} $ or a summary of it.
  \item[Cov Adj] Optionally, effect model-assisted covariance adjustments
  \item[Tests \& CIs] Select test statistic, perform h-tests (separately for each MOE). Summarize the results with a 95\% CI, maybe also 2/3 CI. 
  \item[HL estimates] Optionally, Hodges-Lehmann estimate
  \end{itemize}

    \end{column}
  \end{columns}
\end{frame}




\end{document}
