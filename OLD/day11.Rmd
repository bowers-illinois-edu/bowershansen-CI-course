---
title: Instruments, Randomization Assessment (Balance), Adjustment for Interpretable Comparisons
date: '`r format(Sys.Date(), "%B %d, %Y")`'
bibliography: refs.bib
fontsize: 10pt
geometry: margin=1in
graphics: yes
biblio-style: authoryear-comp
output:
  beamer_presentation:
    slide_level: 2
    keep_tex: true
    latex_engine: xelatex
    citation_package: biblatex
    includes:
        in_header:
           - defs-all.sty
---


<!-- Make this document using library(rmarkdown); render("exploration1.Rmd") -->
<!--- \input{defs-all} --->


```{r include=FALSE, cache=FALSE}
# Some customization.  You can alter or delete as desired (if you know what you are doing).
# knitr settings to control how R chunks work.

## To make the html file do
## render("exploration1.Rmd",output_format=html_document(fig_retina=FALSE))
## To make the pdf file do
## render("exploration1.Rmd",output_format=pdf_document())

require(knitr)
opts_chunk$set(
  tidy=FALSE,     # display code as typed
  echo=TRUE,
  results='markup',
  strip.white=TRUE,
  fig.path='figs/fig',
  cache=FALSE,
  highlight=TRUE,
  width.cutoff=132,
  size='footnotesize',
  out.width='.9\\textwidth',
  fig.retina=FALSE,
  message=FALSE,
  comment=NA)

if(!file.exists('figs')) dir.create('figs')

options(SweaveHooks=list(fig=function(){
			   par(mar=c(3.5, 3, 1.1, 0),
			       pty="s",
			       mgp=c(1.5,0.5,0),
			       oma=c(0,0,0,0))},
			 echo=function(){options(continue=" ") ##Don't show "+" prompts,
			 options(prompt=" ")
			 }),
	digits=4,
	scipen=8,
	width=132
	)
```

## Today

\begin{enumerate}
  \item Agenda: Introductions; Where are we going?; Weak Instruments (Imbens and Rosenbaum 2005); Randomization
    assessment (Were the covariates balanced? Standards for balance?); Methods
    of adjustment / making the case for interpretability of comparisons /
    ignorability for observational studies.
\item Reading for tomorrow: DOS 8--9, 13.
\item Blalock Lecture tonight on academic publishing -- from editors of
  journals!
\item Questions arising from assignment 2: Benefits of gain scores?; 2SLS
  Intuition?; "Figure 2 sided..." is "Produce 2 sided..."
\end{enumerate}

<!-- \input{announcement-of-the-day.tex} -->
# Strategies for Causal Inference

## Why Causal Inference?

For policy evaluation to answer questions like: "Did this intervention / change / policy work here and
now?"

To assess theoretical claims / explanations: "There are competing
explanations, they have different implications for observation, is there
evidence in favor of these implications? Or against them?" (Explanations can
be about mechanism or laws, and a well-designed observational study or
randomized experiment can help engage with claims made by alternative
explanations, can help isolate the mechanisms behind different explanations
for the same phenomena.)


## Strategies for randomized studies

 - Make the case that randomization worked.
 -  Increase precision with design and test statistics (and even models of effects)
 - Make sure that your estimator is estimating the right thing (i.e. is not biased or at least is consistent)

## Strategies for Adjustment of Observational Studies

 - If you have randomized $Z$ but not $D$, then IV. (Not really an observational study.)
 - Find a discontinuity/A Natural Experiment (RDD: either natural experiment
   or continuous forcing function)
 - Multiple controls (i.e. "Choice as an alternative to control"
   \cite{rosenbaum:1999})
 - "Controlling For"
 - Difference in Differences
 - Matched Stratification (approximating a block-randomized experiment)
 - Matching for pruning (using matching to common support)
 - Best matched subset selection (approximating a completely or simply
   randomized experiment)
 - Weighting
 - Direct theoretical modeling / Directed Acyclic Graphs (DAGS) to guide other
   data modeling choices.


# The precision benefits of a baseline outcome in an experiment

## See Example from the Newspapers Experiment

I expect that the reference distribution for $H_0: y_{iT}=y_{iC}$ will be
narrower with (1) the gain score and (2) using pair-randomized treatment
assignment.

```{r loaddata}
## newsdf<-read.csv("http://jakebowers.org/Data/news.df.csv")
newsdf<-read.csv("data/news.df.csv")
```


## Define functions

```{r results="hide",tidy=TRUE, size='tiny'}
meanDiffTZ <- function(y,z){
    mndiff <- mean(y[z==1]) - mean(y[z==0])
    return(mndiff)
}

pairMeanDiffTZ <- function(y,z,b){
  z <- z[order(b)]
  y <- y[order(b)]
  ydiff <- y[z==1] - y[z==0]
  mean(ydiff)
}

library(randomizr)
newExperimentPair <- function(b){
    block_ra(block_var=b)
}

library(permute)
newExperimentPair2 <- function(z,b){
  how1 <- how(blocks=b)
  z[shuffle(length(z),control=how1)]
}

## could also have used complete_ra() from randomizr or shuffle() from permute
newExperiment <- function(z){
    sample(z)
}
```

## The reference dists

```{r cache=TRUE}
set.seed(12345)
res1 <- replicate(1000,meanDiffTZ(y=newsdf$r,z=newExperiment(newsdf$z)))
res2 <- replicate(1000,meanDiffTZ(y=newsdf$r - newsdf$rpre,z=newExperiment(newsdf$z)))
res3 <- replicate(1000,pairMeanDiffTZ(y=newsdf$r,z=newExperimentPair(newsdf$s),b=newsdf$s))
res4 <- replicate(1000,pairMeanDiffTZ(y=newsdf$r - newsdf$rpre,z=newExperimentPair(newsdf$s),b=newsdf$s))
res5 <- replicate(1000,pairMeanDiffTZ(y=newsdf$r,z=newExperimentPair2(newsdf$z,newsdf$s),b=newsdf$s))
res6 <- replicate(1000,pairMeanDiffTZ(y=newsdf$r - newsdf$rpre,z=newExperimentPair2(newsdf$z,newsdf$s),b=newsdf$s))
```

## The reference dists

```{r}
summary(res1)
summary(res2)
summary(res3)
summary(res4)
```

# Weak Instruments and 2SLS

## See Imbens and Rosenbaum 2005 Table

*Example:* Effect of education on wages ( Angrist and Krueger 1991)
*Design:* Instrument/Treatment is quarter of birth, Actual Treatment/Dose is additional year of
education, Outcome is wages

What is the intuition about how 2SLS focuses attention on the effect of
education **only related to quarter of birth**? [ Z $\rightarrow$ D
$\rightarrow$ Y]

\igrphx{imbensRosenbaum2005table3}

# Balance in controlled and natural experiments

\begin{frame}
\frametitle{The Neyman-Rubin Model for (simple) experiments}
\vfill
This is what randomization ensures:
$$ (\alert<4>{Y_t, Y_c},\alert<2>{X}) \perp \alert<3>{Z} $$
\vfill

I.e., each of $X$, $Y_{c}$ and $Y_{t}$ is balanced (in expectation; modulo sampling variability).

\begin{itemize}
\item In controlled experiments, random assignment warrants this.
\item In natural experiments, justified otherwise, or an article of faith.
\item In an experiment, the $x$es aren't necessary for inference.
\item However, the part with the $x$es has testable consequences.
\end{itemize}

\end{frame}

 \begin{frame}%<1>[label=covbalexptsFr]
 \frametitle{Covariate balance in experiments}
 %\only<2>{\framesubtitle{The importance of comparing it to balance in other experiments}}

\begin{columns}
\begin{column}{.4\linewidth}
\begin{itemize}
\item<1-> \cite{arceneaux:2005}
\item<1-> Kansas City, November 2003
\item<1-> Completely randomized design: 14 precincts $\rightarrow$ Tx; 14 $\rightarrow $ Control.

    \item<1-> Substantively large baseline differences
    \item<2-> Differences not large compared to other assignments from same design.
    \item<2-> $\PP(\chi^{2} > x) = .94$ \cite{hansenbowers2008}.
    \end{itemize}
    \end{column}

\begin{column}{.6\linewidth}
\only<1>{\igrphx{KC-baseline}}
\only<2>{\igrphx{KC-bal+SDs}}
\end{column}
\end{columns}

\end{frame}


```{r}
acorn <- read.csv("data/acorn03.csv", row.names=1)
library(RItools)

xb1 <- xBalance(z ~ v_p2003 + v_m2003 + v_g2002 + v_p2002 + v_m2002 + v_s2001 + 
         v_g2000 + v_p2000 + v_m2000 + v_s1999 + v_m1999 + v_g1998 + 
         v_m1998 + v_s1998 + v_m1997 + v_s1997 + v_g1996 + v_p1996 + 
         v_m1996 + v_s1996 + size, data=acorn, 
         report = 'all')

acorncovs<-c("v_p2003","v_m2003","v_g2002","v_p2002","v_m2002","v_s2001","v_g2000","v_p2000","v_m2000","v_s1999","v_m1999","v_g1998","v_m1998","v_s1998","v_m1997","v_s1997","v_g1996","v_p1996","v_m1996","v_s1996","size")

xb1ds <- xb1$results[,"adj.diff",]
xb1ps <- xb1$results[,"p",]
```

## DeMystifying xBalance

```{r}
d.stat<-function(zz, mm, ss){
  ## this is the d statistic (harmonic mean weighted diff of means statistic) from Hansen and Bowers 2008
  h.fn<-function(n, m){(m*(n-m))/n}
  myssn<-apply(mm, 2, function(x){sum((zz-unsplit(tapply(zz, ss, mean), ss))*x)})
  hs<-tapply(zz, ss, function(z){h.fn(m=sum(z), n=length(z))})
  mywtsum<-sum(hs)
  myadjdiff<-myssn/mywtsum
  return(myadjdiff)
}
```

## Calculate the reference distribution of the d-stat and the $d^2$ stat

```{r nullddist, cache=TRUE}
## For all vectors z \in \Omega get adj.diffs. This is the distribution of the d statistic
d.dist<-replicate(10000, d.stat(sample(acorn$z), acorn[,acorncovs], ss=rep(1,nrow(acorn))))
```

```{r}
obs.d<-d.stat(acorn$z, acorn[, acorncovs], rep(1,nrow(acorn)))
dps <- matrix(NA,nrow=length(obs.d),ncol=1)
for(i in 1:length(obs.d)){
  dps[i,] <- 2*min( mean(d.dist[i,] >= obs.d[i]),mean(d.dist[i,] <= obs.d[i]))
}
## You can compare this to the results from xBalance
round(cbind(dps,xb1ps,obs.d,xb1ds),3)
```

## Calculate the reference distribution of the d-stat and the $d^2$ stat

```{r}
d2.stat <- function(dstats,ddist=NULL,theinvcov=NULL){
  ## d is the vector of d statistics
  ## ddist is the matrix of the null reference distributions of the d statistics
  if(is.null(theinvcov) & !is.null(ddist)){
    as.numeric( t(dstats) %*% solve(cov(t(ddist))) %*% dstats)
  } else {
    as.numeric( t(dstats) %*% theinvcov %*% dstats)
  }
}
```

## Calculate the reference distribution of the d-stat and the $d^2$ stat

```{r}
## The distribution of the d2 statistic arises from the distribution of the d statistics
## Here we have the inverse of the covariance/variance matrix of the d statistics
invCovDDist <- solve(cov(t(d.dist)))
obs.d2<- d2.stat(obs.d,d.dist,invCovDDist)

d2.dist<-apply(d.dist, 2, function(thed){
                 d2.stat(thed,theinvcov=invCovDDist)
         })
## The chi-squared reference distribution only uses a one-sided p-value going in the positive direction
d2p<-mean(d2.dist>=obs.d2)
cbind(obs.d2,d2p)
xb1$overall
```
## Why differences between xBalance and d2?

I suspect that $N=28$ is too small in this case.

```{r out.width=".6\\textwidth"}
## Notice that the distribution of d2.dist is not that close to the
## chi-squared distribution in this case with N=28
par(mfrow=c(1,2))
qqplot(rchisq(10000,df=21),d2.dist)
abline(0,1)

plot(density(d2.dist))
rug(d2.dist)
curve(dchisq(x,df=21),from=0,to=40,add=TRUE,col="grey")
```


# Anything Else?

## Methods for Covariance Adjustment in Experiments

 - See \cite{rosenbaum2002} for the residualization method.

 - See \cite{hansenbowers2009att} for the Peters-Belson method fitting the
covariance adjustment model to the control group.

 - See \cite{lin2013agnostic} for the interaction effect method.

## References
