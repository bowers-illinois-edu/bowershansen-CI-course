\documentclass[12pt]{article}

%\usepackage{epsf,graphicx}
\usepackage[T1]{fontenc}
\usepackage{mathptmx}
\usepackage[top=1in, bottom=1in, right=1in, left=1in]{geometry}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{natbib}
\usepackage{bibentry} %% to do bib in syllabus
\newcommand{\bibverse}[1]{\begin{verse} \bibentry{#1}. \end{verse}}
\usepackage{hyperref}
\usepackage{parskip}
\usepackage{bookmark}
\usepackage{rotating}

\usepackage{setspace}
\setcounter{secnumdepth}{4}

\title{Causal Inference for the Social Sciences}

\input{courseedition} %misnomer, as of now file only carries date
\author{Jake Bowers \thanks{Political Science and Statistics
    Departments, U. of Illinois, Champaign-Urbana; jwbowers@illinois.edu}
\and Ben Hansen \thanks{Statistics Department and Survey Research Center, U. of Michigan, Ann Arbor; ben.hansen@umich.edu} \and Thomas (Tom)
Leavitt \thanks{Political Science Department, Columbia U.; \mbox{tl2624@columbia.edu}}}


\begin{document}

\maketitle
\begin{abstract}
\noindent This course introduces methods and concepts used to infer causal effects from comparisons of intervention and control groups.  We'll use the potential outcomes framework of causality to analyze both randomized and observational studies, distinguishing different forms of random assignment and separating observational studies that involve instruments, discontinuities and other devices, highlighting the interplay of study design for statistical analysis.  Propensity score matching is treated in depth, with explicit instruction in the use of ``optmatch'' and related packages in R; other areas of methodological focus include assessment of covariate balance by specification tests and other methods; inference methods that are a robust to small sample sizes, weak instruments, spillover and interaction effects, heterogeneous treatment effects, and/or misspecification of response surfaces; and omitted variable sensitivity analysis.  %The content is geared specifically toward students and researchers in the social sciences, with examples are drawn from economics, political science, public health, and sociology, among other fields.

The course presupposes knowledge of multiple regression at the level
of the ICPSR course Regression: II, as well as multiple regression
with binary dependent variables (as taught in the ICPSR courses
Regression: III or Maximum Likelihood).  The part of the course presenting matching requires the use of \texttt{R} for computation, but other methods presented in the course are readily implemented either in \texttt{R} or in \texttt{Stata}.
\end{abstract}

% \section{Meetings}

\input{meetings}

\clearpage

\nobibliography*


\section*{Overview}

We may all warn our freshmen that association is not causation, but inferring causation has always been a central aim both for statisticians and for their collaborators. Until recently, however, inference of causation from statistical evidence depended on murky, scarcely attainable requirements; in practice, the weight of casual arguments was largely determined by the scientific authority of the people making them.

Requirements for causal inference become more clear when they are
framed in terms of \emph{potential outcomes}.  This was first done by
Neyman, who in the 1920s used potential outcomes to model agricultural
experiments.  Fisher independently proposed a related but distinct,
ultimately more influential, analysis of experiments in 1935, and a
rich strain of causal analysis developed among his intellectual
progeny.  It clarified the differing requirements for causal inference
with experiments and with observational data, isolating the distinct
contributions required of the statistician and of his disciplinary
collaborators; generated more satisfying methods with which to address
potential confounding due to measured variables; qualitatively and
quantitatively advanced our grasp of unmeasured confounding and its
potential ramifications; furnished statistical methods with which to
eke more out of the strongest study designs, under fewer assumptions;
and articulated principles with which to understand study designs as a
spectrum, rather than a dichotomy between ``good" experiments and
``bad" observational studies. Understanding the methods and outlook of
the school founded by Fisher's student W. G. Cochran will be the
central task of this course.

The course begins by applying the Fisher and Neyman-Rubin approaches to statistical inference for counterfactual causal efffects to randomized experiments, touching on considerations
specific to clustered treatment assignment, ``small'' sample sizes and
treatment effect heterogeneity. The next segment addresses conceptual
and methodogical challenges of applying the same models to analysis of
non-experimental data. This course segment covers ignorability,
selection, ``common support,'' covariate balance, paired comparisons,
optimal matching and propensity scores. A short separate section
introduces another method aiming to identify experiment-like
structures in observational data, namely regression discontinuity,
before a return to experiments.

With these foundations in place, the course's second half adds
conceptual depth and methodological flexibility.
Central topics include instrumental variables and local average
treatment effects, stratified designs with clustering, interference,
omitted variable sensitivity analysis and adapting workhorse
techniques such as multiple regression to the demands of causal
inference.  Over the course of the four weeks the course becomes
progressively less conceptual and more applied with increasing
emphasis on computing strategies in R.

\section*{Administrative}

\subsection*{Textbooks}

The main texts for the course are

\begin{verse} \bibentry{rosenbaum2017} \end{verse}

\begin{verse} \bibentry{rosenbaum2010} \end{verse}

\begin{verse} \bibentry{rosenbaum2002a} \end{verse}

These three textbooks are presented in varying difficulty and we will draw from all three. Although we won't follow these books closely, their goals and methods align with the course's, and they will be useful as references and supplements.

Other texts that we draw on include

\begin{verse} \bibentry{gerbergreen2012}  \end{verse}

\begin{verse} \bibentry{imbensrubin2015} \end{verse}

% If you'll be using experiments, propensity scores, regression
% discontinuity, or instrumental variables in your work, then each of
% these is a worthwhile investment.

%Several other graduate-level monographs focus or touch
%on causal inference.  Texts that we've found to contain helpful
%discussion include:

%\begin{verse}

%\bibentry{angristpischke2008}

%\bibentry{aronowmiller2019}

%\bibentry{berk2004}

%\bibentry{gelmanhill2006}

%\bibentry{morganwinship2015}

%\bibentry{murnanewillett2010}

%\bibentry{dunning2012}

%\end{verse}

Other readings will be assigned and distributed electronically.

If you're new to \texttt{R}, we suggest getting a hold of:

\begin{verse} \bibentry{fox2016}  \end{verse}

\begin{verse} \bibentry{wickhamgrolemund2017} \end{verse}

\texttt{R} software will be required for several specific segments of the course. With some independent effort, students not familiar with \texttt{R} in advance should be able to learn enough \texttt{R} during the course to complete these assignments. We also recommend some work with \texttt{R} --- for example, via working through some online \texttt{R} courses --- before the course for students who have never used it before.


\subsection*{Assignments}
%Computer or pencil and paper exercises will be assigned periodically and collected on Mondays and on Thursdays at the beginning of class.
Assignments are due each Tuesday, at the beginning of
class. Parts of the assignment will be given at the beginning of the
week, but other parts will be given during class, over the course of
the week.  Many of these daily assignments will be given with the
expectation that they'll be completed by the next course meeting,
although they'll only be collected at the end of the week.
Late homework will not be accepted without cause (or prior arrangement
with the teaching assistant).

You're welcome to submit a paper at the end of the course, whether or not you're taking the course for credit.  In that case we'll return it with comments within a month or so of the course's completion.  (If you're taking the course for a grade, the paper won't contribute to the grade unless you're on the borderline between two grades.)

Participation is expected. It can take various forms:
\begin{enumerate}
\item Doing in-class exercises and discussing them with your peers;
\item From time to time, making a clarification or raising a clarifying questions;
\item \label{it:part0} Contributing to in-class discussions.
%\item \label{it:part0} Using a github pull request to suggest a clarification or other enhancement to a course slide or worksheet.
\item \label{it:part1} Drop by one of the professor's office hours to share a point that you \textit{and at least one classmate} would like to have clarified or amplified, or to point out a connection to your field;
%\item \label{it:part2} Give a 5-10 minute in-class presentation of a paper in your field that uses methods or designs we're discussing in the course.
\end{enumerate}
If you are taking the course for a grade, make a point of doing at
least one of \ref{it:part0} and \ref{it:part1}. %and \ref{it:part2}.  There'll be an electronic sign-up for \ref{it:part2}.

% Course participants will be expected either to give a presentation or to submit a short paper about assigned readings related to their fields of study.  Presentations will be given alone or in pairs, and last 10-20 minutes; short papers should be 5-8 pages long.  Students must decide no later than the end of the second week whether theyâ€™ll present or submit a paper, and on what topic; presentations will be given at times designated by the instructor, whereas papers must be submitted by the beginning of the fourth week.

\section*{Course Schedule}\label{sec:schedule}

The course schedule is below. In the Course content section, we provide more extensive readings on each topic in the schedule, as well as additional ``special topics.'' The last two days of the course are reserved for special topics chosen by students.

\begin{table}[!htbp]
\centering
\resizebox{\textwidth}{!}{\begin{tabular}{|l|l|l|l|l|}
\hline
\textbf{Date} & \textbf{Instructor} & \textbf{Topic} & \textbf{Required readings} & \textbf{Application} \\ \hline
July 19 & Ben Hansen & Introduction & \begin{tabular}{@{}c@{}} Holland (1986) \\Kinder and Palfrey (1993, Section 1.2) \\ Fisher (1935, Introduction) \\ Rosenbaum (2017, Chapter 2) \end{tabular} & N/A \\ \cline{1-5}
July 20 & \multirow{2}{*}{Tom Leavitt} & \multirow{2}{*}{Randomized experiments: Neymanian Estimation and inference} & \begin{tabular}{@{}c@{}} Gerber and Green (2012, Chapter 2) \\ Aronow and Middleton (2013) \\ Middleton and Aronow (2015) \\ Gerber and Green (2012, pp. 51 -- 61) \end{tabular} & \multirow{5}{*}{Arceneaux (2005)} \\ \cline{1-1}
July 21 &  &  & \begin{tabular}{@{}c@{}} \end{tabular} & ~ \\ \cline{1-4}
July 22 & Tom Leavitt & Randomized experiments: Fisherian inference & \begin{tabular}{@{}c@{}} Rosenbaum (2017, Chapter 3) \end{tabular} & ~ \\ \cline{1-4}
July 23 & Tom Leavitt & Randomized Experiments: Covariance adjustment \& regression & \begin{tabular}{@{}c@{}} Gerber and Green (2012, Chapter 4) \\ Rosenbaum (2002) \\ Lin (2013) \end{tabular} & ~ \\ \hline
July 26 & Ben Hansen & \multirow{2}{*}{Randomized experiments: Noncompliance and attrition} & \begin{tabular}{@{}c@{}} Gerber and Green (2012, Chapters 5 -- 6) \end{tabular} & \multirow{2}{*}{Albertson and Lawrence (2009)} \\ \cline{1-2}
July 27 (HW 1 due) & Jake Bowers &  & \begin{tabular}{@{}c@{}} Rosenbaum (1996) \\ Rosenbaum (2010, Section 5.3) \end{tabular} & ~ \\ \hline
July 28 & Jake Bowers & Observational studies: Introduction & \begin{tabular}{@{}c@{}} Bind and Rubin (2019) \\ Gelman and Hill (2006, Sections 9.0 -- 9.2) \\ Berk (2010) \end{tabular} & \multirow{6}{*}{Cerd\'{a} et al (2012)} \\ \cline{1-4}
July 29 & Jake Bowers & Introduction to matching & \begin{tabular}{@{}c@{}} Rosenbaum (2017, pp. 65 -- 90) \end{tabular} & ~ \\ \cline{1-4}
August 2 & Jake Bowers & Nuts \& bolts of matching & \begin{tabular}{@{}c@{}} Rosenbaum (2010, Chapters 7 -- 8) \\ Rosenbaum (2017, Chapter 11) \end{tabular} & ~ \\ \cline{1-4}
July 30 & Jake Bowers & Propensity score methods & \begin{tabular}{@{}c@{}} Rosenbaum (2017, pp. 90 -- 96) \\ Hansen (2011) \end{tabular} & ~ \\ \cline{1-4}
August 3 (HW 2 due) & Jake Bowers & Assessments of covariate balance & \multirow{2}{*}{\begin{tabular}{@{}c@{}} Hansen and Bowers (2008) \\ Gerber and Green (2021, pp. 71 -- 79) \end{tabular}} & ~ \\ \cline{1-3}
August 4 & Jake Bowers & Outcome analysis after matching & & ~ \\ \hline
August 5 & Jake Bowers & Nonbipartite matching & \begin{tabular}{@{}c@{}} Rosenbaum (2010, Chapter 11) \end{tabular} & Wong et al (2012, 2020) \\ \hline
August 6 & Jake Bowers & Regression discontinuity designs and ``natural experiments'' & \begin{tabular}{@{}c@{}}
Cattaneo, Titiunik, and Vazquez-Bare (2020) \\ Keele, Titiunik and Zubizarreta (2015) \\ Sales and Hansen (2020) \end{tabular} & Caughey and Sekon (2011) \\ \hline
August 9 & Tom Leavitt & Fisherian sensitivity analysis & \begin{tabular}{@{}c@{}}
Rosenbaum (2017, Chapter 9) \end{tabular} & \multirow{2}{*}{Cerd\'{a} et al (2012)} \\ \cline{1-4}
August 10 (HW 3 due) & Tom Leavitt & Neymanian sensitivity analysis & \begin{tabular}{@{}c@{}}
Fogarty (2020) \end{tabular} & ~ \\ \hline
August 11 & Jake or Tom & Special topics & TBD & TBD \\ \hline
August 12 & Jake or Tom & Special topics & TBD & TBD \\\hline
\hline
\end{tabular}}
\end{table}

\newpage
\section*{Course content}

\section{Potential outcomes and random assignment}

%Medical- and social-science data generating processes can be difficult to capture accurately in a single regression equation, for various reasons. The statistical foundations of randomized experiments are much more satisfying, particularly when they are taken on their own terms. Fisher and Neyman did this earlier in the 1920s and 30s, in work that Rubin, Holland and others reinvigorated beginning in the 1970s. The course begins by surveying the circle of ideas to emerge from this.

\paragraph*{Required}

\begin{verse}\bibentry{holland1986}, Sections~1 -- 4. (The article that brought the ``Rubin Causal Model'' to  statisticians' attention.)\end{verse}

\begin{verse} Section~1.2, ``Experimentation defined,''  of
\bibentry{kinderpalfrey1993}.  (Particularly pp. 5 -- 10.) \end{verse}

\begin{verse} \bibentry{rosenbaum2017}, Chapter 2. \end{verse}

\begin{verse} Chapter~1, ``Introduction,'' of \bibentry {fisher1935a} and pages 131 -- 135 of \bibentry{box1978} for historical context. \end{verse}

\paragraph*{Recommended}

\begin{verse} \bibentry{bowersleavitt2020} \end{verse}

\section{Random assignment as a basis for inference}

\subsection*{Application}

\begin{verse} \bibentry{arceneaux2005} \end{verse}

\subsection{Inference for causal effects: the Neyman tradition}

\subsubsection{Estimation of average causal effects}

\paragraph*{Required}

\begin{verse} Chapter~2 and pp. 51 -- 61 of \bibentry{gerbergreen2012} \end{verse}
\begin{verse} \bibentry{aronowmiddleton2013} \end{verse}
\begin{verse} \bibentry{middletonaronow2015} \end{verse}

\subsubsection{Variance estimation and hypothesis testing}

\paragraph*{Required}

\begin{verse}
  Chapter~3 of \bibentry{gerbergreen2012}.
\end{verse}

\begin{verse} Endnote spanning pages A-32 and 33,
  \bibentry{freedmanpisanipurves1998}.  (This can be read as a pr{\'e}cis
  of: \bibentry{neyman1990}.)
\end{verse}

\begin{verse} Chapter 6, pp. 87 -- 98 of \bibentry{imbensrubin2015} \end{verse}

\paragraph*{Recommended}

\begin{verse} Chapter~6 of \bibentry{dunning2012} \end{verse}

\begin{verse} \bibentry{liding2017} \end{verse}

\begin{verse} \bibentry{ding2017a} \end{verse}

\begin{verse} \bibentry{aronowetal2014} \end{verse}

\subsection{Inference for causal effects: the Fisherian tradition}

\paragraph*{Required}

\begin{verse}
  Chapter 3 of \bibentry{rosenbaum2017}.
\end{verse}

\paragraph*{Recommended}

\begin{verse}
  Pages 27 -- 49 of \bibentry{rosenbaum2002a}
\end{verse}

\begin{verse}
  Chapter 2 of \bibentry{rosenbaum2010}.
\end{verse}

\subsection{Covariance adjustment in randomized experiments}

\paragraph*{Required}

\begin{verse}
  Chapter~4 of \bibentry{gerbergreen2012}.
\end{verse}

\begin{verse}
  \bibentry{rosenbaum2002c}.
\end{verse}

\begin{verse} \bibentry{lin2013} \end{verse}

\paragraph*{Recommended}

\begin{verse} \bibentry{miratrixetal2013} \end{verse}

\begin{verse} \bibentry{freedman2008a} \end{verse}

\begin{verse} \bibentry{freedman2008b} \end{verse}

\begin{verse} \bibentry{freedman2008c} \end{verse}

%\begin{verse} \bibentry{samiiaronow2012} \end{verse}

\begin{verse} \bibentry{abadieetal2020} \end{verse}

\section{Noncompliance and Attrition}

\subsection*{Applications}

\begin{verse} \bibentry{albertsonlawrence2009} \end{verse}

\subsection{Noncompliance and instrumental variables}

\paragraph*{Required}

\begin{verse} Chapters 5 and 6 of \bibentry{gerbergreen2012}. \end{verse}

\begin{verse}
  Section 5.3, ``Instruments,'' of \bibentry{rosenbaum2010} \end{verse}

\begin{verse}
\bibentry{rosenbaum1996} \end{verse}

\paragraph*{Recommended}

\begin{verse} Section 2.3 of \bibentry{rosenbaum2002c} \end{verse}

\begin{verse} \bibentry{angristetal1996} \end{verse}

\begin{verse} \bibentry{imbensrosenbaum2005} \end{verse}

\begin{verse} \bibentry{kangpeckkeele2018} \end{verse}

\begin{verse} \bibentry{hansenbowers2008} \end{verse}

\subsection{Attrition, or missing outcomes}

\paragraph*{Recommended}

\begin{verse} Chapter 7 of \bibentry{gerbergreen2012} \end{verse}

\begin{verse} \bibentry{lee2009} \end{verse}

\begin{verse} \bibentry{horowitzmanski2000} \end{verse}

\section{Observational Studies}

\subsection{Introduction:  ``Controlling for'' in observational studies}

\paragraph*{Required}

\begin{verse} \bibentry{bindrubin2019} \end{verse}

\begin{verse} Sections 9.0 -- 9.2 (especially discussion of interpolation and extrapolation) of \bibentry{gelmanhill2006} \end{verse}

\bibverse{berk2010}

\paragraph*{Recommended}

\begin{verse} Chapter 5 of \bibentry{rosenbaum2017} \end{verse}

\begin{verse} \bibentry{cochran1965} \end{verse}

\begin{verse} On the problem of kitchen sink regressions, \bibentry{achen2002} \end{verse}

\begin{verse} Chapters 11 and Chap 19 (on overly influential points) of \bibentry{fox2016} \end{verse}

\subsection{Matching: An introduction}

\subsection*{Application}

\begin{verse} \bibentry{cerdaetal2012} \end{verse}

\paragraph*{Required}

\begin{verse}
  Pages 65 -- 90 of \bibentry{rosenbaum2017}
\end{verse}

\paragraph*{Recommended}

\begin{verse}
  Chapter 3 of \bibentry{rosenbaum2002a}, specifically Sections 3.1 -- 3.2 and 3.4 -- 3.5.
\end{verse}

\begin{verse} \bibentry{rosenbaum2001d} \end{verse}

\subsection{Nuts \& bolts of matching}

\paragraph*{Required}

\begin{verse}
  Chapters 7 -- 8 of \bibentry{rosenbaum2010}, 
\end{verse}

\begin{verse}
  Chapter 11 \bibentry{rosenbaum2017}, 
\end{verse}

\subsection{Propensity scores methods}

\paragraph*{Required}

\begin{verse} Pages 90 -- 96 of \bibentry{rosenbaum2017} \end{verse}

\begin{verse}
  \bibentry{hansen2011}
\end{verse}

\paragraph*{Recommended}

\begin{verse}
  \bibentry{rubin1979}
\end{verse}

\bibverse{hoetal2007}

\bibverse{bifulco2012}

\bibverse{arceneauxetal2010}

\begin{verse}
  Chapters 13 of \bibentry{rosenbaum2010}
\end{verse}

\begin{verse}
  \bibentry{rosenbaumrubin1985}
\end{verse}


\subsection{Covariate balance and outcome analysis after matching}

\paragraph*{Required}

\begin{verse}
  \bibentry{hansenbowers2008}
\end{verse}

\begin{verse}
 Pages 71 -- 79 of \bibentry{gerbergreen2012}
\end{verse}

\paragraph*{Recommended}

\begin{verse}
  \bibentry{fogarty2018a}
\end{verse}

\begin{verse}
  \bibentry{pashleymiratrix2020}
\end{verse}

\begin{verse}
  \bibentry{imai2008a}
\end{verse}

\subsection{Nonbipartite matching}

\subsection*{Applications}

\begin{verse} \bibentry{wongetal2012b} \end{verse}

\begin{verse} \bibentry{wongetal2020} \end{verse}

\paragraph*{Required}

\begin{verse} Chapter 11 of \bibentry{rosenbaum2010} \end{verse}

\paragraph*{Recommended}

\begin{verse} \bibentry{luetal2001} \end{verse}

\begin{verse} Chapter 11 of \bibentry{rosenbaum2010} \end{verse}

\begin{verse} \bibentry{luetal2011} \end{verse}

\begin{verse} \bibentry{baiocchietal2010} \end{verse}

\subsection{Regression discontinuity designs and ``natural experiments''}

\subsection*{Application}

\begin{verse} \bibentry{caugheysekhon2011} \end{verse}

\paragraph*{Required}

\begin{verse} \bibentry{cattaneoetal2020} \end{verse}

\begin{verse} \bibentry{saleshansen2020} \end{verse}

\begin{verse} \bibentry{keeletitiunikzubizarreta2015} \end{verse}

\paragraph*{Recommended}

\begin{verse} \bibentry{hahnetal2001} \end{verse}

\begin{verse} Chapter 6 of \bibentry{angristpischke2008} \end{verse}

\section{Sensitivity analysis}

\subsection*{Application}

\begin{verse} \bibentry{cerdaetal2012} \end{verse}

\subsection{Sensitivity analysis for sharp nulls}

\paragraph*{Required}

\begin{verse} Chapter 4 of \bibentry{rosenbaum2002a} \end{verse}

\begin{verse} \bibentry{rosenbaum2018} \end{verse}

\paragraph*{Recommended}

\begin{verse} \bibentry{rosenbaumkrieger1990} \end{verse}

\begin{verse} \bibentry{hansenrosenbaumsmall2014} \end{verse}

\subsection{Sensitivity analysis for weak nulls}

\paragraph*{Required}

\begin{verse} \bibentry{fogarty2020a} \end{verse}

\paragraph*{Recommended}

\begin{verse} \bibentry{fogarty2020b} \end{verse}

\begin{verse} \bibentry{fogartyetal2017} \end{verse}

\section{Additional topics}

\subsection{Regression-based sensitivity analysis}

\bibverse{hosmanetal2010}

\bibverse{cinellihazlett2020}

\bibverse{imbens2003}

\bibverse{oster2019}

\subsection{Difference-in-Differences}

\begin{verse} Pages 162 -- 167 of \bibentry{rosenbaum2017} \end{verse}

\begin{verse} Section 4.1 of \bibentry{gerbergreen2012} \end{verse}

\begin{verse} Chapter 5 of \bibentry{angristpischke2008} \end{verse}

\begin{verse} \bibentry{manskipepper2018} \end{verse}

\subsection{Factorial and complex experiments}

\begin{verse} \bibentry{dasguptaetal2015} \end{verse}

\begin{verse} \bibentry{hainmuelleretal2014} \end{verse}

\begin{verse} \bibentry{egamiimai2019} \end{verse}

\begin{verse} \bibentry{bailey2017} \end{verse}

\subsection{External validity}

\begin{verse} \bibentry{kernetal2016} \end{verse}

\begin{verse} \bibentry{miratrixetal2018a} \end{verse}

\begin{verse} \bibentry{bennettetal2020} \end{verse}

\begin{verse} \bibentry{silberetal2014} \end{verse}

\subsection{Interference}

\bibverse{rosenbaum2007a}

\bibverse{bowersetal2013}

\bibverse{aronowsamii2017}

\bibverse{manski2013b}

\bibverse{atheyetal2018}

\subsection{Attributable effects and random causal effects}

\begin{verse} \bibentry{rosenbaum2001a} \end{verse}

\begin{verse} \bibentry{hansenbowers2009} \end{verse}

\begin{verse} \bibentry{sekhonshem-tov2021} \end{verse}

\begin{verse} \bibentry{keeleetal2017} \end{verse}

\subsection{Bayesian causal inference}

\begin{verse} \bibentry{rubin1978a} \end{verse}

\begin{verse} Chapter 8 of \bibentry{imbensrubin2015} \end{verse}

\begin{verse} \bibentry{imbensrubin1997} \end{verse}

\begin{verse} \bibentry{keelequinn2017} \end{verse}

\begin{verse} \bibentry{dingmiratrix2019} \end{verse}

\clearpage


%\section{Additional Notes}
\clearpage
\bibliographystyle{plain}
\nobibliography{bib_2021}
%\nobibliography{master,abbrev_long,causalinference,biomedicalapplications,misc}
%\nobibliography{../2013/BIB/master,../2013/BIB/abbrev_long,../2013/BIB/causalinference,../2013/BIB/biomedicalapplications,../2013/BIB/misc}
%"master" is Ryan Moore's file (as of summer 2012).
%"causalinference" is Ben's, and lives (as of summer 2013) in
% http://dept.stat.lsa.umich.edu/~bbh/texmf/bibtex/bib/


\end{document}
