\documentclass{article}
%\usepackage{natbib}

\title{P-values under a strong null hypothesis}
\author{ICPSR Causal Inference}
\usepackage{icpsr-classwork}

\begin{document}
\SweaveOpts{concordance=TRUE}
\maketitle

\section{Two ways to read in data}
Two running examples: The results of our coffee experiment, and data from \cite{arceneaux:2005}.

To read in data%
\footnote{This is a recommended way to type in small data sets in interactive sessions, but it (specifically, \texttt{scan()}) doesn't work in scripts.  To see how this script actually assembled the data, check out the source code, at \url{https://github.com/bowers-illinois-edu/bowershansen-CI-course}.}
from the coffee experiment:
\begin{verbatim}
> z = scan(nlines=1)
1 1 1 1 0 0 0 0
> y = scan(nlines=1)
1 1 1 1 0 0 0 0
> coffee = data.frame(z, y)
\end{verbatim}

<<echo=FALSE>>=
coffee = data.frame(z=rep(1:0, each=4), y=rep(1:0, each=4))
## same result as
## coffee = data.frame(z=c(1,1,1,1,0,0,0,0),
##                     y=c(1,1,1,1,0,0,0,0) )
## but with a little less risk of data entry error
@ 
<<>>=
table(coffee)
@


Here is the Acorn GOTV experiment data described in Arceneaux (2005),
after aggregation to the precinct level.
<<>>=
acorn = read.csv("data/acorn03.csv")
@

\section{Test statistics for the coffee experiment}

Fisher's test statistic, the number of focal-group cups that were
correctly identified as belong to the focal group, is $Z'y = \sum_{i}
Z_{i} y_{i}$.  Under the null hypothesis, $y$ is a vector of
constants.  Due to the random assigment, $Z$ is a random vector,
equally likely come out as any length-8 binary sequence containing 4 ones.   The
realization of $Z$ that was obtained in the experiment is denoted $z$,
and the sampled test statistic is $z'y$.  It is computed as
<<>>=
with(coffee, sum(z*y))
@
or, to use an R function mirroring our notation,
<<>>=
with(coffee, crossprod(z, y)) # beware: crossprod() return a **matrix** (of dim (1,1))
with(coffee, crossprod(z, y)[1,1]) #to return a length-1 vector instead
@

Other test statistics are also possible.  For example, the proportion
of the focal-group cups that were correctly identified is
$Z'y/n_1$, where $n_{1}$ is the design constant $\sum_{i} Z_{i}$, here
4.  In our experiment it took
the value
<<>>=
with(coffee, sum(z*y)/sum(z))
@

Yet another possibility would be the difference in proportions of
focal and non-focal group cups that were identified as being in the
focal group, $Z'y/n_{1} - Z'y/n_{0}$, where $n_{0}= \sum_{i} 1- Z_{i} =4$:
<<>>=
with(coffee, sum(z*y)/sum(z) - sum((1-z)*y)/sum(1-z))
@
which can be calculated more simply via
<<>>=
lm(y ~ z, data=coffee)
coef(lm(y ~ z, data=coffee))[2]
@
(The "[2]" picks out the second of the two coefficients reported.)

Assuming that the test statistic $T$ has been defined in such a way that
larger values are more favorable to the proposition we're out to get
evidence for, the $p$ value is $\mathrm{P}(T \geq t)$, where $t$ is
the value of $T$ that was actually obtained.  (This is a one-sided
p-value, the kind Fisher liked.  If you prefer the other kind, it's recommended that you get the
hang of his way of doing things before going back to translate.)

\subsection{Approximate p-values by simulation}

To simulate from the null distribution of a test statistic, use
\texttt{sample} to randomly permute $z$.

<<>>=
with(coffee, sum(z*y))
with(coffee, sum(sample(z)*y))
with(coffee, sum(sample(z)*y))
with(coffee, replicate(3, sum(sample(z)*y)))
simT = with(coffee, replicate(1000, sum(sample(z)*y)))

@

This says that the null distribution of $T = Z'y$ can be approximated as
<<>>=
round(table(simT)/1000, 2)
@

To calculate the corresponding approximate, one-sided p-value, $\mathrm{Pr}(T\geq a)$, at the command line, do
<<>>=
actualT = with(coffee, sum(z*y))
mean( simT >= actualT )
@
%The analogous two-sided p-value, following the general definition of
%the two-sided p-value as $2\min\big( \mathrm{Pr}(T\leq a),
%\mathrm{Pr}(T\geq a) \big)$, is 
<<eval=false, echo=false>>=
2*min( mean( simT <= actualT ), mean( simT >= actualT ) )
@ 
With $N$ simulations, the error of approximation for a quantities of the form $P(T \geq a)$
can itself be approximated as $1/\sqrt{N}$: in this case,
\Sexpr{round(1/sqrt(1000), 2)}.  So the simulation approximation to
our one-sided $p$-value is \Sexpr{sum(simT==4)/1000} $\pm$ \Sexpr{round(1/sqrt(1000), 2)}.

\textbf{Exercise:} Replicate this analysis for yourself, but using a different choice of $N$ (and if you like, a different test statistic). 

\subsection{Exact p-values}

The handout from unit 1 presents a table that visually presents all of the ${8 \choose 4} = 70
$ ways to order the binary sequence \Sexpr{rep(1:0, each=4)}.  You can do
this computation in R, but it's dangerous\footnote{Because ${2m \choose m}$ grows exponentially in $m$. With large $m$, attempting to list all of the permutations will choke up your
computer.  For small $m$, no problem; but drawing the line between large and small is tricky and non-intuitive.}, so I'm not going to say how here.

In the \textit{special case} of \textit{binary} outcomes, many software routines will have dedicated routines, under labels ``Fisher's exact test'' and/or ``hypergeometric distribution''.  

\texttt{Exercise.}\\  \newcounter{saveenumi}
\begin{enumerate}
\item Confirm to your own satisfaction that for analysis of the coffee experiment, the simulation method can approximate the exact, permutation-based calculation to as much accuracy as is practically meaningful.
\item How about the chi-square test, are you approximating that also?
\item For this data set, are the chi-square test and the fisher test both admissible? (Hint: read R's warnings, and try to remember the conditions for the chi-square test for two-way tables.) \setcounter{saveenumi}{\value{enumi}}
\end{enumerate}

Code hints:
\begin{verbatim}
with(coffee, fisher.test(z, y))
with(coffee, chisq.test(z, y))
\end{verbatim}


\section{A GOTV experiment}

Arceneaux (2005) presents a get-out-the-vote experiment that was
randomized at the precinct level.  As in the coffee experiment, it's a
completely randomized design: a predetermined number (14) of precincts
were randomized to treatment, with the remaining precincts (also 14)
randomized to control.  Provided that we can summarize the voting
outcome for each precinct in a single number, we can follow Fisher's
template exactly to attach a $p$-value to the proposition that the
GOTV campaign was inefficacious.

\subsection{Adapting the Fisher test to a continuous outcome}
First, we'll take as our one-number summary of precinct level turnout 
the proportion of registered voters in the precinct who
actually voted.  
<<>>=
head(subset(acorn, select=c(unit,size,z, vote03)),3)
@

Our test statistic could be the sum of these $y$s in the treatment group. Or, equivalently for the purposes of the test, the average of turnout proportions among
precincts assigned to treatment.
<<>>=
with(acorn, sum(z * vote03)/14)
@
(as there were 14 treatment precincts).

An ostensibly different test statistic is the difference in mean turnout proportions
between treatment and control precincts.  

<<>>=
coef(lm(vote03~z, data=acorn))[2]
@


Either choice gives a test statistic $T$ that tends to take larger values if GOTV positively effects voter turnout. So in both cases the appropriate one-sided p-value is $\mathrm{P}_0(T \geq t)$, where $t$ is the observed value of $T$ and $ \mathrm{P}_0(\cdot)$ indicates probability under the hypothesis of no effect.

\textbf{Exercises.}
\begin{enumerate} \setcounter{enumi}{\value{saveenumi}}
\item Pick one of these test statistics, and analyze to obtain a one-sided p-value.  Argue either from first principles or by simulation that using the other one for your test gives the same p-value. 
\item If there were concern that the treatment may have negatively affected the outcome, then a two-sided p-value might be more appropriate. (Another reason to prefer a two-sided p-value would be if one were preparing a research paper for an audience accustomed to two-sided p-values.)  Write a mathematical expression of the form $\mathrm{P}_0$([statement involving $T$]) that uniquely specifies the two-sided p-value. (Note: for some test statistics there may be more than one valid way of construing the two-sided p-value, not necessarily giving precisely the same answers.)
\item Report your two-sided p-value.  \setcounter{saveenumi}{\value{enumi}}
\end{enumerate}



\subsection{Some basic refinements of the test statistic}

Our test statistic doesn't take into account the different sizes of the precincts.  Giving more weight to the large precincts might engender a more powerful test. 

<<>>=
coef(lm(vote03~z, weights=size, data=acorn))[2]
@

The coefficient reported is equivalent to the difference between overall voting rates in treatment and control precincts.  (How is this different from what we got without weighting?)  So maybe it's preferable to the unweighted version in terms of interpretability.  For now, however, we're considering this as a test statistic only, so the reason to prefer it is if we think it'll give us more power to reject a null that happens to be false..

Outliers can cut into the power%
\footnote{They don't undercut its assumptions, as they would the assumption of Normally distributed errors; only power is affected. See \textit{Design of Observational Studies}, \S 2.3.} 
of a randomization test.  
The \texttt{vote03} proportions do appear to contain an outlier:
<<>>=
with(acorn, stem(vote03))
@ 

One way to address this is to use a test statistic based on ranks of the outcome observations:
<<>>=
with(acorn, sum(z * rank(vote03))/14)
@ 

This is a ``rank sum test.'' Rosenbaum likes tests based on ranks. \textit{Design of Observational Studies} features the ``Wilcoxon signed rank test,'' a first cousin of the rank sum test that's adapted to paired data. 

Another approach to the same problem is to use a robust regression routine. 
<<>>=
library(MASS)
coef(rlm(vote03~z, data=acorn))[2]
@

Robust regression (as opposed to the ranking approach) makes it easier to see how to  accommodate weights:
<<>>=

coef(rlm(vote03~z, weights=size, data=acorn))[2]
@

\textbf{Exercises.}
\begin{enumerate} \setcounter{enumi}{\value{saveenumi}}
\item Select (or design) a test statistic addressing both the different sizes of the precinct and the possibility that there may be outlier.  Explain your choice.
\item Use this new and improved test statistic to test the hypothesis of no effect. Comment briefly on the differences, if any, between this p-value and the one you obtained earlier.
\end{enumerate}
\bibliographystyle{plain}
%% \bibliography{../../2013/BIB/master,../../2013/BIB/abbrev_long,../../2013/BIB/causalinference,../../2013/BIB/biomedicalapplications,../../2013/BIB/misc}
\begin{thebibliography}{1}

\bibitem{arceneaux:2005}
Kevin Arceneaux.
\newblock Using cluster randomized field experiments to study voting behavior.
\newblock {\em Annals of the Americal Academy of Political and Social Science},
  601:169--179, September 2005.

\end{thebibliography}
% "master" is Ryan Moore's file (as of summer 2012).
%"causalinference" is Ben's, and lives (as of summer 2013) in
% http://dept.stat.lsa.umich.edu/~bbh/texmf/bibtex/bib/
\end{document}
