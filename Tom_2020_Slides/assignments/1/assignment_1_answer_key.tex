% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  12pt,
  leqno]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Assignment 1 Answer Key},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin = 1.5cm]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% \usepackage{microtype} %
% \usepackage{setspace}
% \onehalfspacing
\usepackage{xcolor, color, ucs}     % http://ctan.org/pkg/xcolor
\usepackage{natbib}
\usepackage{booktabs}          % package for thick lines in tables
\usepackage{amsfonts,amsthm,amsmath,amssymb,bm}          % AMS Fonts
% \usepackage{empheq}            % To use left brace on {align} environment
\usepackage{graphicx}          % Insert .pdf, .eps or .png
\usepackage{enumitem}          % http://ctan.org/pkg/enumitem
% \usepackage[mathscr]{euscript}          % Font for right expectation sign
\usepackage{tabularx}          % Get scale boxes for tables
\usepackage{float}             % Force floats around
\usepackage{rotating}          % Rotate long tables horizontally
\usepackage{bbm}                % for bold betas
\usepackage{csquotes}           % \enquote{} and \textquote[][]{} environments
\usepackage{subfigure}
\usepackage{array}
% \usepackage{cancel}
\usepackage{longtable}
% % \usepackage{lmodern}
% % \usepackage{libertine} \usepackage[libertine]{newtxmath}
% \usepackage{stix}
% % \usepackage[osf,sc]{mathpazo}     % alternative math
% \usepackage[T1]{fontenc}
% \usepackage{fontspec}
% \setmainfont{Times New Roman}
% \usepackage{mathtools}          % multlined environment with size option
% \usepackage{verbatim}
% \usepackage{geometry}
% \usepackage{bigfoot}
% \geometry{verbose,margin=.8in,nomarginpar}
% \setcounter{secnumdepth}{2}
% \setcounter{tocdepth}{2}
% \usepackage{lscape}

\setlist{nosep}


% \usepackage{url}
% \usepackage[nobreak=true]{mdframed} % put box around section with \begin{mdframed}\end{mdframed}

% \usepackage{relsize}            % \mathlarger{} environment
% \usepackage[unicode=true,
%             pdfusetitle,
%             bookmarks=true,
%             bookmarksnumbered=true,
%             bookmarksopen=true,
%             bookmarksopenlevel=2,
%             breaklinks=false,
%             pdfborder={0 0 1},
%             backref=false,
%             colorlinks=true,
%             hypertexnames=false]{hyperref}
% \hypersetup{pdfstartview={XYZ null null 1},
%             citecolor=blue!50,
%             linkcolor=red,
%             urlcolor=green!70!black}

\usepackage{multirow}
% \usepackage{tikz}
% \usetikzlibrary{trees, positioning, arrows, automata}

% \tikzset{
%   treenode/.style = {align=center, inner sep=0pt, text centered,
%     font=\sffamily},
%   arn_n/.style = {treenode, rectangle, black, fill=white, text width=6em},
%   arn_r/.style = {treenode, circle, red, draw=red, text width=1.5em, thick}
% }

\usepackage[noabbrev]{cleveref} % Should be loaded after \usepackage{hyperref}
\usepackage[small,bf]{caption}  % Captions

% \usepackage[obeyFinal,textwidth=0.8in, colorinlistoftodos,prependcaption,textsize=tiny]{todonotes} % \fxnote*[options]{note}{text} to make sticky notes
% \usepackage{xargs}
% \newcommandx{\unsure}[2][1=]{\todo[linecolor=red,backgroundcolor=red!25,bordercolor=red,#1]{#2}}
% \newcommandx{\change}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=blue,#1]{#2}}
% \newcommandx{\info}[2][1=]{\todo[linecolor=OliveGreen,backgroundcolor=OliveGreen!25,bordercolor=OliveGreen,#1]{#2}}
% \newcommandx{\improvement}[2][1=]{\todo[linecolor=Plum,backgroundcolor=Plum!25,bordercolor=Plum,#1]{#2}}

\parskip=8pt
\parindent=0pt
\delimitershortfall=-1pt
\interfootnotelinepenalty=100000

\newcommand{\qedknitr}{\hfill\rule{1.2ex}{1.2ex}}

% \makeatletter
% \def\thm@space@setup{\thm@preskip=0pt
% \thm@postskip=0pt}
% \makeatother

\def\tightlist{}

\makeatletter
% align all math after the command
\newcommand{\mathleft}{\@fleqntrue\@mathmargin\parindent}
\newcommand{\mathcenter}{\@fleqnfalse}
% tilde with text over it
\newcommand{\distas}[1]{\mathbin{\overset{#1}{\kern\z@\sim}}}%
\newsavebox{\mybox}\newsavebox{\mysim}
\newcommand{\distras}[1]{%
  \savebox{\mybox}{\hbox{\kern3pt$\scriptstyle#1$\kern3pt}}%
  \savebox{\mysim}{\hbox{$\sim$}}%
  \mathbin{\overset{#1}{\kern\z@\resizebox{\wd\mybox}{\ht\mysim}{$\sim$}}}%
}
\makeatother

% \newtheoremstyle{newstyle}
% {} %Aboveskip
% {} %Below skip
% {\mdseries} %Body font e.g.\mdseries,\bfseries,\scshape,\itshape
% {} %Indent
% {\bfseries} %Head font e.g.\bfseries,\scshape,\itshape
% {.} %Punctuation afer theorem header
% { } %Space after theorem header
% {} %Heading

\newtheorem{thm}{Theorem}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{lem}{Lemma}
\newtheorem{cor}{Corollary}
\newtheorem{definition}{Definition}
\newcommand*\diff{\mathop{}\!\mathrm{d}}
\newcommand*\Diff[1]{\mathop{}\!\mathrm{d^#1}}
\DeclareMathOperator{\E}{\mathrm{E}}
\DeclareMathOperator{\Var}{\mathrm{Var}}
\DeclareMathOperator{\R}{\mathbb{R}}
\DeclareMathOperator{\1}{\mathbbm{1}}
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

% suppress table numbering
\captionsetup[table]{labelformat=empty}

\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apsr}

\title{Assignment 1 Answer Key}
\author{\href{mailto:tl2624@columbia.edu}{Thomas Leavitt}}
\date{04 August 2020}

\begin{document}
\maketitle

\section*{Question 1}

\subsection*{1a}

Let's first load the data and then write a function to calculate this
specific test statistic, \(n_1^{-1}\mathbf{Z}^{\prime}\mathbf{y}\),
under the sharp null hypothesis of no effect:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{acorn\_data \textless{}{-}}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"acorn03.csv"}\NormalTok{)}

\NormalTok{acorn\_data \textless{}{-}}\StringTok{ }\NormalTok{dplyr}\OperatorTok{::}\KeywordTok{select}\NormalTok{(}\DataTypeTok{.data =}\NormalTok{ acorn\_data, unit, size, z, vote03)}

\NormalTok{treat\_group\_mean \textless{}{-}}\StringTok{ }\ControlFlowTok{function}\NormalTok{(.Z, .y) \{}
    
\NormalTok{    n\_}\DecValTok{1}\NormalTok{ =}\StringTok{ }\KeywordTok{sum}\NormalTok{(.Z }\OperatorTok{==}\StringTok{ }\DecValTok{1}\NormalTok{)}
    
\NormalTok{    test\_stat =}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(n\_}\DecValTok{1}\OperatorTok{\^{}}\NormalTok{\{}
        \DecValTok{{-}1}
\NormalTok{    \} }\OperatorTok{*}\StringTok{ }\KeywordTok{t}\NormalTok{(.Z) }\OperatorTok{\%*\%}\StringTok{ }\NormalTok{.y)}
    
    \KeywordTok{return}\NormalTok{(test\_stat)}
    
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\normalsize

Calculate the observed test statistic as follows: \scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{obs\_test\_stat \textless{}{-}}\StringTok{ }\KeywordTok{treat\_group\_mean}\NormalTok{(}\DataTypeTok{.Z =}\NormalTok{ acorn\_data}\OperatorTok{$}\NormalTok{z, }\DataTypeTok{.y =}\NormalTok{ acorn\_data}\OperatorTok{$}\NormalTok{vote03)}
\end{Highlighting}
\end{Shaded}

\normalsize

In this example there are \(\binom{28}{14} = 40,116,600\) possible ways
in which \(14\) precincts could be assigned to treatment and the
remaining \(14\) to control. It is too computationally intensive to
enumerate all \(40,116,600\) of them. Instead, we can use a
simulation-based approximation to the null distribution of the test
statistic under all possible assignments.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{5}\NormalTok{)}
\NormalTok{null\_test\_stats \textless{}{-}}\StringTok{ }\KeywordTok{replicate}\NormalTok{(}\DataTypeTok{n =} \DecValTok{10}\OperatorTok{\^{}}\DecValTok{5}\NormalTok{, }\DataTypeTok{expr =} \KeywordTok{treat\_group\_mean}\NormalTok{(}\DataTypeTok{.Z =} \KeywordTok{sample}\NormalTok{(acorn\_data}\OperatorTok{$}\NormalTok{z), }
    \DataTypeTok{.y =}\NormalTok{ acorn\_data}\OperatorTok{$}\NormalTok{vote03))}

\NormalTok{null\_test\_stat\_dist \textless{}{-}}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{null\_test\_stat =}\NormalTok{ null\_test\_stats)}
\end{Highlighting}
\end{Shaded}

\normalsize

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# Use Freedman{-}Diaconis rule for bin width}
\NormalTok{bw \textless{}{-}}\StringTok{ }\DecValTok{2} \OperatorTok{*}\StringTok{ }\KeywordTok{IQR}\NormalTok{(null\_test\_stats)}\OperatorTok{/}\KeywordTok{length}\NormalTok{(null\_test\_stats)}\OperatorTok{\^{}}\NormalTok{(}\DecValTok{1}\OperatorTok{/}\DecValTok{3}\NormalTok{)}

\KeywordTok{library}\NormalTok{(ggplot2)}
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ null\_test\_stat\_dist, }\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ null\_test\_stat, }\DataTypeTok{y =}\NormalTok{ (..count..)}\OperatorTok{/}\KeywordTok{sum}\NormalTok{(..count..))) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom\_histogram}\NormalTok{(}\DataTypeTok{binwidth =}\NormalTok{ bw) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom\_vline}\NormalTok{(}\DataTypeTok{xintercept =}\NormalTok{ obs\_test\_stat, }\DataTypeTok{linetype =} \StringTok{"dashed"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{xlab}\NormalTok{(}\DataTypeTok{label =} \StringTok{"Null test statistic"}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{ylab}\NormalTok{(}\DataTypeTok{label =} \StringTok{"Probability"}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{theme\_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{assignment_1_answer_key_files/figure-latex/unnamed-chunk-4-1.pdf}
\normalsize

The upper, one-sided p-value is simply the proportion of null test
statistics greater than or equal to the observed test statistic (the
dashed line in the plot above). \scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{null\_dist\_sim\_p\_value \textless{}{-}}\StringTok{ }\KeywordTok{mean}\NormalTok{(null\_test\_stats }\OperatorTok{\textgreater{}=}\StringTok{ }\NormalTok{obs\_test\_stat)}

\NormalTok{null\_dist\_sim\_p\_value}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.07516
\end{verbatim}

\normalsize
\subsection*{1b}

To calculate the null expected value of our test statistic, simply take
the mean of our simulations of the test statistic under the null.
\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{null\_dist\_sim\_EV \textless{}{-}}\StringTok{ }\KeywordTok{mean}\NormalTok{(null\_test\_stats)}

\NormalTok{null\_dist\_sim\_EV}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.3066652
\end{verbatim}

\normalsize
\subsection*{1c}

We can do the same for the variance. \scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{null\_dist\_sim\_var \textless{}{-}}\StringTok{ }\KeywordTok{mean}\NormalTok{((null\_test\_stats }\OperatorTok{{-}}\StringTok{ }\KeywordTok{mean}\NormalTok{(null\_test\_stats))}\OperatorTok{\^{}}\DecValTok{2}\NormalTok{)}

\NormalTok{null\_dist\_sim\_var}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.0001552291
\end{verbatim}

\normalsize
\section*{Question 2}

We can calculate the null expected value of the test statistic,
\(\E\left[n_1^{-1} \mathbf{Z}^{\prime}\mathbf{y}\right]\), from first
principles via the logic given below. Note that holding the vector
\(\mathbf{y}\) fixed as \(\mathbf{Z}\) varies corresponds to the sharp
null hypothesis of no effect.

Drawing upon basic properties of expectations, we can express
\(\E\left[n_1^{-1} \mathbf{Z}^{\prime}\mathbf{y}_t\right]\) as follows:

\begin{align*}
\E\left[n_1^{-1} \mathbf{Z}^{\prime}\mathbf{y}\right] \\
& = n_1^{-1} \E\left[\mathbf{Z}^{\prime}\mathbf{y}\right] & \text{Since } \E\left[c\right] = c \\
& = n_1^{-1} \E\left[\sum \limits_{n = 1}^n Z_i y_{i}\right] & \text{By the definition of matrix multiplication} \\
& = n_1^{-1} \sum \limits_{n = 1}^n \E\left[Z_i y_{i}\right] & \text{By the linearity of expectations} \\
& = n_1^{-1} \sum \limits_{n = 1}^n y_{ti} \E\left[Z_i\right] & \text{Since } y_{i} \text{ is a constant} \\
& = n_1^{-1} \sum \limits_{n = 1}^n y_{i} \frac{n_1}{n} & \text{By the random assignment process of the experiment} \\
& = n_1^{-1}  \left(y_{1} \frac{n_1}{n}\right) + \dots + \left(y_{n} \frac{n_1}{n}\right) & \text{By the definition of the summation operator} \\
& = n_1^{-1} \frac{n_1}{n} \left(y_{1} + \dots + y_{n}\right) & \text{By the distributive property } (a b) + (a  c) = a(b + c) \\
& = \frac{1}{n_1} \frac{n_1}{n} \left(y_{1} + \dots + y_{n}\right) & \text{Since } n_1^{-1} = \frac{1}{n_1} \\
& = \frac{1}{n} \left(y_{1} + \dots + y_{n}\right) & \text{Since } \frac{n_1}{n n_1} = \frac{1}{n} \\
& = \frac{\left(y_{1} + \dots + y_{n}\right)}{n} \\
& = \overline{y}
\end{align*}

The steps enumerated above show that the expected value of
\(n_1^{-1} \mathbf{Z}^{\prime}\mathbf{y}\) is equal to the mean of the
outcome among all \(1, \dots , n\) units.

\section*{Question 3}

In our finite population, experimental setup,
\(\Var\left[n_1^{-1} \mathbf{Z}^{\prime}\mathbf{y}\right] = \frac{1}{n_1} \frac{n_0}{n} \frac{\sum \limits_{i = 1}^n \left(y_i - \bar{y}\right)^2}{n - 1}\).
we can reexpress the variance of the test statistic as follows:
\begin{align*}
\Var\left[n_1^{-1} \mathbf{Z}^{\prime}\mathbf{y}\right] & = \frac{1}{n_1} \frac{n_0}{n} \frac{\sum \limits_{i = 1}^n \left(y_i - \bar{y}\right)^2}{n - 1} \\ 
& = \frac{1}{n_1} \frac{n_0}{n} \frac{\sum_{i = 1}^n \left(y_i - \bar{y}\right)}{n - 1} \\
& = \frac{n_0 \left(\sum_{i = 1}^n \left(y_i - \bar{y}\right)\right)}{\left(n - 1\right)\left(n\right) \left(n_1\right)} \\
& = \frac{n_0}{n - 1} \frac{\sum_{i = 1}^n \left(y_i - \bar{y}\right)}{n} \frac{1}{n_1} \\
& = \frac{n_0}{n - 1} \sigma^2_y \frac{1}{n_1} \\
& = \frac{n - n_1}{n - 1} \frac{\sigma^2_y}{n_1}
\end{align*} which is the expression for the variance of the sample mean
given in the question.

It is now simple to assess when
\(\Var\left[n_1^{-1} \mathbf{Z}^{\prime}\mathbf{y}\right] = \frac{n - n_1}{n - 1} \frac{\sigma^2_y}{n_1}\)
is smaller than the standard expression for the variance we normally
encounter in introductory textbooks given by \(\frac{\sigma^2_y}{n_1}\),
which assumes random sampling from an infinite superpopulation of
outcomes. In particular, we can see that if \(n_1 > 1\), then
\(\frac{n - n_1}{n - 1}\) will be less than 1, in which case
\(\frac{n - n_1}{n - 1} \frac{\sigma^2_y}{n_1}\) will be less than
\(\frac{\sigma^2_y}{n_1}\).

\section*{Question 4}

For this experiment, the test statistic is
\(n_1^{-1}\mathbf{Z}^{\prime}\mathbf{y}\). The observed test statistic,
\(n_1^{-1}\mathbf{z}^{\prime}\mathbf{y}\), then, is simply
\begin{align*}
\left(\frac{1}{14}\right) \begin{bmatrix} 0 & 0 & \dots & 1 & 1 \end{bmatrix} \begin{bmatrix}  0.3832 \\ 0.1865 \\ \vdots \\ 0.3690 \\ 0.2924 \end{bmatrix} & \approx \left(\frac{1}{14}\right)\begin{bmatrix} 4.5473 \end{bmatrix} \\
& \approx 0.3248.
\end{align*} This quantity is the mean turnout proportion among treated
units.

We can calculate this value in \texttt{R} as follows: \scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# t() is to transpose a matrix; \%*\% is the matrix multiplication operator}
\NormalTok{(}\DecValTok{1}\OperatorTok{/}\KeywordTok{sum}\NormalTok{(acorn\_data}\OperatorTok{$}\NormalTok{z)) }\OperatorTok{*}\StringTok{ }\KeywordTok{t}\NormalTok{(acorn\_data}\OperatorTok{$}\NormalTok{z) }\OperatorTok{\%*\%}\StringTok{ }\NormalTok{acorn\_data}\OperatorTok{$}\NormalTok{vote03}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          [,1]
[1,] 0.3248104
\end{verbatim}

\normalsize

Under the sharp null hypothesis of no effect, the observed outcome
\(y_i\), is fixed for all \(i \in \left\{1 , \dots , 28\right\}\) units
over all possible random assignments:

\begin{table}[ht]
\centering
\begin{tabular}{rrr}
\hline
Unit Index & $\mathbf{z}$ & $\mathbf{y}$ \\ 
\hline
1  & 0  & 0.3832  \\ 
2  & 0  & 0.1865  \\ 
$\vdots$ & $\vdots$ \\ 
27 & 1  & 0.3699 \\ 
28 & 1  & 0.2924 \\ 
\hline
\end{tabular}
\end{table}

Therefore, we can directly calculate the population mean and variance of
all \(28\) outcome values under the sharp null hypothesis of no effect.
The population mean and variance of the outcome under the sharp null
hypothesis of no effect are \(\mu_{y} \approx 0.3071\) and
\(\sigma^2_{y} \approx 0.0042\), respectively.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pop\_mean \textless{}{-}}\StringTok{ }\KeywordTok{mean}\NormalTok{(acorn\_data}\OperatorTok{$}\NormalTok{vote03)}

\NormalTok{pop\_var \textless{}{-}}\StringTok{ }\KeywordTok{mean}\NormalTok{((acorn\_data}\OperatorTok{$}\NormalTok{vote03 }\OperatorTok{{-}}\StringTok{ }\KeywordTok{mean}\NormalTok{(acorn\_data}\OperatorTok{$}\NormalTok{vote03))}\OperatorTok{\^{}}\DecValTok{2}\NormalTok{)}

\KeywordTok{cbind}\NormalTok{(pop\_mean, pop\_var)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      pop_mean     pop_var
[1,] 0.3066632 0.004194751
\end{verbatim}

\normalsize

Given that we now know \(\mu_{y}\) and \(\sigma^2_{y}\) under the sharp
null hypothesis, we can directly calculate
\(\Var\left[n_1^{-1} \mathbf{Z}^{\prime} \mathbf{y}\right]\):
\begin{align*}
\Var\left[n_1^{-1} \mathbf{Z}^{\prime} \mathbf{y}\right] & = \left(n_1^{-1}\right) \left(\frac{n_0}{n}\right) \left(\frac{\sum \limits_{i = 1}^n \left(y_i - \bar{y}\right)^2}{n - 1}\right) \\
& \approx \left(\frac{1}{14}\right) \left(\frac{14}{28}\right) \left(\frac{0.1175}{28 - 1}\right) \\
& \approx 0.0002.
\end{align*} This quantity is the variance of the randomization
distribution, which is distinct from the variance of the finite
population of \(28\) outcomes under the sharp null hypothesis of no
effect.

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fpc\_var\_sample\_mean \textless{}{-}}\StringTok{ }\ControlFlowTok{function}\NormalTok{(.y, .n\_}\DecValTok{1}\NormalTok{) \{}
    
\NormalTok{    (.n\_}\DecValTok{1}\OperatorTok{\^{}}\NormalTok{(}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)) }\OperatorTok{*}\StringTok{ }\NormalTok{((}\KeywordTok{length}\NormalTok{(.y) }\OperatorTok{{-}}\StringTok{ }\NormalTok{.n\_}\DecValTok{1}\NormalTok{)}\OperatorTok{/}\KeywordTok{length}\NormalTok{(.y)) }\OperatorTok{*}\StringTok{ }\NormalTok{(}\KeywordTok{sum}\NormalTok{((.y }\OperatorTok{{-}}\StringTok{ }\KeywordTok{mean}\NormalTok{(.y))}\OperatorTok{\^{}}\DecValTok{2}\NormalTok{))}\OperatorTok{/}\NormalTok{(}\KeywordTok{length}\NormalTok{(.y) }\OperatorTok{{-}}\StringTok{ }
\StringTok{        }\DecValTok{1}\NormalTok{)}
    
\NormalTok{\}}

\NormalTok{fpc\_var \textless{}{-}}\StringTok{ }\KeywordTok{fpc\_var\_sample\_mean}\NormalTok{(}\DataTypeTok{.y =}\NormalTok{ acorn\_data}\OperatorTok{$}\NormalTok{vote03, }\DataTypeTok{.n\_1 =} \KeywordTok{sum}\NormalTok{(acorn\_data}\OperatorTok{$}\NormalTok{z))}

\NormalTok{fpc\_var}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.0001553611
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\KeywordTok{abs}\NormalTok{(null\_dist\_sim\_var }\OperatorTok{{-}}\StringTok{ }\NormalTok{fpc\_var)}\OperatorTok{/}\NormalTok{fpc\_var) }\OperatorTok{*}\StringTok{ }\DecValTok{100}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.08497887
\end{verbatim}

\normalsize

The error of the simulation based approximation, expressed as a
percentage of
\(\mathrm{Var}\left[n_1^{-1} \mathbf{Z}^{\prime} \mathbf{y}\right]\) is:
\begin{align*}
\left(\frac{\left|\mathrm{Var}_{sim}\left[n_1^{-1} \mathbf{Z}^{\prime} \mathbf{y}\right] - \mathrm{Var}\left[n_1^{-1} \mathbf{Z}^{\prime} \mathbf{y}\right]\right|}{\mathrm{Var}\left[n_1^{-1} \mathbf{Z}^{\prime} \mathbf{y}\right]}\right) 100 = 0.5318 \%.
\end{align*}

\section*{Question 5}

In the case of the Acorn experiment, we can calculate the Z-score as
follows: \begin{align*}
\text{Z-score} & = \frac{n_1^{-1}\mathbf{Z}^{\prime}\mathbf{y} - \E\left[n_1^{-1}\mathbf{Z}^{\prime}\mathbf{y}\right]}{\sqrt{\mathrm{Var}\left[n_1^{-1}\mathbf{Z}^{\prime}\mathbf{y}\right]}} \\
& \approx \frac{\left(0.3248 - .3067\right)}{0.0125}
\end{align*}

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{z\_score \textless{}{-}}\StringTok{ }\NormalTok{(obs\_test\_stat }\OperatorTok{{-}}\StringTok{ }\NormalTok{pop\_mean)}\OperatorTok{/}\KeywordTok{sqrt}\NormalTok{(fpc\_var)}
\end{Highlighting}
\end{Shaded}

\normalsize

We can now calculate the Normal approximation based upper, one-sided
p-value as follows:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pnorm}\NormalTok{(}\DataTypeTok{q =}\NormalTok{ z\_score, }\DataTypeTok{lower.tail =} \OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.07270733
\end{verbatim}

\normalsize

The \texttt{pnorm} function reports the probability density to the left
of the observed test statistic by default; but since we expect a
positive effect, we want the probability density to the right of the
observed test statistic, which we can do by setting
\texttt{lower.tail = FALSE}.

\section*{Question 6}

A researcher plans to ask six subjects to donate time to an adult
literacy program. Each subject will be asked to donate either \(30\)
\((Z = 0)\) or \(60\) \((Z = 1)\) minutes. The researcher is considering
three methods for randomizing the treatment. Method I is to make
independent decisions for each subject, tossing a coin each time. Method
C is to write ``30'' and ``60'' on three playing cards each, and then
shuffle the six cards. Method P tosses one coin for each of the 3 pairs
(1, 2), (3, 4), (5, 6), asking for 30 (60) minutes from exactly one
member of each pair.

\subsection*{6a}

Method I independently assigns each subject to treatment \((Z_i = 1)\)
with probability \(0.5\). Under simple random assignment all subjects
are assigned to groups without regard to the assignments of other
subjects in the study; this assignment process is especially simple to
implement. With a small \(n\), however, this method may result in no
subjects in one of the two conditions. If \(n = 6\), then, under simple
random assignment (method I), the probability that all units are
assigned to the treatment condition is \(0.5^6 \approx 0.0156\) and the
probability that all units are assigned to the control condition is also
\(0.5^6 \approx 0.0156\). Although small, the probability of these two
outcomes taken together is \(0.5^6 + 0.5^6 \approx 0.0312\). Method C
has the benefit of enabling the researcher to assign a predetermined
number of subjects to treatment and control such that there is a fixed
number of participants in each condition. Method P assigns units to
treatment and control within blocked pairs, which (if covariates are
predictive of potential outcomes) decreases the variance of the
randomization distribution.

\subsection*{6b}

If \(n\) increases to \(600\), then the probability that all \(600\)
units are assigned to treatment is \(0.5^{600}\) and the probability
that all units are assigned to control is also \(0.5^{600}\). Thus, the
probability that all units are assigned to one of the two treatment
conditions is \(0.5^{600} + 0.5^{600}\). The aforementioned weakness of
method \(I\) is far less of a concern if \(n\) were \(600\) instead of
\(6\).

\subsection*{6c}

Let's first consider the set of possible assignments under each method.
Under method \(I\) the set of possible assignments, \(\Omega_I\) is
\begin{align*}
\Omega_{I} & = \left\{ \ \begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0 \end{bmatrix}, \  \begin{bmatrix} 1 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0 \end{bmatrix}, \ \cdots , \ \begin{bmatrix} 1 \\ 1 \\ 1 \\ 1 \\ 1 \\ 0  \end{bmatrix}, \ \begin{bmatrix} 1 \\ 1 \\ 1 \\ 1 \\ 1 \\ 1  \end{bmatrix} \ \right\}.
\end{align*}

Under method \(C\), the set of assignments, \(\Omega_C\), is
\begin{align*}
\Omega_{C} & = \left\{ \mathbf{z}: \sum \limits_{i = 1}^n z_i = n_1 \right\} = \left\{ \ \begin{bmatrix} 1 \\ 1 \\ 0 \\ 1 \\ 0 \\ 0 \end{bmatrix}, \ \begin{bmatrix} 1 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0 \end{bmatrix}, \ \cdots , \ \begin{bmatrix} 0 \\ 0 \\ 1 \\ 0 \\ 1 \\ 1  \end{bmatrix}, \ \begin{bmatrix} 0 \\ 0 \\ 0 \\ 1 \\ 1 \\ 1  \end{bmatrix} \ \right\}.
\end{align*}

Finally, under method \(P\), the set of assignments, \(\Omega_P\), is
\begin{align*}
\Omega_{P} & = \left\{ \mathbf{z}: \sum \limits_{i = 1}^n z_{bi} = 1, \sum \limits_{i = 1}^n \left(1 - z_{bi}\right) = 1, b = 1, \dots , B \right\} = \left\{ \ \begin{bmatrix} 1 \\ 0 \\ 1 \\ 0 \\ 1 \\ 0 \end{bmatrix}, \ \begin{bmatrix} 0 \\ 1 \\ 1 \\ 0 \\ 1 \\ 0 \end{bmatrix}, \ \cdots , \ \begin{bmatrix} 1 \\ 0 \\ 0 \\ 1 \\ 0 \\ 1  \end{bmatrix}, \ \begin{bmatrix} 0 \\ 1 \\ 0 \\ 1 \\ 0 \\ 1  \end{bmatrix} \ \right\},
\end{align*} where the index \(b \in \left\{1, \dots , B\right\}\) runs
over the pairs in the randomized experiment.

Under all three methods, the respective probabilities of each possible
assignment is \(\cfrac{1}{\left\lvert \Omega_I \right \rvert}\),
\(\cfrac{1}{\left\lvert \Omega_C \right \rvert}\) and
\(\cfrac{1}{\left\lvert \Omega_P \right \rvert}\), respectively. Recall
that for a set \(S\), \(\left\lvert S \right\rvert\) denotes the number
of elements in (i.e., the cardinality of) the set, \(S\). After noting
that \(\E\left[Z_1\right]\) is equivalent to
\(\Pr\left(Z_1 = 1\right)\), we can calculate \(\E\left[Z_1\right]\) by
summing the probabilities of assignment vectors in which \(z_1 = 1\).
Under all three methods, \(\E\left[Z_1\right] = 0.5\).

\subsection*{6d}

Along the same lines as the question above, we can also deduce that
\(\E\left[Z_i\right] = 0.5\) for all
\(i \in \left\{1, \dots , n\right\}\) under each method. Then, by the
linearity of expectations, we know that \begin{align*}
\E\left[Z_1 + \dots + Z_6\right] \\
& = \E\left[Z_1\right] + \dots + \E\left[Z_6\right] \\
& = 0.5 + \dots + 0.5 \\
& = 3
\end{align*} for all methods.

\subsection*{6e}

Under each method, we can calculate
\(\E\left[\mathbf{Z}^{\prime}\mathbf{1}\right]\), which is the expected
number of treated units, by calculating \(\mathbf{z}'\mathbf{1}\) for
each \(\mathbf{z} \in \Omega_{\cdot}\) and then calculating the average
of all possible values of \(\mathbf{z}'\mathbf{1}\).

For all three methods, the expected number of treated units,
\(\E\left[\mathbf{Z}'\mathbf{1}\right]\) is equal to \(3\). For example,
in \texttt{R}, we could calculate the expexted number of treated units
as follows:

\scriptsize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n\_}\DecValTok{1}\NormalTok{\_sra \textless{}{-}}\StringTok{ }\ControlFlowTok{function}\NormalTok{(.n, .k, .p) \{}
    
    \KeywordTok{return}\NormalTok{(}\KeywordTok{choose}\NormalTok{(}\DataTypeTok{n =}\NormalTok{ .n, }\DataTypeTok{k =}\NormalTok{ .k) }\OperatorTok{*}\StringTok{ }\NormalTok{.p}\OperatorTok{\^{}}\NormalTok{(.k) }\OperatorTok{*}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{{-}}\StringTok{ }\NormalTok{.p)}\OperatorTok{\^{}}\NormalTok{(.n }\OperatorTok{{-}}\StringTok{ }\NormalTok{.k))}
    
\NormalTok{\}}

\NormalTok{probs \textless{}{-}}\StringTok{ }\KeywordTok{sapply}\NormalTok{(}\DataTypeTok{X =} \KeywordTok{seq}\NormalTok{(}\DataTypeTok{from =} \DecValTok{0}\NormalTok{, }\DataTypeTok{to =} \DecValTok{6}\NormalTok{, }\DataTypeTok{by =} \DecValTok{1}\NormalTok{), }\DataTypeTok{FUN =}\NormalTok{ n\_}\DecValTok{1}\NormalTok{\_sra, }\DataTypeTok{.n =} \DecValTok{6}\NormalTok{, }\DataTypeTok{.p =} \FloatTok{0.5}\NormalTok{)}


\NormalTok{events \textless{}{-}}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DataTypeTok{from =} \DecValTok{0}\NormalTok{, }\DataTypeTok{to =} \DecValTok{6}\NormalTok{, }\DataTypeTok{by =} \DecValTok{1}\NormalTok{)}

\KeywordTok{sum}\NormalTok{(events }\OperatorTok{*}\StringTok{ }\NormalTok{probs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 3
\end{verbatim}

\normalsize

\subsection*{6f}

For methods C and P, the variance of \(\mathbf{Z}^{\prime} \mathbf{1}\)
is \(0\), since under every treatment assignment permutation in
\(\Omega_C\) and \(\Omega_P\), respectively, the value of
\(\mathbf{Z}^{\prime}\mathbf{1}\) is constant.

We know that
\(\mathrm{Var}\left[X\right] = \E\left[X^2\right] - \E\left[X\right]^2\);
hence, for method I we can calculate the variance as follows:
\begin{align*}
\E\left[\left(\mathbf{Z}^{\prime}\mathbf{1}\right)^2\right] - \E\left[\mathbf{Z}^{\prime}\mathbf{1}\right]^2 & = 10.5 - 9 \\
& = 1.5
\end{align*}

\subsection*{6h}

For methods C and P, \(\mathbf{Z}^{\prime}\mathbf{1}\) is a constant
that is equal to \(n_1\). The expected value of a constant is the
constant; hence, \begin{align*}
\E\left[\mathbf{Z}^{\prime}\mathbf{1}\right] \\
& = \E\left[n_1\right] \\
& = n_1
\end{align*} Therefore, we can express
\(\E\left[\frac{\mathbf{Z}^{\prime}\mathbf{x}}{\mathbf{Z}^{\prime}\mathbf{1}}\right]\)
as follows: \begin{align*}
\E\left[\frac{\mathbf{Z}^{\prime}\mathbf{x}}{\mathbf{Z}^{\prime}\mathbf{1}}\right] \\
& = \E\left[\frac{\mathbf{Z}^{\prime}\mathbf{x}}{n_1}\right] \\
& \vdots  \\
& = \frac{\left(x_1 + \dots + x_n\right)}{n} \\
& = \overline{x},
\end{align*} which is simply the mean of \(\mathbf{x}\).

For method I, \(\mathbf{Z}^{\prime}\mathbf{1}\) is a random quantity
that varies across different possible realizations of treatment
assignment. Since, the number of treated units,
\(\mathbf{Z}^{\prime}\mathbf{1}\), is a random variable, we can no
longer write
\(\E\left[\frac{\mathbf{Z}^{\prime}\mathbf{x}}{\mathbf{Z}^{\prime}\mathbf{1}}\right] = \E\left[\frac{\mathbf{Z}^{\prime}\mathbf{x}}{n_1}\right]\).
In addition, it is \textit{not} the case in general that
\(\E\left[\frac{\mathbf{Z}'\mathbf{x}}{\mathbf{Z}'\mathbf{1}} \right] = \frac{\E\left[\mathbf{Z}'\mathbf{x} \right]}{\E\left[\mathbf{Z}'\mathbf{1} \right]}\).
Therefore, the fact that
\(\cfrac{\mathbf{Z}'\mathbf{x}}{\mathbf{Z}'\mathbf{1}} = \bar{x}\) in a
completely randomized experiment does not immediately carry over to a
simply randomized experiment.

Nevertheless, so long as \(n_1 > 0\), it follows that \begin{align*}
\E\left[\frac{\mathbf{Z}'\mathbf{x}}{\mathbf{Z}'\mathbf{1}}\big| \mathbf{Z}' \mathbf{1} = n_{1}\right] & = \E\left[\frac{\mathbf{Z}'\mathbf{x}}{n_1}\big| \mathbf{Z}' \mathbf{1} = n_{1}\right] \\
& \vdots \\
& = \sum \limits_{i = 1}^n \E\left[\frac{Z_{i}}{n_{1}} \big| \mathbf{Z}'\mathbf{1} = n_{1} \right] x_i \\ 
& = \sum \limits_{i = 1}^n \E\left[\frac{\left(n_1/n\right)}{n_{1}} \big| \mathbf{Z}'\mathbf{1} = n_{1} \right] x_i \\ 
& = \sum \limits_{i = 1}^n \E\left[\frac{n_1}{n n_{1}} \big| \mathbf{Z}'\mathbf{1} = n_{1} \right] x_i \\ 
& = \sum \limits_{i = 1}^n \frac{1}{n} x_i \\ 
& = \bar{x}
\end{align*}

But when \(n_1 = 0\), which will occur with probability
\(\cfrac{1}{\left\lvert \Omega_I \right\rvert}\) under method \(I\), the
quantity
\(\frac{\mathbf{Z}'\mathbf{x}}{\mathbf{Z}'\mathbf{1}}\big| \mathbf{Z}' \mathbf{1} = n_{1}\)
is no longer defined. Thus, in general
\(\E\left[\frac{\mathbf{Z}^{\prime}\mathbf{x}}{\mathbf{Z}^{\prime}\mathbf{1}}\right]\)
does not reduce to \(\bar{x}\) under simple random assignment. But if
one were to condition on all assignments in \(\Omega_I\) such that
\(n_1 > 0\), then it would be the case that
\(\E\left[\frac{\mathbf{Z}^{\prime}\mathbf{x}}{\mathbf{Z}^{\prime}\mathbf{1}}\right] = \bar{x}\).

\newpage

\renewcommand\refname{References}
  \bibliography{Bibliography.bib}

\end{document}
