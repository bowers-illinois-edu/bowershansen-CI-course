% MERGE UNITS 03 AND 04 INTO A SINGLE UNIT, FISHERIAN RANDOMIZATION INFERENCE

%  For slides only
\input{slidesonly}

% % For handout
%\input{handout}

%For handout + mynotes
% \input{handout+mynotes}

\input{beamer-preamble-bbh-all}
\input{defs-all}
\input{courseedition}

\title[Fisherian inference]{Unit 3: Fisherian randomization inference and models of effects}
% \author, date moved to beamer-preamble-*-all.tex

\begin{document}


% putting `\begin{frame}`/ `\end{frame}` in announcement-of-the-day.tex lets us 
% put frame notes into that file
% announcement-of-the-day.tex not part of repo
\InputIfFileExists{announcement-of-the-day.tex}{% from https://tex.stackexchange.com/questions/100663/if-the-remote-file-exists-then-include-it-else-include-the-local-one
  % File personal/bar.tex exists and is read
  \input{announcement-of-the-day}
}{%
  % File personal/bar.tex is not found, try bar.tex
}


\begin{frame}[<+->]{Background: permutation tests vs parametric tests}

To compare 2 (or more) groups, one chooses between
permutation and parametric tests. E.g., Fisher vs. $\chi^{2}$ tests.
\begin{itemize}
\item both begin by computing a test statistic
\item they differ in terms of what they compare the statistic to in order to get a p-value
\item parametric tests posit a model for $Y| \mathrm{group}$
\item W/ random assignment, permutation tests don't have to
  assume any model for $Y| \mathrm{group}$\ldots
\item but a provisionally entertained model can suggest a test
  statistic.  E.g., $Y| G=g \sim \mathcal{N}(\mu_{g}, \sigma^{2})
  \Rightarrow $ $t(\mathbf{z}, \mathbf{y}) =$ difference of means statistic; $Y| G=g \sim \mathrm{Logistic}(\mu_{g}, s)
  \Rightarrow $ $t(\mathbf{z}, \mathbf{y}) =$  rank sum statistic.
\item likewise, the permutational approach circumvents sample-size requirements for p-values' validity.
\end{itemize}

Software notes:
\begin{itemize}
\item In unit 2, $z$'s were permuted using \texttt{sample(z)}.
\item \texttt{sample()} is part of base R.  the ``permute'' library's
  ``\textrm{shuffle}''  is more evocative.
\end{itemize}

\end{frame}


\begin{frame}<1-4\mynoteonly>[label=testStats4MeanComparison1Fr]{Background:
    non-Normality robustness; choice of $t(\mathbf{z}, \mathbf{y})$}

Stepping back momentarily from issues specific to causal inference, consider the one-way model
$$
Y = \mu + Z\tau + \epsilon,\, \mathbf{E}(\epsilon) = 0.
$$

Suppose the goal is to test the hypothesis that $\tau = 0$.
  
\begin{itemize}[<+->]
\item If $\epsilon \sim \mathcal{N}(0, \sigma^{2})$, some $\sigma >0$, regardless of whether $Z=1$ or 0, the difference of means is optimal, in various senses, as an estimator of $\tau$. By extension, using it as a test statistic gives favorable power.
\item True both for parametric tests (t-test) and permutation tests.
\item If $\epsilon$ follows some other distribution, parametric
  $t$-test's $\alpha$ level is only approximate, depending on CLT. (To
  fix, use permutation $t$-test.)
\item For both versions, \textit{power} suffers: the means reacts so
  strongly to outliers unrelated to treatment that  the ACE becomes
  hard to see.
\item To fix, select a test statistic with built-in outlier
  protection.
\end{itemize}
\end{frame}

\itnote{
\item This time, first 4 bullets only.
}

\section{Models of effects}
\begin{frame}{A simple model of effects for the Acorn GOTV experiment}
  
One simple model is that the GOTV campaign increases voter turnout by $p$ percentage points per precinct.

\begin{center}
  \begin{tabular}{r|rr|rr}
  \hline
 & GOTV? & vote03(\%)& $y_c$ & $y_t$ \\
  \hline
1 & 0 & 38 & 38 & $38+p$\\
$\vdots$& & & & \\
13 & 0 & 19 & 19& $19+p$\\
14 & 0 & 34 & 34& $34+p$\\
15 & 1 & 49 & $49-p$& 49\\
16 & 1 & 38 & $38-p$& 38\\
$\vdots$& & & & \\
28 & 1 & 29 & $29-p$& 29\\
   \hline
\end{tabular}

\end{center}

This family of hypotheses, as $p$ varies between $-100$ and $100$, can be called a \textit{model of effects}.
\end{frame}

\begin{frame}{Testing simple models other than the no-effect model}

\begin{columns}
\column{.4\linewidth}

\begin{itemize}
\item At right: 3 models/hypotheses
\item You can decide how to test:
  \begin{itemize}
  \item $t$
  \item one-sided or 2? 
  \item \ldots
  \end{itemize}
\item Relative to the model that assignment to GOTV increases turnout by
  $p$, and to designated tests (each $p$) ---  
\end{itemize}
\column{.6\linewidth}    
{\small
\addtolength{\tabcolsep}{-\tabcolsepadj} 
  \begin{tabular}{r|rr|rr|rrr}
  \hline
  &       &                           &           &         &
                                                              \multicolumn{3}{c}{$y_{C
                                                              | p=
                                                              \underline{\hspace{1em}}}$} \\
 & $z$ & $y_{\mathrm{obs}}$ & $y_C$ & $y_T$ & $-10$\% & 0\% & 10\% \\
  \hline
1 & 0 & 38 & 38 & $38+p$ & 38 & 38 & 38\\
$\vdots$& & & & & &  &\\
13 & 0 & 19 & 19& $19+p$ & 19 & 19 & 19\\
14 & 0 & 34 & 34& $34+p$& 34 & 34 & 34 \\
15 & 1 & 49 & $49-p$& 49 & 59 & 49 & 39 \\
16 & 1 & 38 & $38-p$& 38 & 48 & 38 & 28 \\
$\vdots$& & & & & & &\\
28 & 1 & 29 & $29-p$& 29 & 39 & 29 & 19 \\
   \hline
\end{tabular}
 \addtolength{\tabcolsep}{\tabcolsepadj}
}

\end{columns}
  \vfill 
\begin{quote}
$1-\alpha$ confidence set for $p$ $\equiv $ \{$p$: $H_{p}$ not rejected at
  level $\alpha$\} .  
\end{quote}

\vfill
\end{frame}

\begin{frame}{A more nuanced model for the Acorn GOTV experiment} % if
                                % "more nuanced" changes, drop from
                                % next slide too

Recall that a \textit{response schedule} is a complete specification of unit-level responses to the experiment under every possible random assigment.

It's often more natural to hypothesize only about how treated units would have responded to control, not also how controls would have responded to treatment. For example, here are 3 competing models of the effects of the Acorn GOTV campaign:
\begin{itemize}
\item[No effect] says there was no effect (\texttt{RS0})
\item[one per 10] says the GOTV campaign generated 1 vote for every 10 contacts (\texttt{RS1})
\item[one per 5]says the GOTV campaign generated 1 vote for every 5 contacts (\texttt{RS2})
\end{itemize}

\pause
Note that these models don't specify $y_{t}$ for precincts we only got to observe under control, $z=0$ --- they leave ``blanks'' in the potential schedule.  That's OK.

\end{frame}

\begin{frame}<\nottheirhandout>{Incomplete response schedules and statistical testing}
   An incomplete response schedule can still give us enough to do
   statistical testing. For example, if the schedule specifies $y_c$
   for all subjects --- more generally, if hypothesis +
   $\mathbf{y}_{\mathrm{obs}}$ together determine $\mathbf{y}_{U}$,
   the vector of responses that would have been obtained in the
   \textit{uniformity trial}   then for any test statistic $t $ we can
   test by comparing $t(\mathbf{z}, \mathbf{y}_{U})$ to the permutation distribution of $t(\mathbf{Z}, \mathbf{y}_{U}) $ .

Using $t(\mathbf{z}, \mathbf{y}_{U}) = \bar{y}_{U1} - \bar{y}_{U0} $,

\begin{center}
\begin{tabular}{l|rrr} \hline
& \multicolumn{3}{c}{votes/ 10 contacts}\\
  Hypothesis & 0 & 1 & 2 \\ \hline
$p$ (2-sided) & \visible<2->{.15} & \visible<2->{.38} & \visible<2->{.003} \\ \hline
\end{tabular}
\end{center}

(see \texttt{unit03-Rex.pdf}).
\end{frame}

\note{
Now start \texttt{unit03-Rex}
}



\section{Inference w/ general models of effects}

\begin{frame}{Confidence intervals and models of effects}

  \begin{itemize}[<+->]
  \item The 3 models just considered fall under the broader model that the GOTV
generated $v$ votes per contact, some $v \in [-1, 1]$.
\item Assuming that model, the 95\% CI for $v$ is the collection of $v$s corresponding to incomplete response schedules that would not be rejected at level .05 - a confidence interval by inversion of a family of hypothesis tests.
\item If you want an estimate to go with such a confidence interval, the convention is to report a \textit{Hodges-Lehmann} estimate --- essentially, limit of 100*$(1-\alpha)$\% CIs, as $\alpha \uparrow 1$.
\item There's no precise analogue of the ``standard error.''
\item However, for some of the spirit of a ``standard error'', report a sometimes 2/3 CI alongside a 95\% CI, as suggested by Mosteller \& Tukey (1977, \textit{Data analysis and regression}).
\item We just backed out estimates of the ``Complier average treatment effect,'' and associated confidence intervals, w/o violating the intention-to-treat principle! (Rosenbaum, 1997).
  \end{itemize}


\end{frame}


\begin{frame}
\frametitle{Example: Violence and public infrastructure in Medell{\'i}n, Colombi
a}
\begin{columns}
  \begin{column}{.5\linewidth}
    \begin{itemize}
    \item 2 million residents; 16 districts
    \item Pre-intervention: 60\% poverty rate, 20\% unemployment, homicide 185 p
er 100K
    \item High residential segregation
    \item<2-> 2004-2006: infrastructure intervention for certain poor neighborho
ods.
    \end{itemize}
  \end{column}
  \begin{column}{.5\linewidth}
    \only<1>{\igrphx{medellin-conc-pov}}
\only<2-\mynoteonly>{\igrphx{medellin-gondola}}
  \end{column}
\end{columns}

\end{frame}
\Note{(strata will enter the story because the end analysis involved matching)}



\begin{frame}[fragile]{A model of effects for homicide rates in Medellin}

Each Medellin neighborhood provides several years of non-independent
data.  If we're willing to model Metrocable as a natural experiment,
we can borrow longitudinal data methods, without having to adopt their
dependence assumptions.   For instance, using random
 effects: 

 \begin{enumerate}[<+->]
 \item Let
   $y(T)=$ neighborhood homicide rate in year $T=2002, \ldots, 2008$.  We test models of
   effects of form, for rates $r \leq 0$:
$$H_{0}: y_{t}(T) = \left\{ \begin{array}{lr}\exp((T-2004) r/4)
                              y_{c}(T),& T> 2004; \\
y_{c}(T),& T\leq 2004.\end{array} \right.$$ 
 \item We then fit a random effects model of this form:
\begin{semiverbatim}
 lmer(Count \textasciitilde\  year + (year+1|nh) +\ \pause
            \alert<@+| handout:0>{offset}( nhTrt*(yr>2004)*(r/4)*(yr-2004) ),
          family=poisson, data=homd)
\end{semiverbatim}
\item Fitted params include  ``fixed'' intercept and slope,
  $\hat{\beta}_{0(r)}$ and $ \hat{\beta}_{1(r)}$,\pause  plus a
  ``random'' slope and intercept (also specific to $r$) for
  each n-hood.  
\item To test $H_{0}$, I calculated a test statistic comparing $t$ vs $c$
  n-hoods' fitted intercepts. For the reference dist'n, I rerandomized
  $Z$ and recalculated.
 \end{enumerate}

  
\end{frame}

\begin{frame}<\nottheirhandout>{Outcome analysis for the Medellin study}
  
  \begin{center}
    \igrphx[width=\linewidth]{RIoutcomeAnalysisBarchart}
  \end{center}

\end{frame}

\section{Tests for normal, not Normal, data distributions}


\subsection{Unstratified case}
\againframe{testStats4MeanComparison1Fr}

\begin{frame}{M-estimation using Huber's loss/psi function} \framesubtitle{as a remedy for the difference in means' hypersensitivity}
  \begin{columns}
    \begin{Column}
          \begin{center}
         {\usebeamercolor[fg]{titlelike} Huber vs squared-error loss}
    \end{center}
      \igrphx{huber-loss-fct}
    \end{Column}
    \begin{Column}
          \begin{center}a
         {\usebeamercolor[fg]{titlelike} Huber's psi function}
    \end{center}

\igrphx{Hubers-Psi-Graph}
    \end{Column}
  \end{columns}
\pause
In practice, Huber's M-estimation solves a regression problem in which
the residuals have been top- and bottom-coded, $e \mapsto \max(-t,
\min(t,e))$ at a data-dependent threshold $t>0$.
\end{frame}
\Note{

Tech note: specificially, just as OLS produces residuals that sum to 0
and are uncorrelated with each column of $\mathbf{x}$, the Huber
M-estimate gives residuals which sum to 0 and are uncorrelated with
the xes, \textit{after} the top and bottom coding.
}
\begin{frame}{Rank-based tests } \framesubtitle{as a remedy for the difference in means' hypersensitivity}
  
\end{frame}

\begin{frame}{Workflow for analyzing experiments/obs studies}
  \framesubtitle{To summarize from earlier units:}

  \begin{columns}
    \begin{column}{.25\linewidth}
      
    \end{column}
    \begin{column}{.75\linewidth}
        \begin{itemize}
  \item[Comparison Design] Specify clustering, pairing or blocking
  \item[Estimation] Optionally, compute unbiased estimate of ATE
  \item[MOEs] Specify models of effect; separately for each, figure $\mathbf{y}_{\mathbf{z}\equiv 0} $ or a summary of it.
  \item[Tests \& CIs] Select test statistic, perform h-tests (separately for each MOE). Summarize the results with a 95\% CI, maybe also 2/3 CI. 
  \item[HL estimates] Optionally, Hodges-Lehmann estimate
  \end{itemize}

    \end{column}
  \end{columns}
\end{frame}

\section{Covariance adjustment}
\begin{frame}<\nottheirhandout>{What's missing from this picture?}


  \begin{columns}
    \begin{column}{.25\linewidth}
      
    \end{column}
    \begin{column}{.75\linewidth}
        \begin{itemize}
  \item[Comparison Design] 
  \item[Estimation] 
  \item[MOEs] 
  \item[Tests \& CIs] 
  \item[HL estimates] 
  \end{itemize}

    \end{column}
  \end{columns}
\pause

\vfill
Covariance adjustments to enhance precision, of course.
  
\end{frame}

\begin{frame}{Basic varieties of covariance adjustment}
  
  \begin{itemize}
   \item{} {Differences-in-differences}
  
\item {} {Model-assisted covariance adjustment}

  \end{itemize}

\end{frame}

\begin{frame}{Workflow for analyzing experiments/obs studies}
  \framesubtitle{To summarize from earlier units:}

  \begin{columns}
    \begin{column}{.25\linewidth}
      
    \end{column}
    \begin{column}{.75\linewidth}
        \begin{itemize}
  \item[Comparison Design] Specify clustering, pairing or blocking
  \item[Gain scores] Optionally, adjust for lagged measure of the outcome by subtracting it off from the actual outcome.
  \item[Estimation] Optionally, compute unbiased estimate of ATE
  \item[MOEs] Specify models of effect; separately for each, figure $\mathbf{y}_{\mathbf{z}\equiv 0} $ or a summary of it.
  \item[Cov Adj] Optionally, effect model-assisted covariance adjustments
  \item[Tests \& CIs] Select test statistic, perform h-tests (separately for each MOE). Summarize the results with a 95\% CI, maybe also 2/3 CI. 
  \item[HL estimates] Optionally, Hodges-Lehmann estimate
  \end{itemize}

    \end{column}
  \end{columns}
\end{frame}




\end{document}
