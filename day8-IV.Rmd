---
title: |
  | Statistical Inference for Causal Quantities when the Active Ingredient is not Random
date: '`r format(Sys.Date(), "%B %d, %Y")`'
author: |
  | ICPSR 2022 Session 2
  | Jake Bowers, Ben Hansen, Tom Leavitt
bibliography:
 - 'BIB/MasterBibliography.bib'
fontsize: 10pt
geometry: margin=1in
graphics: yes
biblio-style: authoryear-comp
output:
  beamer_presentation:
    slide_level: 2
    keep_tex: true
    latex_engine: xelatex
    citation_package: biblatex
    template: icpsr.beamer
    incremental: true
    includes:
        in_header:
           - defs-all.sty
    md_extensions: +raw_attribute-tex_math_single_backslash+autolink_bare_uris+ascii_identifiers+tex_math_dollars
---

<!-- To show notes  -->
<!-- https://stackoverflow.com/questions/44906264/add-speaker-notes-to-beamer-presentations-using-rmarkdown -->

```{r setup1_env, echo=FALSE, include=FALSE}
library(here)
source(here::here("rmd_setup.R"))
```

```{r setup2_loadlibs, echo=FALSE, include=FALSE}
## Load all of the libraries that we will use when we compile this file
## We are using the renv system. So these will all be loaded from a local library directory
library(dplyr)
library(ggplot2)
library(estimatr)
library(coin)
library(DeclareDesign)
```

## Today

 1. Agenda: The estimation approach to Causal Inference with
Instruments perhaps a walk through a testing based approach.
 2. Reading for tomorrow from "Noncompliance and instrumental variables" section.
 3. Questions arising from previous days or reading or assignments or life?

# But first: Where are we and where are we going?

## Overview of Research designs to aid the creation of interpretable comparisons

   - Randomized experiments (randomized $Z$ changes $Y$) <!-- (more precision from reducing heterogeneity in $Y$) -->
     - No systematic differences between groups
     - Known reference distribution for tests of the sharp null and, in large
       samples, the weak null.
     - Unbiased estimators of average causal effects where the distributions of the estimators is also known from the randomization.
   - Instrumental variables (randomized treatment assignment, $Z$,  changes dose of active ingredient, $D$, which changes $Y$)
   - Natural Experiments / Discontinuities (one $X$ creates $Z$ which $\rightarrow D \rightarrow Y$)
   - Semi-/Non-parametric Covariance Adjustment ($Z$ out of our control, but we can choose how to organize and observe given $X$) (matching and difference-in-differences)
   - Parametric covariance adjustment (same as above, but with a model for statistical adjustment, i.e. "controlling for")


# Now: Instruments, the ITT and CACE/LATE

## Instruments, the ITT and CACE/LATE

**Context:** An NGO invites you to help design and evaluate a program to increase donations involving in-person, door-to-door, discussions about the canvasser's own personal experiences. Building rapport with another person should increase willingness to donate, according to the NGO who had just read @broockman2016durably.

\smallskip

**Opportunity for learning about theory** You are interested in
understanding why and how social norms influence behavior. So, you ask to
that canvassers appeal to a descriptive social norm ("other people we have
spoken with agree") toward the end of the discussion.

\smallskip

**Design:** The NGO randomizes visits by canvassers to a set of addresses and
measures the amount pledged online in the following month.

\smallskip

**Analysis:** The NGO cares about the cost effectiveness of the approach. Did
it work? You (and the NGO should care) about **why** it worked (or did not
work).


## Defining causal effects {.fragile}

 - $Z_i$ is random assignment to a visit ($Z_i=1$) or not ($Z_i=0$).
 - $d_{i,Z_i=1}=1$ means that person $i$ would open the door to have a conversation when assigned a visit. 
 - $d_{i,Z_i=1}=0$ means that person $i$ would not open the door to have a conversation when assigned a visit. 
 - Opening the door is an outcome of the treatment.

\begin{center}
\begin{tikzcd}[column sep=large]
Z  \arrow[from=1-1,to=1-2] \arrow[from=1-1, to=1-4, bend left, "\text{0 (exclusion)}"] & d  \arrow[from=1-2,to=1-4] & & y \\
(x_1 \ldots x_p) \arrow[from=2-1,to=1-1, "\text{0 (as if randomized)}"]  \arrow[from=2-1,to=1-2] \arrow[from=2-1,to=1-4]
\end{tikzcd}
\end{center}


## Defining causal effects {.fragile}

 - $y_{i,Z_i = 1, d_{i,Z_i=1}=1}$ is the potential outcome for people who were assigned a visit and who opened the door. ("Compliers" or "Alwaystakers")
 - $y_{i,1, d_{i,Z_i=1}=0}$ is the potential outcome for people who were assigned a visit and who did not open the door. ("Nevertakers" or "Defiers")
 - $y_{i,0, d_{i,0}=1}$ is the potential outcome for people who were not assigned a visit and who opened the door. ("Defiers" or "Always Takers")
 - $y_{i,0, d_{i,0}=0}$ is the potential outcome for people who were not assigned a visit and who would not have opened the door. ("Compliers" or "Nevertakers")


 We could also write $y_{i,Z_i = 0, d_{i,Z_i=1}=1}$ for people who were not
   assigned a visit but who would have opened the door had they been assigned a
   visit etc..

In this case we can simplify our potential outcomes:

  - $y_{i,0, d_{i,1}=1} = y_{i,0, d_{i,1}=0} = y_{i,0, d_{i,0}=0}$ because your outcome is the same regardless of how you don't open the door.


## Defining causal effects

We can simplify the ways in which people get a dose of the treatment like so
(where $d$ is lower case reflecting the idea that whether you open the door
when visited or not is a fixed attribute like a potential outcome).

 -  $Y$ : outcome ($y_{i,T}$ or $y_{i,Z_i=1}$ for potential outcome to
   treatment for person $i$, fixed)
 - $X$ : covariate/baseline variable
 - $Z$ : treatment assignment ($Z_i=1$ if assigned to a visit, $Z_i=0$ if not
   assigned to a visit)
 -  $D$ : treatment received ($D_i=1$ if answered phone, $D_i=0$ if person $i$
   dd not answer the door) (using $D$ here because $D_i = d_{i,1} Z_{i} + d_{i,0} (1-Z_i)$)

We have two causal effects of $Z$: $Z \rightarrow Y$ ($\delta$, ITT, ITT$_Y$), and $Z \rightarrow D$ (GG
call this ITT$_D$).

And different types of people can react differently to the attempt to move the
dose with the instrument.

\centering
\begin{tabular}{llcc}
                       &        & \multicolumn{2}{c}{$Z=1$} \\
		       &       & $D=0$ & $D=1$ \\
		       \midrule
\multirow{2}{*}{$Z=0$} & $D=0$ & Nevertaker & Complier \\
                       & $D=1$ & Defier     & Always taker \\
		       \bottomrule
\end{tabular}


##  Defining causal effects

The $ITT=ITT_Y=\delta= \bar{y}_{Z=1} - \bar{y}_{Z=0}$.

\medskip

But, in this design, $\bar{y}_{Z=1}=\bar{y}_{1}$ is split into pieces: the outcome of
those who answered the door (Compliers and Alwaystakers and Defiers). Write
$p_C$ for the proportion of compliers in the study.

\begin{equation}
\bar{y}_{1}=(\bar{y}_{1}|C)p_C + (\bar{y}_{1}|A)p_A + (\bar{y}_1|N)p_N + (\bar{y}_1|D)p_D.
\end{equation}

And $\bar{y}_{0}$ is also split into pieces:

\begin{equation}
\bar{y}_{0}=(\bar{y}_{0}|C)p_C + (\bar{y}_{1}|A)p_A + (\bar{y}_{0}|N)p_N + (\bar{y}_0|D)p_D.
\end{equation}

\medskip

So, the ITT itself is a combination of the effects of $Z$ on $Y$ within these
different groups (imagine substituting in and then re-arranging so that we
have a set of ITTs, one for each type of subject). But, we can still estimate it because we have unbiased
estimators of $\bar{y}_1$ and $\bar{y}_0$ within each type.

## Learning about the ITT

First, let's learn about the effect of the policy itself. To write down the
ITT, we do not need to consider all of the types above: we have no defiers
($p_D=0$) and we know the ITT for both Alwaystakers and Nevertakers is 0.

\begin{equation}
\bar{y}_{1}=(\bar{y}_{1}|C)p_C + (\bar{y}_{1}|A)p_A + (\bar{y}_1|N)p_N
\end{equation}

\begin{equation}
\bar{y}_{0}=(\bar{y}_{0}|C)p_C + (\bar{y}_{0}|A)p_A + (\bar{y}_{0}|N)p_N
\end{equation}


## Learning about the ITT

First, let's learn about the effect of the policy itself. To write down the
ITT, we do not need to consider all of the types above: we have no defiers
($p_D=0$) and we know the ITT for both Alwaystakers and Nevertakers is 0.


\begin{align}
ITT  & = \bar{y}_{1} - \bar{y}_{0} \\
       & = ( (\bar{y}_{1}|C)p_C + (\bar{y}_{1}|A)p_A + (\bar{y}_1|N)p_N ) - ( (\bar{y}_{0}|C)p_C + (\bar{y}_{0}|A)p_A + (\bar{y}_{0}|N)p_N )  \\
       \intertext{collecting each type together --- to have an ITT for each type}
       & = ( (\bar{y}_{1}|C)p_C -  (\bar{y}_{0}|C)p_C )  +   ( (\bar{y}_{1}|A)p_A - (\bar{y}_{1}|A)p_A ) +  ( (\bar{y}_1|N)p_N  - (\bar{y}_{0}|N)p_N ) \\
       & = \left( (\bar{y}_{1}|C) -  (\bar{y}_{0}|C) \right)p_C   +   \left( (\bar{y}_{1}|A)- (\bar{y}_{0}|A) \right)p_A  +  \left( (\bar{y}_1|N) - (\bar{y}_{0}|N) \right)p_N
\end{align}

## Learning about the ITT

\begin{align}
ITT  & = \bar{y}_{1} - \bar{y}_{0} \\
       & = ( (\bar{y}_{1}|C)p_C + (\bar{y}_{1}|A)p_A + (\bar{y}_1|N)p_N ) - ( (\bar{y}_{0}|C)p_C + (\bar{y}_{0}|A)p_A + (\bar{y}_{0}|N)p_N )  \\
       & = ( (\bar{y}_{1}|C)p_C -  (\bar{y}_{0}|C)p_C )  +   ( (\bar{y}_{1}|A)p_A - (\bar{y}_{1}|A)p_A ) +  ( (\bar{y}_1|N)p_N  - (\bar{y}_{0}|N)p_N ) \\
       & = ( (\bar{y}_{1}|C) -  (\bar{y}_{0}|C))p_C   +   ( (\bar{y}_{1}|A)- (\bar{y}_{0}|A))p_A  +  ( (\bar{y}_1|N) - (\bar{y}_{0}|N) )p_N
\end{align}


And, if the effect of the dose can only occur for those who open the door, and you can only open the door when assigned to do so then:

\begin{equation}
( (\bar{y}_{1}|A)- (\bar{y}_{0}|A))p_A = 0  \text{ and } ( (\bar{y}_1|N) - (\bar{y}_{0}|N) )p_N = 0
\end{equation}

And

\begin{equation}
ITT =  ( (\bar{y}_{1}|C) -  (\bar{y}_{0}|C))p_C  = ( CACE ) p_C.
\end{equation}


## The Complier Average Causal Effect

We would also like to learn about the causal effect of answering the door and
having the conversation, the theoretically interesting effect. But, this
comparison is confounded by $x$: a simple $\bar{Y}|D=1 - \bar{Y}|D=0$
comparison tells us about differences in the outcome due to $x$ in addition to
the difference caused by $D$. (Numbers below from some simulated data)

\begin{center}
\begin{tikzcd}[column sep=large]
Z  \arrow[from=1-1,to=1-2] \arrow[from=1-1, to=1-4, bend left, "\text{0 (exclusion)}"] & D  \arrow[from=1-2,to=1-4] & & y \\
(x_1 \ldots x_p) \arrow[from=2-1,to=1-1, "\text{-.006 (as if randomized)}"]  \arrow[from=2-1,to=1-2, ".06"] \arrow[from=2-1,to=1-4, ".48"]
\end{tikzcd}
\end{center}


```{r cors, eval=FALSE, echo=TRUE, results="hide"}
with(dat, cor(Y, x)) ## can be any number
with(dat, cor(d, x)) ## can be any number
with(dat, cor(Z, x)) ## should be near 0
```

But we just saw that, in this design, and with these assumptions (including a
SUTVA assumption) that $ITT =  ( (\bar{y}_{1}|C) -  (\bar{y}_{0}|C))p_C  = (
CACE ) p_C$ so we can define $CACE=ITT/p_C$.

## A simulation to help us understand the design and analysis

Setting up the simulation and analysis before going into the field.

```{r makedat, echo=TRUE}
library(randomizr)
set.seed(20200730)
n <- 1000
## Make a covariate, like age
xtmp <- rnorm(n, mean = 45, sd = 10)
x <- pmax(xtmp, 18)
## Make potential outcome to control
y0tmp <- round(rnorm(n, mean = 0, sd = 10)) + x / 2
y0 <- pmax(y0tmp, 0)
Z <- complete_ra(n)
## Door opening is a function of x (age) and Z (visits)
probd <- (x - min(x)) / (max(x) - min(x))
# mean(probd)
d <- ifelse(Z == 1, rbinom(sum(Z == 1), prob = probd / 2, size = 1), 0)
table(Z, d, exclude = c())
## Compliance rate (p(d=1))
mean(d[Z == 1])
```


## A simulation to help us understand the design and analysis {.shrink=20}

Setting up the simulation and analysis before going into the field. Notice we have more potential outcomes.


```{r makedat2, echo=TRUE}
## No effects possible if not visited
y0d0 <- y0
y0d1 <- y0
y1d0 <- y0
taubar <- .25 * sd(y0) ## Effect of .25 sds on compliers/door openers
## The treatment also changes variance of y1d1
y1d1 <- mean(y0) + taubar + (y0 - mean(y0)) / 2
## Define observed outcome
Y <- Z * d * y1d1 + Z * (1 - d) * y1d0 + (1 - Z) * d * y0d1 + (1 - Z) * (1 - d) * y0d0
dat <- data.frame(y1d1, y1d0, y0d1, y0d0, y0, Y, Z, d, x, probd)
dat$y1 <- (1 - Z) * y0 + Z * d * y1d1 + Z * (1 - d) * y1d0
dat$y1v2 <- dat$Y[dat$Z == 1]
dat$thetype <- interaction(dat$Z, dat$d, drop = TRUE)
## 0.0 = who would not take a dose if assigned to control (nevertakers and  compliers)
## 1.0 = who would not take a dose if assigned  to  treatment  (nevertakers and defiers)
## 1.1 = who would take a dose if  assigned to treatment  (alwaystakeers and compliers)
## 0.1 = who would take  a dose if assigned to treatment (defiers and alwaystakers)
```

## A simulation to help us understand the design and analysis {.shrink}

Setting up the simulation and analysis before going into the field. Notice we have more potential outcomes.


```{r}
kable(head(dat))
```


## A simulation to help us understand the design and analysis

Setting up the simulation and analysis before going into the field. Notice we have more potential outcomes.

```{r}
dat %>%
  group_by(Z, d) %>%
  summarize(
    meanY = mean(Y),
    sdY = sd(Y),
    n = n()
  )
```


## A simulation to help us understand the design and analysis

```{r bplot1}
boxplot(Y ~ Z * d, data = dat)
```


## Learning about the ITT

First, let's learn about the effect of the policy itself, about the ITT.

```{r echo=TRUE}
## True ITT with one-sided non-compliance
pd <- mean(dat$d[dat$Z == 1])

bary1 <- mean(dat$y1d1) * pd + mean(dat$y1d0) * (1 - pd)
bary0 <- mean(dat$y0)

trueITT <- bary1 - bary0
trueITT
```

**Some questions for later:**

 -  What is our best guess about the ITT itself? How would we assess whether or
not this estimator is biased or not?
 - What evidence do we have against the claim that the policy had no effects? How
would we assess whether this testing procedure is trustworthy --- controls its
false positive error rate?
 - What is our best guess about how our estimate of the ITT would vary from
experiment to experiment?

## Estimating the ITT

If $Z$ is randomized, we can estimate the ITT directly:

```{r, eval=TRUE, echo=TRUE}
taubarhat1 <- with(dat, mean(Y[Z==1]) - mean(Y[Z==0]))
taubarhat2 <- coef(lm(Y~Z))[["Z"]]
library(estimatr)
taubarhat <- difference_in_means(Y ~ Z, data = dat)
setaubarhat <- sqrt(var(Y[Z==1])/sum(Z==1) + var(Y[Z==0])/sum(Z==0))
taubarhat
c(taubarhat1,taubarhat2)
setaubarhat
```
##  Estimating the CACE

The CACE is the same as the LATE (the local average treatment effect). Where
"local" makes us realize that the causal effect is only on some specific kinds
of people --- the compliers.


```{r snip, echo=TRUE}
ITT <- with(dat, mean(Y[Z == 1]) - mean(Y[Z == 0]))
pd <- with(dat, mean(d[Z == 1]) - mean(d[Z == 0])) 
ITT / pd
```

Notice that this estimator of the Complier Average Causal Effect (also known as the Wald estimator or the Bloom estimator) is the same as the two-stage least squares estimator:

```{r 2sls, echo=TRUE}
library(AER)
iv1 <- ivreg(Y ~ d | Z, data = dat)
coef(iv1)["d"]
library(estimatr)
iv2 <- iv_robust(Y ~ d | Z, data = dat)
coef(iv2)
```

## Testing a hypothesis of no effects

```{r testing1,  echo=TRUE, eval=TRUE,cache=TRUE}
newExp <- function(trt) {
  sample(trt)
}
testStat <- function(outcome, trt) {
  mean(outcome[trt == 1]) - mean(outcome[trt == 0])
}
obsTestStat <- testStat(outcome = dat$Y, trt = dat$Z)
nullDist <- replicate(1000, testStat(outcome = dat$Y, trt = newExp(dat$Z)))
lowerP <- mean(nullDist <= obsTestStat)
## OR
library(coin)
dat$ZF <- factor(Z)
meanTest <- oneway_test(Y ~ ZF,
  data = dat, distribution = approximate(nresample = 1000),
  alternative = "greater"
)
pvalue(meanTest)

meanTestAsymp <- oneway_test(Y ~ ZF,
  data = dat, distribution = asymptotic(),
  alternative = "greater"
)
pvalue(meanTestAsymp)

t.test(Y ~ ZF, data = dat, alternative = "greater")$p.value
```

## Estimating the ITT and SE


```{r}

minidat <- dat[sample(1:nrow(dat), 6), ]

minidat$y1 <- minidat$y0 + 50
minidat$Y <- with(minidat, Z * y1 + (1 - Z) * y0)

ap <- summary(lm(Y ~ Z, data = minidat))$coef[2, 4]

myfn <- function() {
  newz <- sample(minidat$Z) # make truth 0
  ## newY <- newz * minidat$y1 + (1-newz)*minidat$y0 # reveal new potential outcomes
  newp <- summary(lm(minidat$Y ~ newz))$coef[2, 4] # test H0: no effects.
  return(newp)
}

res <- replicate(1000, myfn())
```

# Assessing our estimators and tests

## Using DeclareDesign to Assess IV Estimation

```{r dd, eval=TRUE}
library(DeclareDesign)

then <- 1000
summary(dat[, c("y1d1", "y1d0", "y0d1", "y0d0", "y0", "y1", "x", "d", "thetype")])
dat$D <- dat$d
thepop <- declare_population(dat[, c("y1d1", "y1d0", "y0d1", "y0d0", "y0", "y1", "x", "D", "thetype")])
theassign <- declare_assignment(m = then / 2)
po_fun <- function(data) {
  data$Y_Z_1_D_1 <- data$y1d1
  data$Y_Z_0_D_0 <- data$y0d0
  data$Y_Z_1_D_0 <- data$y1d0
  data$Y_Z_0_D_1 <- data$y0d1
  data$Y_Z_0 <- data$y0
  data$Y_Z_1 <- data$y1
  data
}
thepo <- declare_potential_outcomes(handler = po_fun)

reveal_outcomes <- declare_reveal(outcome_variables = Y, assignment_variables = c("Z", "D")) ## how does assignment reveal potential outcomes

thedesign <- thepop + theassign + thepo + reveal_outcomes
oneexp <- draw_data(thedesign)

theestimands <- declare_estimand(
  ITT1 = mean(Y_Z_1 - Y_Z_0),
  CACE = mean(Y_Z_1_D_1 - Y_Z_0_D_0)
)

theestimands(oneexp)

theest1 <- declare_estimator(Y ~ Z,
  estimand = "ITT1", model = difference_in_means, term="Z",
  label = "itt1: diff means"
)
theest2 <- declare_estimator(Y ~ D | Z,
  estimand = "CACE", model = iv_robust, term="D",
  label = "cace1: iv"
)
theest3 <- declare_estimator(Y ~ D + x | Z + x,
  estimand = "CACE", model = iv_robust, term="D",
  label = "cace2: iv+x"
)
theest4 <- declare_estimator(Y ~ D | Z + x,
  estimand = "CACE", model = iv_robust, term="D",
  label = "cace3: iv+x v2"
)

thedesign_plus_est <- thedesign + theestimands + theest1 + theest2 + theest3 + theest4
theest1(oneexp)
theest2(oneexp)
theest3(oneexp)
theest4(oneexp)

thediagnosands <- declare_diagnosands(
  bias = mean(estimate - estimand),
  rmse = sqrt(mean((estimate - estimand)^2)),
  power = mean(p.value < .25),
  coverage = mean(estimand <= conf.high & estimand >= conf.low),
  mean_estimate = mean(estimate),
  sd_estimate = sd(estimate),
  mean_se = mean(std.error),
  mean_estimand = mean(estimand)
)
```

```{r dd1, cache=TRUE, eval=TRUE, echo=TRUE}
set.seed(12345)
diagnosis <- diagnose_design(thedesign_plus_est,
  sims = 1000, bootstrap_sims = 0,
  diagnosands = thediagnosands
)
kable(reshape_diagnosis(diagnosis)[, -c(1:2, 4,6,7,13,14)])
```

## What about standard errors?

What is $Var( \hat{\delta}_c/\hat{p}_c)$? Why wouldn't it be a ratio of
standard errors? How would we check to see if we agreed with `ivreg` or `iv_robust`?

# A Testing Approach

## Summary of the Day

## References

