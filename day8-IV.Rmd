---
title: Statistical Inference for Causal Quantities when the Active Ingredient is not Random
date: '`r format(Sys.Date(), "%B %d, %Y")`'
author: ICPSR 2019 Session 2
bibliography:
 - refs.bib
 - BIB/master.bib
 - BIB/misc.bib
fontsize: 10pt
geometry: margin=1in
graphics: yes
biblio-style: authoryear-comp
output:
  beamer_presentation:
    slide_level: 2
    keep_tex: true
    latex_engine: xelatex
    citation_package: biblatex
    template: icpsr.beamer
    incremental: true
    includes:
        in_header:
           - defs-all.sty
---


<!-- Make this document using library(rmarkdown); render("day12.Rmd") -->


```{r include=FALSE, cache=FALSE}
# Some customization.  You can alter or delete as desired (if you know what you are doing).
# knitr settings to control how R chunks work.
rm(list=ls())

require(knitr)

## This plus size="\\scriptsize" from https://stackoverflow.com/questions/26372138/beamer-presentation-rstudio-change-font-size-for-chunk

knitr::knit_hooks$set(mysize = function(before, options, envir) {
  if (before)
    return(options$size)
                              else return("\\normalsize")
})

knit_hooks$set(plotdefault = function(before, options, envir) {
    if (before) par(mar = c(3, 3, .1, .1),oma=rep(0,4),mgp=c(1.5,.5,0))
})

opts_chunk$set(
  tidy=FALSE,     # display code as typed
  echo=TRUE,
  results='markup',
  strip.white=TRUE,
  fig.path='figs/fig',
  cache=FALSE,
  highlight=TRUE,
  width.cutoff=132,
  size='\\scriptsize',
  out.width='.8\\textwidth',
  fig.retina=FALSE,
  message=FALSE,
  comment=NA,
  mysize=TRUE,
  plotdefault=TRUE)

if(!file.exists('figs')) dir.create('figs')

options(digits=4,
	scipen=8,
	width=132
	)
```

```{r eval=FALSE, include=FALSE, echo=FALSE}
## Run this only once and then not again until we want a new version from github
library('devtools')
library('withr')
with_libpaths('./lib', install_github("markmfredrickson/RItools"), 'pre')
```

```{r echo=FALSE}
library(dplyr)
library(RItools,lib.loc="./lib")
```

## Today

\begin{enumerate}
\item Agenda: Recap of the Estimation approach to Causal Inference with
Instruments, Walk through a testing based approach.
\item Reading for tomorrow from "Principled Search for designs with ignorable
assignment" on the Syllabus. DOS Chapter 1, Chapter 6 in Dunning, Hansen and
Sales 2015, Hansen and Bowers 2008. We are beginning the "Found experiments" section
of the course.
\item Questions arising from the reading or assignments or life?
%\item Recap:
\end{enumerate}

# But first: Where are we and where are we going?

## Research designs to aid the creation of interpretable comparisons

   - Randomized experiments (randomized $Z$ changes $y$) <!-- (more precision from reducing heterogeneity in $Y$) -->
     - No systematic differences between groups
     - Known reference distribution for tests of the sharp null and, in large
       samples, the weak null.
   - Instrumental variables (randomized $Z$ changes $D$ which changes $y$)
   - Natural Experiments / Discontinuities (one $X$ creates $Z$ which \ldots)
   - Semi-/Non-parametric Covariance Adjustment ($Z$ out of our control, but we can choose how to organize and observe given $X$) (matching and difference-in-differences)
   - Parametric covariance adjustment (same as above, but with a model for statistical adjustment, i.e. "controlling for")


# Now: Instruments, the ITT and CACE/LATE



## A simulation to understand the design and analysis

Setting up the simulation and analysis before going into the field.

```{r}
library(randomizr)
set.seed(20180730)
n <- 1000
## Make a covariate, like age
xtmp <- rnorm(n,mean=45,sd=10)
x <- pmax(xtmp,18)
## Make potential outcome to control
y0tmp <- round(rnorm(n,mean=0,sd=10)) + x/2
y0 <- pmax(y0tmp,0)
Z <- complete_ra(n)
## Door opening is a function of x (age) and Z (visits)
probd <- ( x-min(x) )/( max(x) - min(x) )
mean(probd)
d <- ifelse(Z==1, rbinom(sum(Z==1),prob=probd/2,size=1), 0)
table(Z,d,exclude=c())
mean(d[Z==1])
```
## A simulation to understand the design and analysis

Setting up the simulation and analysis before going into the field.

```{r}
## No effects possible if not visited
y0d0 <- y0
y0d1 <- y0
y1d0 <- y0
taubar <- .25*sd(y0) ## Effect of .25 sds on compliers/door openers
## The treatment also changes variance of y1d1
y1d1 <- mean(y0) + taubar + (y0 - mean(y0))/2
## Define observed outcome
Y <-  Z*d*y1d1 + Z*(1-d)*y1d0 + (1-Z)*d*y0d1 + (1-Z)*(1-d)*y0d0
dat <- data.frame(y1d1,y1d0,y0d1,y0d0,y0,Y,Z,d,x,probd)
dat$y1 <- dat$Y[dat$Z==1]
dat$thetype <-  interaction(dat$Z,dat$d,drop=TRUE)
##  0.0 = who would not take a dose if assigned to control (nevertakers and  compliers)
## 1.0 = who would not take a dose if assigned  to  treatment  (nevertakers and defiers)
## 1.1 = who would take a dose if  assigned to treatment  (alwaystakeers and compliers)
## 0.1 = who would take  a dose if assigned to treatment (defiers and alwaystakers)

```

```{r}
dat %>% group_by(Z,d) %>% summarize(meanY=mean(Y),
				    sdY=sd(Y),
				    n=n())

```


## A simulation to understand the design and analysis

```{r}
boxplot(Y~Z*d,data=dat)
```

## Defining causal effects for the Adams and Smith (1980) Study

 -  $Y$ : outcome ($y_{i,T}$ or $y_{i,Z_i=1}$ for potential outcome to
   treatment for person $i$, fixed)
 - $X$ : covariate/baseline variable
 - $Z$ : treatment assignment ($Z_i=1$ if assigned to a call, $Z_i=0$ if not
   assigned to a call)
 -  $D$ : treatment received ($D_i=1$ if answered phone, $D_i=0$ if person $i$
   dd not answer the phone.)

We have two causal effects: $Z \rightarrow Y$ ($\delta$, ITT, ITT$_Y$), and $Z \rightarrow D$ (GG
call this ITT$_D$).

And different types of people can react differently to the attempt to move the
dose with the instrument.

\centering
\begin{tabular}{llcc}
                       &        & \multicolumn{2}{c}{$Z=1$} \\
		       &       & $D=0$ & $D=1$ \\
		       \midrule
\multirow{2}{*}{$Z=0$} & $D=0$ & Nevertaker & Complier \\
                       & $D=1$ & Defier     & Always taker \\
		       \bottomrule
\end{tabular}

##  Defining causal effects

The $ITT=ITT_Y=delta= \bar{y}_{Z=1} - \bar{y}_{Z=0}$.

\medskip

But, in this design, $\bar{y}_{Z=1}=\bar{y}_{1}$ is split into two pieces: the outcome of
those who answered the phone (Compliers and Alwaystakers and Defiers). Write
$p_C$ for the proportion of compliers in the study.

$$ \bar{y}_{1}=(\bar{y}_{1}|C)p_C + (\bar{y}_{1}|A)p_A + (\bar{y}_1|N)p_N + (\bar{y}_1|D)p_D $$.

And $\bar{y}_{0}$ is also split into pieces:

$$ \bar{y}_{0}=(\bar{y}_{0}|C)p_C + (\bar{y}_{1}|A)p_A + (\bar{y}_{0}|N)p_N + (\bar{y}_0|D)p_D $$.

\medskip

So, the ITT itself is a combination of the effects of $Z$ on $Y$ within these
different groups (imagine substituting in and then re-arranging so that we
have a set of ITTs, one for each type of subject). But, we can still estimate it because we have unbiased
estimators of $\bar{y}_1$ and $\bar{y}_0$.

## Learning about the ITT

First, let's learn about the effect of the policy itself, about the ITT. To
write down the ITT, we do not need to consider all of the types above. For
example, we have no defiers ($ p_D=0 $) and that the ITT for both
Alwaystakers and Nevertakers is 0.

So:

$$\bar{y}_{1}=(\bar{y}_{1}|C)p_C + (\bar{y}_{1}|A)p_A + (\bar{y}_1|N)p_N$$.

$$\bar{y}_{0}=(\bar{y}_{0}|C)p_C + (\bar{y}_{0}|A)p_A + (\bar{y}_{0}|N)p_N$$.


\begin{align}
ITT  & = \bar{y}_{1} - \bar{y}_{0} \\
       & = ( (\bar{y}_{1}|C)p_C + (\bar{y}_{1}|A)p_A + (\bar{y}_1|N)p_N ) - ( (\bar{y}_{0}|C)p_C + (\bar{y}_{0}|A)p_A + (\bar{y}_{0}|N)p_N )  \\
       & = ( (\bar{y}_{1}|C)p_C -  (\bar{y}_{0}|C)p_C )  +   ( (\bar{y}_{1}|A)p_A - (\bar{y}_{1}|A)p_A ) +  ( (\bar{y}_1|N)p_N  - (\bar{y}_{0}|N)p_N ) \\
       & = ( (\bar{y}_{1}|C) -  (\bar{y}_{0}|C))p_C   +   ( (\bar{y}_{1}|A)- (\bar{y}_{0}|A))p_A  +  ( (\bar{y}_1|N) - (\bar{y}_{0}|N) )p_N
\end{align}

## Learning about the ITT

\begin{align}
ITT  & = \bar{y}_{1} - \bar{y}_{0} \\
       & = ( (\bar{y}_{1}|C)p_C + (\bar{y}_{1}|A)p_A + (\bar{y}_1|N)p_N ) - ( (\bar{y}_{0}|C)p_C + (\bar{y}_{0}|A)p_A + (\bar{y}_{0}|N)p_N )  \\
       & = ( (\bar{y}_{1}|C)p_C -  (\bar{y}_{0}|C)p_C )  +   ( (\bar{y}_{1}|A)p_A - (\bar{y}_{1}|A)p_A ) +  ( (\bar{y}_1|N)p_N  - (\bar{y}_{0}|N)p_N ) \\
       & = ( (\bar{y}_{1}|C) -  (\bar{y}_{0}|C))p_C   +   ( (\bar{y}_{1}|A)- (\bar{y}_{0}|A))p_A  +  ( (\bar{y}_1|N) - (\bar{y}_{0}|N) )p_N
\end{align}


And, if the effect of the dose can only occur for those who open the door, and you can only open the door/pick up the phone when assigned to do so then: 

$$ ( (\bar{y}_{1}|A)- (\bar{y}_{0}|A))p_A = 0  \text{ and } ( (\bar{y}_1|N) - (\bar{y}_{0}|N) )p_N = 0 $$.

And

$$ ITT =  ( (\bar{y}_{1}|C) -  (\bar{y}_{0}|C))p_C  = ( CACE ) p_C$$.


## Some practice with code: How would you answer these questions?

\smallskip

What evidence do we have against the claim that the policy had no effects? How
would we assess whether this testing procedure is trustworthy --- controls its
false positive error rate?

\smallskip

What is our best guess about the ITT itself? How would we assess whether or
not this estimator is biased or not?

\smallskip

What is our best guess about how our estimate of the ITT would vary from
experiment to experiment?


## Some code notes

### Testing a hypothesis of no effects

```{r, eval=FALSE}
newExp <- function(trt){ sample(trt) }
testStat <- function(outcome,trt){  mean(outcome[trt==1]) - mean(outcome[trt==0]) }
obsTestStat <- testStat(outcome=dat$Y,trt=dat$Z)
nullDist <- replicate(1000,testStat(outcome=dat$Y,trt=newExp(dat$Z)))
upperP <- mean(nullDist >= obsTestStat)
upperP
## OR
library(coin)
dat$ZF<- factor(Z)
meanTest <- oneway_test(Y~ZF,data=dat,distribution=approximate(B=1000),
			alternative="less")
pvalue(meanTest)

meanTestAsymp <- oneway_test(Y~ZF,data=dat,distribution=asymptotic(),
			alternative="less")
pvalue(meanTestAsymp)

t.test(Y~ZF,data=dat,alternative="less")$p.value

```

## Estimating the ITT and SE


```{r, eval=FALSE}
taubarhat <- with(dat, mean(Y[Z==1]) - mean(Y[Z==0]))
## or taubarhat <- coef(lm(Y~Z))[["Z"]]
library(estimatr)
taubarhat <- difference_in_means(Y~Z,data=dat)
setaubarhat <- sqrt( var(Y[Z==1])/sum(Z==1) + var(Y[Z==0])/sum(Z==0) )
```

```{r}

minidat <- dat[sample(1:nrow(dat),6),]

minidat$y1 <- minidat$y0 + 50
minidat$Y <- with(minidat, Z*y1 + (1-Z)*y0)

ap <- summary(lm(Y~Z,data=minidat))$coef[2,4]

myfn <- function(){
	newz <- sample(minidat$Z) # make truth 0
	##newY <- newz * minidat$y1 + (1-newz)*minidat$y0 # reveal new potential outcomes
	newp <- summary(lm(minidat$Y~newz))$coef[2,4] # test H0: no effects.
	return(newp)
}

res <- replicate(1000,myfn())
```


## How would you assess these procedures?

How would we check to see if this is a good estimator? (What does "good
estimator" mean anyway?)

\medskip

How would we check to see if this is a good test? (What does "good test" mean
anyway?)

## Using DeclareDesign to Assess IV Estimation

```{r eval=FALSE}
library(DeclareDesign)

then <- 1000

summary(dat[,c("y1d1","y1d0","y0d1","y0d0","y0","y1","x","d","thetype")])

dat$D <- dat$d

thepop <- declare_population(dat[,c("y1d1","y1d0","y0d1","y0d0","y0","y1","x","D","thetype")])
theassign <- declare_assignment(m=then/2)

po_fun <- function(data){
	data$Y_Z_1_D_1 <- data$y1d1
	data$Y_Z_0_D_0 <- data$y0d0
	data$Y_Z_1_D_0 <- data$y1d0
	data$Y_Z_0_D_1 <- data$y0d1
	data$Y_Z_0 <-  data$y0
	data$Y_Z_1 <-  data$y1
	data
}
thepo <- declare_potential_outcomes(handler=po_fun)

reveal_outcomes <- declare_reveal(outcome_variables=Y,assignment_variables=c("Z","D")) ## how does assignment reveal potential outcomes

## From  DeclareDesign blog  about IV
##  declare_step(
##    U1_complier = X_U1_0_Z_0 == 0 & X_U1_0_Z_1 == 0 & X_U1_1_Z_0 == 1 & X_U1_1_Z_1 == 1,
 ##   Z_complier  = X_U1_0_Z_0 == 0 & X_U1_1_Z_0 == 0 & X_U1_0_Z_1 == 1 & X_U1_1_Z_1 == 1, 
  ##  handler = fabricate) +


thedesign <- thepop + theassign + thepo + reveal_outcomes

oneexp <- draw_data(thedesign)

theestimands <- declare_estimand(ITT1 = mean(Y_Z_1 - Y_Z_0),
				 CACE = mean(Y_Z_1_D_1 - Y_Z_0_D_0),
				 CACE2=mean(Y_Z_1[D==1] - Y_Z_0[D==0]))

theest1 <- declare_estimator(Y~Z, estimand="ITT1", model=difference_in_means,
			     label="itt1: diff means")
theest2 <- declare_estimator(Y~D|Z, estimand="CACE", model=iv_robust,
			     label="cace1: iv")
theest3 <- declare_estimator(Y~D+x|Z+x, estimand="CACE", model=iv_robust,
			     label="cace2: iv+x")
theest4 <- declare_estimator(Y~D|Z+x, estimand="CACE", model=iv_robust,
			     label="cace3: iv+x v2")

thedesign_plus_est <- thedesign + theestimands + theest1 + theest2 + theest3 + theest4
theest1(oneexp)
theest2(oneexp)
theest3(oneexp)
theest4(oneexp)

set.seed(12345)
thediagnosands <- declare_diagnosands(
     bias = mean(estimate - estimand),
     rmse = sqrt(mean((estimate - estimand) ^ 2)),
     power = mean(p.value < .25),
     coverage = mean(estimand <= conf.high & estimand >= conf.low),
     mean_estimate = mean(estimate),
     sd_estimate = sd(estimate),
     mean_se = mean(std.error),
     mean_estimand = mean(estimand)
     )

diagnosis <- diagnose_design(thedesign_plus_est,sims=1000,bootstrap_sims=0,
			     diagnosands = thediagnosands)
kable(reshape_diagnosis(diagnosis)[,-c(1:2,4)])

```



## The Complier Average Causal Effect or Local Average Treatment Effect (on the Compliers)

Now we would like to learn about the causal effect of answering the door and having the
conversation, the theoretically interesting effect. But, this comparison is confounded
by $x$ (tells us about differences in the outcome due to $x$ in addition to
the difference caused by $D$).

```{r}
with(dat,cor(Y,x))
with(dat,cor(d,x))
with(dat,cor(Z,x)) ## should be near 0
```


## Identifying the causal effect of opening the door

From above, and yesterday (and in the reading) we learned that we can write
the CACE as $CACE = ITT/\text{proportion of compliers}$

## Code snippets

```{r}
ITT <- with(dat,mean(Y[Z==1]) - mean(Y[Z==0]))
pc <- with(dat, mean(d[Z==1]) - mean(d[Z==0]))
ITT/pc

library(AER)
iv1 <- ivreg(Y~d | Z, data=dat)

library(estimatr)

iv2 <- iv_robust(Y~d | Z, data=dat)

```

## What about standard errors?

What is $Var( \hat{\delta}_c/\hat{p}_c)$? Why wouldn't it be a ratio of
standard errors? How would we check to see if we agreed with `ivreg`?

# A Testing Approach

## Summary of the Day

## References

