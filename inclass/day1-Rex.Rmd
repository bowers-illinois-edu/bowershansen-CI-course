---
title: Exercises for day 1
author: |
  | ICPSR 2025 Session 1
  | Jake Bowers \& Ben Hansen
date: '\today'
pdf_document:
    keep_tex: true
    latex_engine: pdflatex
    includes:
       in_header: styles/handout-preamble.tex
---

# Entering a small data set directly into R

Suppose a coffee experiment paralleling Fisher's tea-tasting study.  To enter the data directly into R, do:
```r
> z = scan(nlines=1)
1:  1 1 1 1 0 0 0 0
```
That is, type "`z = scan(nlines=1)`" at the "`>`" prompt in your R console. You'll be 
greeted with a "`1:`," followed by the cursor. Then you'll type in 
```r
1 1 1 1 0 0 0 0 <Enter-key>
```
and be greeted by a fresh "`>`" prompt at the next line. 

Fisher doesn't say how many cups the lady classified correctly.  Supposing it was 3: 
```r
> y = scan(nlines=1)
1:  1 1 1 0 1 0 0 0
```

Tidying up, 
```r
> coffee = data.frame(z, y)
> rm(z,y)
```
The variables \texttt{z} and \texttt{y} are now bound together in the \texttt{coffee} data frame. 

The above sequence of commands won't work if you select and copy them from this document and then paste them into R; nor should you use them in scripts.
However, each block of R code *below* can be cut-and-pasted into your R session.  Check your data-entry work by cutting and pasting the below.

```{r, echo=FALSE}
coffee = data.frame(z=rep(1:0, each=4), y=c(rep(1,3), 0, 1, rep(0,3)))
## same result as
## coffee = data.frame(z=c(1,1,1,1,0,0,0,0),
##                     y=c(1,1,1,0,1,0,0,0) )
## but with a little less risk of data entry error
```
```{r}
table(coffee)
```



# A test statistic and its distribution under the strict null

## Fisher's test statistic \& its representation under Fisher's strict null

Fisher's (1935) test statistic was the number of milk-first cups that were
correctly identified as belong to the milk-first group.  Translating
to our coffee experiment, and today's causal jargon, the number of
treatment-group cups that were identified as having received the treatment, $\mathbf{Z}^{\top}\mathbf{y} = \sum_{i}
Z_{i} y_{i}$.  

Due to the random assignment,
$\mathbf{Z} = (Z_{1}, Z_{2}, \ldots, Z_{n})$ is a random vector,
equally likely come out as any length-8 binary sequence containing 4
ones.  The realization of $Z$ that was obtained in the experiment is
denoted $z$.

According to Fisher's strict null hypothesis, the labels that
our experimental subject would eventually assign to cups was in no way
influenced by the treatment.  They may be encoded in a vector of
constants: $\mathbf{y} = (y_{1}, y_{2}, \ldots, y_{n})$.  

Other test statistics are also possible.  For example, the proportion
of the focal-group cups that were correctly identified is
$\mathbf{Z}^{\top}\mathbf{y}/n_1$, where $n_{1}$ is the design constant $\sum_{i} Z_{i}$, here
4.  Another possibility would be the difference in proportions of
focal and non-focal group cups that were identified as being in the
focal group, $\mathbf{Z}^{\top}\mathbf{y}/n_{1} -
(1-\mathbf{Z})'\mathbf{y}/n_{0}$, where $n_{0}= \sum_{i} 1- Z_{i} =4$.
We'll see later that these apparent alternatives will turn out to be
equivalent in a certain sense.

## Realized value of Fisher's test statistic

The realized value of Fisher's test statistic is $\mathbf{z}^{\top}\mathbf{y}$.  It is computed as
```{r}
with(coffee, sum(z*y))
```
or, to use an R function mirroring our notation,
```{r}
with(coffee, crossprod(z, y)) # beware: crossprod() returns **matrices** (of dim (1,1))
with(coffee, crossprod(z, y)[1,1]) #to return a length-1 vector instead
```


(Had our test statistic been the \textit{proportion} of focal-group
cups that were correctly identified, we would compute its realized
value as 
```{r}
with(coffee, sum(z*y)/sum(z))
```
.)

## Two ways to get p-values

Assuming that the test statistic $T$ has been defined in such a way that
larger values are more favorable to the proposition we're out to get
evidence for, the $p$ value is $\mathrm{P}(T \geq t)$, where $t$ is
the value of $T$ that was actually obtained.  (This is a one-sided
p-value, the kind Fisher liked.  If you prefer the two-sided kind, it's recommended that you get the
hang of his way of doing things before going back to translate.)

## Approximate p-values by simulation

To simulate from the null distribution of a test statistic, use
\texttt{sample} to randomly permute, i.e. shuffle, the entries in $z$.

```{r}
with(coffee, sum(z*y))
coffee$z ; sample(coffee$z)
with(coffee, sum(sample(z)*y))
with(coffee, sum(sample(z)*y))
with(coffee, replicate(3, sum(sample(z)*y)))
simT = with(coffee, replicate(1000, sum(sample(z)*y)))
```

(If you re-run this code expect to see somewhat different output, due to the difference between your computer's random shuffles and mine.)  This says that the null distribution of $T = \mathbf{Z}^{\top}\mathbf{y}$ can be approximated as

```{r}
round(table(simT)/1000, 2)
```

To calculate the corresponding approximate, one-sided p-value, $\mathrm{Pr}(T\geq a)$, at the command line, do
```{r}
actualT = with(coffee, sum(z*y))
mean( simT >= actualT )
```
The analogous two-sided p-value, following the general definition of
the two-sided p-value as $2\min\big( \mathrm{Pr}(T\leq a),
\mathrm{Pr}(T\geq a) \big)$, is 
```{r}
2*min( mean( simT <= actualT ), mean( simT >= actualT ) )
```
With $N$ simulations, the error of approximation for a quantities of the form $P(T \geq a)$
can itself be approximated as $1/\sqrt{N}$: in this case,
`r round(1/sqrt(1000), 2)`.  So the simulation approximation to
our one-sided $p$-value is `r sum(simT==4)/1000` $\pm$ `r round(1/sqrt(1000), 2)`.


## Exercises

1. Replicate this analysis for yourself, but using different choices of
$N$: a few small runs first, and then one that's large enough to
double the precision of what was just shown. (How large is that?)
2. Compare your simulation-based *p*-value to p-values from `fisher.test(z,y, alternative=foo)`, where `foo` is whichever of "`greater`", "`less`" or "`two.sided`" you find most appropriate.  (You can experiment in order to decide.) Do `fisher.test()` and the simulation you just did agree to within the precision limit you had calculated?
3. For this data set, are the chi-square test and the fisher test
  both admissible? (Hint: read R's warnings and documentation.  Can
  you remember the conditions for the chi-square test for two-way
  tables, from a previous stats class?) 

Code hints:
```r
with(coffee, fisher.test(z, y))
with(coffee, chisq.test(z, y))
```

\pagebreak

# Normal-theory p-values

You may have at some point studied the Central Limit Theorem, which
says that if you draw a sufficiently large sample $\mathbf{s}$ of pebbles from an urn containing many more pebbles, each
of which is marked
with a number, then the probability distribution of the mean
pebble-number in your sample, $\bar{Y}
= \frac{1}{|s|} \sum_{i \in \mathbf{s}} Y_{i}$, is approximately Normal in
shape.  To express this sample mean in a notation mirroring the
present one, let $n$ be the number of pebbles in the
entire urn, and let   $\mathbf{Z} = (Z_{1}, Z_{2}, \ldots, Z_{N})$ be
a random vector distributed uniformly on sequences of exactly $n_{1}$ ones
and $n_{0}$ zeroes, $n = n_{1} + n_{0}$.  The sample mean can be
written $n_{1}^{-1} \mathbf{Z}^{\top}\mathbf{y}$.


Even though our "urn" has only $2n$ pebbles, there's a
version of the central limit theorem that applies to it,  i.e. to
$\frac{1}{4} \mathbf{Z}^{\top}\mathbf{y}$ \cite{li+Deng17CLTsforCI}.  On the other
hand our $n$ is fairly small.  Let's investigate the quality of the
Normal approximation.

Normal curves are described by their means and variances (or standard
deviations, i.e. square-rooted variances).

### More exercises

In each of the below, assume the hypothesis
of strictly no effect to be true. \\

4. Use your simulation to approximate $\mathrm{E} n_{1}^{-1}\mathbf{Z}^{\top}\mathbf{y}$ and
  $\mathrm{Var}(n_{1}^{-1}\mathbf{Z}^{\top}\mathbf{y})$. 
5.  Calculate $\mathrm{E} n_{1}^{-1}\mathbf{Z}^{\top}\mathbf{y}$, the exact expected value of the
  sample mean, from first principles.  
6. In this setup, $\mathrm{Var}\, n_{1}^{-1}\mathbf{Z}^{\top}\mathbf{y}  = n_{1}^{-1}
  \frac{n_{0}}{n} \frac{\sum_{i=1}^{n} (y_{i} - \bar y)^{2}}{n-1}$.
  If you've studied sampling theory, you may previously have seen this formula, perhaps in a different notation.  In any other statistics course you may have taken, however, the sampling
 variance of the sample mean would have been presented as
  $$
  \mathrm{Var} \bar{y} = \frac{\sigma_{y}^{2}}{n_{1}} = \frac{1}{n_{1}}
  \frac{\sum_{i=1}^{n} (y_{i} - \bar y)^{2}}{n} 
  $$
--- a formula that's similar but not equivalent to ours. In those other courses
it would also have been assumed that 
$\{i: Z_i =1\}$ was sampled from an "infinite superpopulation," as opposed
to from the finite "population" $\{1,2, \ldots, n \}$.   
Which of the two formulas gives a larger value?  Explain why it makes
sense that the formula we've given would differ the direction it does
from this other formula, in terms of the difference between this
sampling situation and the sampling model that more commonly
accompanies the Central Limit Theorem.
7. Calculate $\mathrm{Var}\, n_{1}^{-1}\mathbf{Z}^{\top}\mathbf{y}$ using the appropriate
  formula. 
8. Determine the normal theory approximation to
  $\mathrm{Pr}_{0}(n_{1}^{-1}\mathbf{Z}^{\top}\mathbf{y} =1 )$.  (To do this in R, use
  \texttt{pnorm()}; type \texttt{?pnorm} for help. It's a good idea to
  check your answer against some 
  more user-friendly Normal table; you'll find one of these quickly
  using any search engine.)


\begin{thebibliography}{1}
\bibitem{fisher:1935}
R.~A. Fisher.
\newblock {\em Design of Experiments}.
\newblock Oliver and Boyd, Edinburgh, 1935.

\bibitem{li+Deng17CLTsforCI}
Xinran Li and Peng Ding.
\newblock General forms of finite population central limit theorems with
  applications to causal inference.
\newblock {\em Journal of the American Statistical Association}, 2017.
\end{thebibliography}
