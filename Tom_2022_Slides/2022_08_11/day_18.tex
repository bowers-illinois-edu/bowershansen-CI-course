%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Beamer Presentation
% LaTeX Template
% Version 1.0 (10/11/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%------------------------------------------------------------------------------------------------
%	PACKAGES AND THEMES
%------------------------------------------------------------------------------------------------

\documentclass[table, xcolor = {dvipsnames}, 9pt]{beamer}
\usepackage{tikz}
\usetikzlibrary{calc}
\usetikzlibrary{positioning}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{external}
\mode<presentation> {

% The Beamer class comes with a number of default slide themes
% which change the colors and layouts of slides. Below this is a list
% of all the themes, uncomment each in turn to see what they look like.

\usetheme{default}
%\usetheme{AnnArbor}
%\usetheme{Antibes}
%\usetheme{Bergen}
%\usetheme{Berkeley}
%\usetheme{Berlin}
%\usetheme{Boadilla}
%\usetheme{CambridgeUS}
%\usetheme{Copenhagen}
%\usetheme{Darmstadt}
%\usetheme{Dresden}
%\usetheme{Frankfurt}
%\usetheme{Goettingen}
%\usetheme{Hannover}
%\usetheme{Ilmenau}
%\usetheme{JuanLesPins}
%\usetheme{Luebeck}
%\usetheme{Madrid}
\usetheme{metropolis}
%\usetheme{Malmoe}
%\usetheme{Marburg}
%\usetheme{Montpellier}
%\usetheme{PaloAlto}
%\usetheme{Pittsburgh}
%\usetheme{Rochester}
%\usetheme{Singapore}
%\usetheme{Szeged}
%\usetheme{Warsaw}

% As well as themes, the Beamer class has a number of color themes
% for any slide theme. Uncomment each of these in turn to see how it
% changes the colors of your current slide theme.

%\usecolortheme{albatross}
%\usecolortheme{beaver}
%\usecolortheme{beetle}
%\usecolortheme{crane}
%\usecolortheme{dolphin}
%\usecolortheme{dove}
%\usecolortheme{fly}
%\usecolortheme{lily}
%\usecolortheme{orchid}
%\usecolortheme{rose}
\usecolortheme{seagull}
%\usecolortheme{seahorse}
%\usecolortheme{whale}
%\usecolortheme{wolverine}
\usefonttheme{professionalfonts}
%\setbeamertemplate{footline} % To remove the footer line in all slides uncomment this line
%\setbeamertemplate{footline}[page number] % To replace the footer line in all slides with a simple slide count uncomment this line

%\setbeamertemplate{navigation symbols}{} % To remove the navigation symbols from the bottom of all slides uncomment this line
}

\usepackage{graphicx} % Allows including images
\usepackage{booktabs} % Allows the use of \toprule, \midrule and \bottomrule in tables
\usepackage{tikz}
\usepackage{multirow}
\usepackage{natbib}
\usepackage{hyperref}
\usepackage{diagbox}
\usepackage{makecell}
\usepackage{xparse}
\usepackage{subfig}
\usepackage{amsmath}
\usepackage{amsfonts,amsthm,amsmath,amssymb}    
\usepackage{bbm}
\usepackage{bm}
\usepackage{empheq}
\usepackage{pgfplots}
\usepackage{animate}
\usepgfplotslibrary{colorbrewer}

\newcommand\mybox[2][]{\tikz[overlay]\node[fill=lightgray,inner sep=2pt, anchor=text, rectangle, rounded corners=1mm,#1] {#2};\phantom{#2}}
\hypersetup{unicode=true,
            bookmarksnumbered=true,
            bookmarksopen=true,
            bookmarksopenlevel=2,
            breaklinks=false,
            pdfborder={0 0 1},
            hypertexnames=false,
            pdfstartview={XYZ null null 1}}
\usepackage{xcolor}
\newcommand\myheading[1]{%
  \par\bigskip
  {\Large\bfseries#1}\par\smallskip}
\newcommand\given[1][]{\:#1\vert\:}
\theoremstyle{plain}
\newtheorem{thm}{Theorem}
\newtheorem{prop}{Proposition\thisthmnumber}
\newtheorem{lem}{Lemma\thisthmnumber}
\newtheorem{cor}{Corollary}
\newtheorem{defin}{Definition}
\newtheorem{algo}{Algorithm}
\newcommand*\diff{\mathop{}\!\mathrm{d}}
\newcommand*\Diff[1]{\mathop{}\!\mathrm{d^#1}}
\newcommand{\thisthmnumber}{}
\newcommand{\tikzmark}[1]{\tikz[baseline,remember picture] \coordinate (#1) {};}
\newcommand*{\QEDA}{\hfill\ensuremath{\blacksquare}}%
\newcommand*{\QEDB}{\hfill\ensuremath{\square}}%
\DeclareMathOperator{\E}{\rm{E}}
\DeclareMathOperator{\R}{\mathbb{R}}
\DeclareMathOperator{\N}{\mathbb{N}}
\DeclareMathOperator{\Var}{\rm{Var}}
\DeclareMathOperator{\Cov}{\rm{Cov}}
\DeclareMathOperator{\Supp}{\rm{Supp}}
\DeclareMathOperator{\e}{\rm{e}}
\DeclareMathOperator{\F}{\mathcal{F}}
\DeclareMathOperator{\Z}{\mathcal{Z}}
\DeclareMathOperator{\logit}{\rm{logit}}
\DeclareMathOperator{\indep}{{\perp\!\!\!\perp}}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
%\DeclareMathOperator{\Pr}{\rm{Pr}}
%------------------------------------------------------------------------
%	TITLE PAGE
%-----------------------------------------------------------------------
\pagestyle{empty}
\title[]{Sensitivity Analysis for Weak Null} % The short title appears at the bottom of every slide, the full title is only on the title page

\author{Thomas Leavitt} % Your name
\institute[] % Your institution as it will appear on the bottom of every slide, may be shorthand to save space
{ % Your institution for the title page
\medskip
\textit{} % Your email address
}
\date{August 11, 2022} % Date, can be changed to a custom date

\NewDocumentEnvironment{statement}{mo}
 {%
  \IfValueT{#2}{\renewcommand{\thisthmnumber}{ #2}}\begin{#1}%
 }
 {\end{#1}}

\begin{document}

\begin{frame}
\titlepage % Print the title page as the first slide
\end{frame}

%\begin{frame}
%\frametitle{Overview} % Table of contents slide, comment this block out to remove it
%\tableofcontents % Throughout your presentation, if you choose to use \section{} and \subsection{} commands, these will automatically be printed on this slide as an overview of your presentation
%\end{frame}

%------------------------------------------------------------------------
%	PRESENTATION SLIDES
%----------------------------------------------------------------
\section{Review of Neymanian Hypothesis Testing}
\begin{frame}{Hypothesis tests of the weak null} \vfill
\begin{itemize} \vfill
\item The finite population CLT tells us that \vfill
\begin{align*}
\cfrac{\hat{\tau}\left(\bm{Z}, \bm{Y}\right) - \E\left[\hat{\tau}\left(\bm{Z}, \bm{Y}\right)\right]}{\sqrt{\Var\left[\hat{\tau}\left(\bm{Z}, \bm{Y}\right)\right]}} & \overset{d}{\to} \mathcal{N}\left(0, 1\right)
\end{align*} \vfill
\item Diff-in-Means is unbiased, so write \vfill
\begin{align*}
\cfrac{\hat{\tau}\left(\bm{Z}, \bm{Y}\right) - \tau}{\sqrt{\Var\left[\hat{\tau}\left(\bm{Z}, \bm{Y}\right)\right]}} & \overset{d}{\to} \mathcal{N}\left(0, 1\right)
\end{align*} \vfill
\item The CLT is an asymptotic results as $N \to \infty$ \vfill
\item But we can bound error of Normal approximation for fixed $N$ \vfill
\item Thus, with experiments of at least moderate size and outcomes that aren't too skewed or have extreme outliers, \vfill
\begin{align*}
\cfrac{\hat{\tau}\left(\bm{Z}, \bm{Y}\right) - \tau}{\sqrt{\Var\left[\hat{\tau}\left(\bm{Z}, \bm{Y}\right)\right]}} & \overset{\text{approx.}}{\sim} \mathcal{N}\left(0, 1\right)
\end{align*} \vfill
\item This justifies use of standard Normal distribution for hypothesis tests \vfill
\end{itemize} \vfill
\end{frame}
%----------------------------------------------------------------
\begin{frame}{Hypothesis tests of the weak null} \vfill
\begin{itemize} \vfill
\item To test null hypothesis relative to alternative \vfill
\begin{align*}
H_0: & \tau = \tau_0 \text{ versus either } \\
H_A: & \tau > \tau_0, \, H_A: \tau < \tau_0 \text{ or } H_A: \left\lvert \tau \right\rvert > \left\lvert \tau_0 \right \rvert
\end{align*} \vfill
\item Calculate upper(u), lower(l) or two-sided(t) p-value as \vfill
\begin{align*}
p_u & =  1 - \Phi\left(\frac{\hat{\tau}\left(\bm{Z}, \bm{Y}\right) - \tau_0}{\sqrt{\Var\left[\hat{\tau}\left(\bm{Z}, \bm{Y}\right)\right]}}\right) \\
p_l & =  \Phi\left(\frac{\hat{\tau}\left(\bm{Z}, \bm{Y}\right) - \tau_0}{\sqrt{\Var\left[\hat{\tau}\left(\bm{Z}, \bm{Y}\right)\right]}}\right) \\
p_t & = 2\left(1 - \Phi\left(\frac{\left\lvert\hat{\tau}\left(\bm{Z}, \bm{Y}\right) - \tau_0\right\rvert}{\sqrt{\Var\left[\hat{\tau}\left(\bm{Z}, \bm{Y}\right)\right]}}\right)\right)
\end{align*} \vfill
\item If p-value is less than size ($\alpha$-level) of test, reject; otherwise, don't \vfill
\item Note that, since we don't know $\Var\left[\hat{\tau}\left(\bm{Z}, \bm{Y}\right)\right]$, \\ we use its conservative estimator instead, $\widehat{\Var}\left[\hat{\tau}\left(\bm{Z}, \bm{Y}\right)\right]$ \vfill
\end{itemize} \vfill
\end{frame}
%----------------------------------------------------------------
\begin{frame}{Hypothesis tests of the weak null} \vfill
\begin{itemize} \vfill
\item Recall ACORN GOTV experiment \citep{arceneaux2005} from Week 1 \vfill
\item Estimated ATE $\approx 0.0363$ \vfill
\item Conservatively estimated variance $\approx 0.0083$ \vfill
\item So, standardized test-statistic for test of weak null of no average effect is $\approx 0.3978$ \vfill
\vspace{1em}
\begin{figure}
\includegraphics[width = 0.9\linewidth]{acorn_stand_norm_null.pdf}
\end{figure} \vfill
\end{itemize} \vfill
\end{frame}
%----------------------------------------------------------------
\section{Sensitivity Analysis for weak nulls}
\begin{frame}
\frametitle{Sensitivity analysis for weak nulls} 
\vfill
\begin{itemize} \vfill
\item Denote the estimator of average treatment effect in block $b$ by $\hat{\tau}_b$ \vfill
\item An unbiased estimator of the ATE is $\hat{\tau} = \sum \limits_{b = 1}^B (n_b/N)\hat{\tau}_b$ \vfill
\item Suppose Rosenbaum's sensitivity analysis model: \vfill
\begin{align*}
\dfrac{1}{\Gamma} \leq \dfrac{\pi_{bi}/(1 - \pi_{bi})}{\pi_{bj} / (1 - \pi_{bj})} \leq \Gamma \text{ for all } i = 1, \ldots , n_b \text{ and } b = 1, \ldots , B 
\end{align*} \vfill
\item How would we test $H_0: \tau = \tau_0$ under increasingly severe violations of random assignment? \vfill
\end{itemize}  
\vfill
\end{frame}
%----------------------------------------------------------------
\begin{frame}[t]
\frametitle{Sensitivity analysis for weak nulls} 
\vfill
\begin{itemize} \vfill
\item Under random assignment, $\Gamma = 1$, we write our test statistic as \vfill
\begin{align*}
\frac{\hat{\tau}\left(\bm{Z}, \bm{Y}\right) - \tau_0}{\sqrt{\widehat{\Var}\left[\hat{\tau}\left(\bm{Z}, \bm{Y}\right)\right]}}
\end{align*} \vfill
\item But under violations of random assignment $\E\left[\hat{\tau}\right]$ not necessarily equal to $\tau_0$ \vfill
\begin{align} \label{eq: test stat nonrandom}
\frac{\hat{\tau}\left(\bm{Z}, \bm{Y}\right) - \E_{\bm{u}}\left[\hat{\tau}\right]}{\sqrt{\widehat{\Var}_{\bm{u}}\left[\hat{\tau}\left(\bm{Z}, \bm{Y}\right)\right]}}
\end{align} \vfill
\item Ideally, we would directly compare \eqref{eq: test stat nonrandom} to standard Normal distribution \vfill
\item But $\E_{\bm{u}}\left[\hat{\tau}\right]$ and $\widehat{\Var}_{\bm{u}}\left[\hat{\tau}\left(\bm{Z}, \bm{Y}\right)\right]$ depend on unknown $\bm{u}$ and unknown potential outcomes
\end{itemize}  
\vfill
\end{frame}
%----------------------------------------------------------------
\begin{frame}[t]
\frametitle{Sensitivity analysis for weak nulls} 
\vfill
\begin{itemize} \vfill
\item Alternatively, for fixed $\Gamma \geq 1$, we could use
\begin{equation}
\dfrac{\hat{\tau} - \max_{\bm{u} \in \mathcal{U}} \E_{\bm{u}}\left[\hat{\tau}\right]}{\sqrt{\widehat{\Var}_{\bm{u}}\left[\hat{\tau}\right]}}
\end{equation} \vfill
\item Conservative because larger $\E_{\bm{u}}\left[\hat{\tau}\right] \implies $ smaller standardized test statistic $\implies$ higher p-value \vfill
\item Unfortunately, explicitly calculating $\max \limits_{\bm{u} \in \mathcal{U}} \E\left[\hat{\tau}\right]$ requires knowledge of potential outcomes, so we can't actually do this \vfill
\item[$\star$] \textbf{Unlike sharp null, weak null does not imply all missing POs} \vfill
\end{itemize}  
\vfill
\end{frame}
%----------------------------------------------------------------
\begin{frame}[t]
\frametitle{Sensitivity analysis for weak nulls} 
\vfill
\begin{itemize} \vfill
\item So what can we do? \vfill
\item \citet{fogarty2020} shows that, if we choose right test statistic, $t(\cdot, \cdot)$, we can compute tight upper bound for $\max \limits_{\bm{u} \in \mathcal{U}} \E_{\bm{u}}\left[t(\cdot, \cdot)\right]$ \vfill
\item What does ``tight upper bound'' mean? \vfill
\item Tight upper bound is the smallest value greater than maximum expected value of test statistic over all possible configurations of $\bm{u}$ and potential outcomes consistent with $\tau_0$ \vfill
\item \citet{fogarty2020} proposes test-stat in which, under the null,
\begin{equation*}
\max \limits_{\bm{u} \in \mathcal{U}} \E_{\bm{u}}\left[t(\cdot, \cdot)\right] \leq \tau_0
\end{equation*} \vfill
\item Under the null, $\tau_0$ is the ``tight upper bound'' of $\E_{\bm{u}}\left[t(\cdot, \cdot)\right]$ \vfill
\item So we use
\begin{equation}
\dfrac{t(\cdot, \cdot) - \tau_0}{\sqrt{\widehat{\Var}_{\bm{u}}\left[t(\cdot, \cdot)\right]}}
\end{equation}
\end{itemize}  
\vfill
\end{frame}
%----------------------------------------------------------------
\begin{frame}[t]
\frametitle{Sensitivity analysis for weak nulls} 
\vfill
\textbf{Recap}: \vfill
\begin{enumerate} \vfill
\item We want to directly calculate 
\begin{align*}
\frac{\hat{\tau} - \E_{\bm{u}}\left[\hat{\tau}\right]}{\sqrt{\widehat{\Var}_{\bm{u}}\left[\hat{\tau}\right]}}
\end{align*} \vfill
But we cannot because $\bm{u}$ and POs are unknown \vfill
\item To be conservative, what if instead we calculated 
\begin{equation*}
\dfrac{\hat{\tau} - \max_{\bm{u} \in \mathcal{U}} \E_{\bm{u}}\left[\hat{\tau}\right]}{\sqrt{\widehat{\Var}_{\bm{u}}\left[\hat{\tau}\right]}}
\end{equation*} \vfill
But doing this requires info about all POs, not just their means \vfill
\item Instead, we choose sepcific test-stat and use math to show \vfill
\begin{align*}
\max \limits_{\bm{u} \in \mathcal{U}} \E_{\bm{u}}\left[t(\cdot, \cdot)\right] \leq \tau_0,
\end{align*} \vfill
which justifies use of
\begin{equation*}
\dfrac{t(\cdot, \cdot) - \tau_0}{\sqrt{\widehat{\Var}_{\bm{u}}\left[t(\cdot, \cdot)\right]}}
\end{equation*} \vfill
\end{enumerate}
\vfill
\end{frame}
%----------------------------------------------------------------
\begin{frame}[t]{Worst-case inverse probability weighted (IPW) test-stat}
\frametitle{} 
\vfill
\begin{itemize} \vfill
\item Test statistic \citet{fogarty2020} proposes is ``worst-case IPW estimator'' \vfill
\item First, note we can bound $\Pr\left(\bm{Z}_b = \bm{z}\right)$ for given $\Gamma$:
\begin{equation*}
\dfrac{1}{\Gamma(\left\lvert \Omega_b \right \rvert - 1) + 1} \leq \Pr(\bm{Z}_b = \bm{z}) \leq \dfrac{\Gamma}{(\left\lvert \Omega_b \right \rvert - 1) + \Gamma}
\end{equation*}
\vfill
\item With one treated unit in each set, expression simplifies \vfill
\begin{equation*}
\dfrac{1}{\Gamma(n_b - 1) + 1} \leq \Pr(\bm{Z}_b = \bm{z}) \leq \dfrac{\Gamma}{(n_b - 1) + \Gamma}
\end{equation*} \vfill
\end{itemize}  
\vfill
\end{frame}
%----------------------------------------------------------------
\begin{frame}[t]{Worst-case inverse probability weighted (IPW) test-stat}
\frametitle{} 
\vfill
\begin{itemize} \vfill
\item Then, the ``worst case IPW estimator'' is \vfill
\small
\begin{equation}
\widetilde{W}_b = \dfrac{1}{\left\lvert \Omega_b \right \rvert}\left(\dfrac{\hat{\tau}_b}{\Gamma / \left(n_b - 1 + \Gamma\right) \mathbbm{1}\left\{\hat{\tau}_b \geq 0\right\} + 1 / \left(\Gamma(n_b - 1) + 1\right)\mathbbm{1}\left\{\tau_b < 0\right\}}\right)
\end{equation} \normalsize \vfill
\normalsize
\item Weight by largest possible probability when $\hat{\tau}_b \geq 0$ and least possible probability when $\hat{\tau}_b < 0$ \vfill
\item This maximizes expectation of our test statistic, which can be no larger than $\tau_b$ \vfill
\item With asymptotically conservative variance estimator \citep{fogarty2018,fogarty2020}, we have asymptotically valid tests for any $\Gamma \geq 1$ \vfill
\end{itemize}  
\vfill
\end{frame}
%----------------------------------------------------------------

\begin{frame}[t]
\frametitle{Sensitivity analysis for weak nulls} 
\vfill
\begin{itemize} \vfill
\item But what about the variance? It still depends on unknowable $\bm{u}$ . . .  \vfill
\item \citet{fogarty2018} provides conservative variance estimator that converges in probability to value greater than or equal to true variance \vfill
\item We don't need to know missing potential outcomes or unknown confounder $\bm{u}$ to implement this estimator \vfill
\end{itemize}  
\vfill
\end{frame}
%----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{References} 
\scriptsize
\bibliographystyle{chicago}
\bibliography{bibliography}    % name your BibTeX data base
\end{frame}
%----------------------------------------------------------------
%----------------------------------------------------------------
\end{document}