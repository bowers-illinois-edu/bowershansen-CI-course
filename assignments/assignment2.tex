\documentclass{article}
\usepackage{natbib}
\usepackage{soul}
\usepackage{wrapfig}
\title{Assignment 2}
\input{../courseedition}
\author{Due noon Saturday 6/28}
\usepackage{../icpsr-classwork}

\begin{document}
\maketitle

\begin{minipage}{1.0\linewidth}

\begin{wrapfigure}{r}{.65\linewidth}
\igrphx{albertsonLawrence2009tab1}
\end{wrapfigure}

The table at right comes from Albertson and Lawrence's (2009, \textit{Amer. Pol. Res.} \textbf{37}/2) paper ``After the credits roll: The long term effects of educational television on public knowledge and attitudes,'' which reported on two field experiments. Besides being thematically related, the two experiments followed very similar designs, using random digit dialing (RDD) telephone sampling to recruit initial samples, then employing a randomized encouragement design.  Common methods estimate the CACE (LATE) under the following assumptions:

\begin{itemize}
\item Random assignment: $\mathrm{Pr}(Z_{i}=1) = $ constant over study population;  and $\mathrm{Z} $ is determined by coin tosses, card shuffles or equivalent methods
\item Excludability (for all $z$, $d$, $y_{Z=z, D=d} \equiv y_{D=d}$)
\item $p_{c} = \mathrm{Pr}(\mathrm{Complier}) > 0$
\item No interference
\item Monotonicity (no defiers)
\end{itemize}

\end{minipage}
\vspace{2ex}

\begin{enumerate}
\item \label{item:1}Assuming (for this question) that the IV assumptions are
     valid as applied to the Round 2 respondents of each experiment, estimate
     the ACE (Average Causal Effect) of encouragement to view the program on
     program viewing.
\item For one of the experiments, describe a hypothetical outcome variable that
     you would have collected had you written the study questionnaire. Posit a
     hypothetical value for your estimated ACE of encouragement on this outcome;
     combine this and your answer to (\ref{item:1}) to furnish a (hypothetical)
     Bloom-type estimate (estimated ITT/estimated proportion compliers) of the
     complier average causal effect (CACE).
%% \item Response rates for the Round 1 RDD sample recruitment effort are not
%%      reported in the table. Would you need to know these response rates in order
%%      to evaluate the IV assumptions as applied to a ``study population'' of
%%      Round 1 respondents?  As applied to a study population of Round 2
%%      respondents?

\item We use $R$ to indicate whether a subject responds at round 2. Whether a
	person responds can be considered as a (secondary) outcome. Let
	$r_{Ti}$ be an indicator of whether subject $i$ would respond at round
	2 if assigned to the encouragement condition, with $r_{Ci}$ denoting
	$i$'s corresponding potential response if assigned to control.

     \begin{enumerate}

  \item Despite proper use of random assignment procedures during Round 1, the
       possibility that, for many individuals, $r_{T}=1$ (would respond if
               assigned treatment) while $r_{C}=0$ (would not respond if
               assigned control) poses a threat to inference among
               \textit{Round 2} respondents. We can see that the total number
               of valid observations for Table 3 and Table 4 differ somewhat
               from the total number of those assigned to treatment and
               control. The authors do not drop observations based on missing
               covariates (as they explain in a footnote about using dummy
               variables for missingness on covariates). So, these differences
               in numbers reflect missing outcomes rather than a simple average
               of unobserved potential outcomes. Explain why. (It might help to
               think about how the ITT is defined as a difference between
               average potential outcomes among those assigned treatment versus
               among those assigned control, and how  "Always-Reporters" and
               "If Treated Reporters" might differ from each other in regards
               potential outcomes.)

  \item Conversely, explain how for a study population of Round 2 respondents,
       random assignment at round 1 plus the additional assumption that $r_{Ti}
       \equiv r_{Ci}$, all $i$, alleviates this threat to inference.
  % \item What pieces of information that are necessary to appraise the
       %      plausibility of Albertson and Lawrence's (2009) random assignment
       %      assumption are missing from the table?
  \end{enumerate}
\item Which study's instrument is weakest, the Arceneaux 2005 (Acorn) study,
    Albertson and Lawrence's (2009) Study 1 (PBS program) or A. \& L.'s (2009)
    Study 2 (Fox News program)? Briefly justify your answer.
\end{enumerate}


\end{document}
